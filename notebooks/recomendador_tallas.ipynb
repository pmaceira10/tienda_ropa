{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b130ef8d-a37d-4da6-baab-6c8bb0215188",
   "metadata": {},
   "source": [
    "# Recomendador de tallas orientado a reducción de devoluciones\n",
    "\n",
    "Este notebook recoge el desarrollo completo del **recomendador de tallas**, desde la construcción de los datasets hasta la estimación del impacto económico esperado. El objetivo no es predecir devoluciones de forma aislada, sino **utilizar un modelo de riesgo para decidir cuándo y cómo intervenir cambiando la talla recomendada**, minimizando devoluciones y cuantificando el ahorro potencial.\n",
    "\n",
    "El proyecto se apoya en tres pilares:\n",
    "1. Datos consistentes y auditables (productos, clientes, tickets y costes).\n",
    "2. Un modelo de probabilidad de devolución entrenado y calibrado.\n",
    "3. Un recomendador que usa ese modelo para decidir cambios de talla con criterio económico.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Datos de partida y estructura\n",
    "\n",
    "El universo de análisis está a nivel **item** (línea de ticket). A partir de los generadores previos se dispone de:\n",
    "\n",
    "- **Productos**: categoría, SKU, talla, color y sesgos de tallaje implícitos por histórico.\n",
    "- **Clientes**: altura, peso, BMI, histórico de compras y devoluciones.\n",
    "- **Tickets (online)**: fecha de compra, item_id, ticket_id, producto y talla comprada.\n",
    "- **Variable objetivo**: `devuelto` (1 si el item fue devuelto).\n",
    "\n",
    "Adicionalmente, se construye un **dataset de costes de devolución** (`items_devoluciones_ajustadas.csv`) que incluye:\n",
    "- coste base por categoría,\n",
    "- recargo logístico por zona,\n",
    "- ajustes por canal,\n",
    "- ruido controlado para mayor realismo.\n",
    "\n",
    "Este coste se mergea de forma auditada por `(item_id, ticket_id)`, resolviendo duplicados con una política conservadora (máximo coste informado) y generando el flag `has_coste`.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Modelo de devoluciones: para qué se entrena\n",
    "\n",
    "El modelo de devoluciones no se utiliza como un clasificador genérico, sino como un **estimador de riesgo** (`p_dev`) que permite comparar escenarios de talla.\n",
    "\n",
    "La pregunta que responde no es:\n",
    "> “¿Este item se devolverá?”\n",
    "\n",
    "sino:\n",
    "> “¿Qué talla minimiza la probabilidad de devolución para este cliente y este producto?”\n",
    "\n",
    "Por tanto, el modelo es un **componente interno del recomendador**, no un fin en sí mismo.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Feature engineering orientado a talla\n",
    "\n",
    "El feature engineering está diseñado para capturar la interacción cliente–producto:\n",
    "\n",
    "### Variables antropométricas\n",
    "- `altura_cm`\n",
    "- `peso_kg`\n",
    "- `bmi`\n",
    "\n",
    "### Talla y ajuste\n",
    "- `talla_idx`\n",
    "- `ideal_idx` (estimada a partir de altura y peso)\n",
    "- `desajuste` y `desajuste_abs`\n",
    "- `talla_extrema`\n",
    "\n",
    "### Producto y contexto\n",
    "- `categoria`\n",
    "- `id_producto`\n",
    "- estadísticas históricas de devoluciones por producto\n",
    "\n",
    "Estas variables permiten al modelo aprender patrones como:\n",
    "- productos que tallan sistemáticamente grandes o pequeños,\n",
    "- mayor riesgo cuando el desajuste de talla es elevado,\n",
    "- comportamientos diferenciados en tallas extremas.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Entrenamiento, validación y calibración\n",
    "\n",
    "El entrenamiento se realiza con **split temporal**, evitando leakage:\n",
    "\n",
    "- **Train**: histórico antiguo.\n",
    "- **Calibración**: periodo intermedio.\n",
    "- **Test**: periodo más reciente.\n",
    "\n",
    "El modelo principal es **XGBoost**, entrenado con:\n",
    "- PR-AUC como métrica objetivo,\n",
    "- early stopping,\n",
    "- gestión explícita del desbalanceo de clases.\n",
    "\n",
    "Posteriormente, las probabilidades se **calibran** (Platt / Isotonic), de forma que `p_dev` pueda interpretarse como un riesgo real y utilizarse directamente en métricas económicas.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Recomendador de tallas: lógica de decisión\n",
    "\n",
    "El recomendador opera a nivel item y sigue estos pasos:\n",
    "\n",
    "1. Se calcula una talla ideal (`ideal_idx`) mediante heurística antropométrica.\n",
    "2. Se generan tallas candidatas dentro de un rango acotado (±2 tallas).\n",
    "3. Para cada talla candidata:\n",
    "   - se recalculan las variables dependientes de talla,\n",
    "   - el modelo estima la probabilidad de devolución (`p_dev`).\n",
    "4. Se selecciona la talla con menor riesgo esperado.\n",
    "5. La talla solo se cambia si la mejora supera un umbral mínimo (`min_gain`).\n",
    "\n",
    "Este enfoque evita cambios innecesarios, reduce fricción en la experiencia de usuario y prioriza decisiones con impacto real.\n",
    "\n",
    "Las variables clave generadas son:\n",
    "- `p_dev_actual`\n",
    "- `p_dev_final`\n",
    "- `delta_p_final`\n",
    "- `cambia_talla`\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Integración con el modelo global y costes\n",
    "\n",
    "Para contextualizar el impacto económico, se integra un **modelo global de devoluciones** (`p_dev_global`) y el coste estimado de cada devolución.\n",
    "\n",
    "Esto permite medir de forma directa:\n",
    "- **ahorro esperado por item**,\n",
    "- **ahorro esperado por intervención** (solo cuando cambia la talla),\n",
    "- **share del coste total de devoluciones atacable mediante talla**.\n",
    "\n",
    "La métrica central utilizada es:\n",
    "\n",
    "expected_savings_talla = delta_p_final × coste_devolucion\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Dataset final para BI y métricas\n",
    "\n",
    "Se construye un dataset plano **`bi_items.csv`**, listo para Power BI, que incluye:\n",
    "\n",
    "- información del item y del producto,\n",
    "- scores del modelo de devoluciones,\n",
    "- decisión del recomendador de tallas,\n",
    "- métricas económicas esperadas,\n",
    "- variables temporales (`year`, `month`).\n",
    "\n",
    "A partir de este dataset se generan agregaciones para análisis y reporting:\n",
    "- por **categoría**,\n",
    "- por **producto** (top impacto),\n",
    "- por **deciles de riesgo global**,\n",
    "- curvas de **fricción vs ahorro** en función del umbral `min_gain`.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Lectura de resultados\n",
    "\n",
    "Los resultados muestran que:\n",
    "- solo alrededor del **18% de los items** requieren intervención,\n",
    "- el ahorro se concentra en una fracción reducida de productos y en items de mayor riesgo,\n",
    "- aumentar el umbral reduce la fricción con un impacto económico marginal.\n",
    "\n",
    "Esto valida que el recomendador:\n",
    "- actúa de forma selectiva,\n",
    "- está alineado con objetivos de negocio,\n",
    "- y es escalable a un entorno productivo.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Conclusión\n",
    "\n",
    "Este recomendador no “adivina tallas”, sino que **optimiza decisiones** utilizando un modelo de riesgo calibrado y una función económica clara.  \n",
    "El valor no está en cambiar muchas tallas, sino en **cambiar pocas, bien justificadas y con impacto medible**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9544c8a2-abf4-46b4-9dee-0eee006b7609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "import unicodedata\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss, brier_score_loss\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "259c9064-be5c-4ffc-98ac-f0b275f04a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta y origen de datos\n",
    "DB_PATH = \"database/mi_base.db\"\n",
    "TABLE_NAME = \"dataset_modelo_a_tallas\"\n",
    "\n",
    "# Categorías consideradas como prendas con recomendación por talla estándar\n",
    "ROPA_CATS = {\"camiseta\", \"sudadera\", \"pantalon\", \"abrigo\", \"camisa\"}\n",
    "\n",
    "# Espacio de tallas soportado y diccionarios de conversión a índice (útil para modelos/clasificación)\n",
    "TALLAS_ROPA = [\"XS\", \"S\", \"M\", \"L\", \"XL\"]\n",
    "TALLA_TO_IDX = {talla: i for i, talla in enumerate(TALLAS_ROPA)}\n",
    "IDX_TO_TALLA = {i: talla for talla, i in TALLA_TO_IDX.items()}\n",
    "\n",
    "# Normalización de tallas de entrada (p. ej. texto en minúsculas o formatos inconsistentes)\n",
    "MAP_TALLA = {\"xs\": \"XS\", \"s\": \"S\", \"m\": \"M\", \"l\": \"L\", \"xl\": \"XL\"}\n",
    "\n",
    "# Rangos heurísticos de referencia (baseline) para asociar talla con altura/peso.\n",
    "# Se utilizan como regla inicial o fallback cuando no se dispone de señal suficiente del modelo.\n",
    "ROPA_RANGES = {\n",
    "    \"XS\": {\"h\": (150, 165), \"w\": (40, 70)},\n",
    "    \"S\":  {\"h\": (158, 172), \"w\": (48, 80)},\n",
    "    \"M\":  {\"h\": (166, 180), \"w\": (58, 95)},\n",
    "    \"L\":  {\"h\": (174, 188), \"w\": (68, 115)},\n",
    "    \"XL\": {\"h\": (182, 210), \"w\": (78, 140)},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc00e5fd-14cb-40a3-b309-9e5e78e1d95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado: 684561 filas, 13 columnas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>canal</th>\n",
       "      <th>sku</th>\n",
       "      <th>id_producto</th>\n",
       "      <th>categoria</th>\n",
       "      <th>talla</th>\n",
       "      <th>altura_cm</th>\n",
       "      <th>peso_kg</th>\n",
       "      <th>bmi</th>\n",
       "      <th>fecha_item</th>\n",
       "      <th>devuelto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T000001-001</td>\n",
       "      <td>T000001</td>\n",
       "      <td>C000001</td>\n",
       "      <td>online</td>\n",
       "      <td>P005-NAV-L</td>\n",
       "      <td>P005</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>L</td>\n",
       "      <td>184.2</td>\n",
       "      <td>71.2</td>\n",
       "      <td>20.99</td>\n",
       "      <td>2017-08-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T000002-001</td>\n",
       "      <td>T000002</td>\n",
       "      <td>C000002</td>\n",
       "      <td>online</td>\n",
       "      <td>P005-BEI-L</td>\n",
       "      <td>P005</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>L</td>\n",
       "      <td>182.3</td>\n",
       "      <td>75.4</td>\n",
       "      <td>22.68</td>\n",
       "      <td>2017-08-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T000003-001</td>\n",
       "      <td>T000003</td>\n",
       "      <td>C000003</td>\n",
       "      <td>online</td>\n",
       "      <td>P002-BLU-XL</td>\n",
       "      <td>P002</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>XL</td>\n",
       "      <td>189.6</td>\n",
       "      <td>94.5</td>\n",
       "      <td>26.29</td>\n",
       "      <td>2017-08-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T000003-002</td>\n",
       "      <td>T000003</td>\n",
       "      <td>C000003</td>\n",
       "      <td>online</td>\n",
       "      <td>P003-BLK-XL</td>\n",
       "      <td>P003</td>\n",
       "      <td>sudadera</td>\n",
       "      <td>XL</td>\n",
       "      <td>189.6</td>\n",
       "      <td>94.5</td>\n",
       "      <td>26.29</td>\n",
       "      <td>2017-08-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T000004-001</td>\n",
       "      <td>T000004</td>\n",
       "      <td>C000003</td>\n",
       "      <td>online</td>\n",
       "      <td>P003-NAV-XL</td>\n",
       "      <td>P003</td>\n",
       "      <td>sudadera</td>\n",
       "      <td>XL</td>\n",
       "      <td>189.6</td>\n",
       "      <td>94.5</td>\n",
       "      <td>26.29</td>\n",
       "      <td>2021-02-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id ticket_id customer_id   canal          sku id_producto  \\\n",
       "0  T000001-001   T000001     C000001  online   P005-NAV-L        P005   \n",
       "1  T000002-001   T000002     C000002  online   P005-BEI-L        P005   \n",
       "2  T000003-001   T000003     C000003  online  P002-BLU-XL        P002   \n",
       "3  T000003-002   T000003     C000003  online  P003-BLK-XL        P003   \n",
       "4  T000004-001   T000004     C000003  online  P003-NAV-XL        P003   \n",
       "\n",
       "  categoria talla  altura_cm  peso_kg    bmi           fecha_item  devuelto  \n",
       "0    abrigo     L      184.2     71.2  20.99  2017-08-01 00:00:00         0  \n",
       "1    abrigo     L      182.3     75.4  22.68  2017-08-01 00:00:00         0  \n",
       "2  camiseta    XL      189.6     94.5  26.29  2017-08-01 00:00:00         0  \n",
       "3  sudadera    XL      189.6     94.5  26.29  2017-08-01 00:00:00         1  \n",
       "4  sudadera    XL      189.6     94.5  26.29  2021-02-14 00:00:00         0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_from_sqlite(db_path: str, table_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carga una tabla completa desde una base de datos SQLite y la devuelve\n",
    "    como DataFrame de pandas.\n",
    "    \"\"\"\n",
    "    con = sqlite3.connect(db_path)\n",
    "    try:\n",
    "        df = pd.read_sql_query(\n",
    "            f\"SELECT * FROM {table_name}\",\n",
    "            con\n",
    "        )\n",
    "    finally:\n",
    "        con.close()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df_raw = load_from_sqlite(DB_PATH, TABLE_NAME)\n",
    "\n",
    "# Comprobación rápida de volumen para asegurar que la carga es consistente\n",
    "print(f\"Dataset cargado: {df_raw.shape[0]} filas, {df_raw.shape[1]} columnas\")\n",
    "\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "569cadd9-81d5-4a47-b69e-c20691f60c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_clean generado: 619514 filas, 13 columnas\n",
      "Distribución por categoría: {'camiseta': 196123, 'abrigo': 169076, 'pantalon': 146619, 'sudadera': 67015, 'camisa': 40681}\n",
      "Distribución por talla: {'M': 237333, 'L': 207858, 'XL': 99612, 'S': 62986, 'XS': 11725}\n",
      "Rango altura (cm): 150.1 - 209.5\n",
      "Rango peso (kg): 40.0 - 153.8\n",
      "Ratio global de devolución: 0.3159\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(value):\n",
    "    \"\"\"\n",
    "    Normaliza texto eliminando acentos, forzando minúsculas y\n",
    "    recortando espacios. Devuelve NaN si el valor es nulo.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "\n",
    "    value = unicodedata.normalize(\"NFKD\", str(value))\n",
    "    value = \"\".join(c for c in value if not unicodedata.combining(c))\n",
    "\n",
    "    return value.lower().strip()\n",
    "\n",
    "\n",
    "def build_df_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aplica limpieza y validaciones básicas al dataset original,\n",
    "    dejando un conjunto consistente de observaciones aptas para\n",
    "    la lógica de recomendación de tallas.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    # Normalización de variables categóricas clave\n",
    "    out[\"categoria\"] = out[\"categoria\"].apply(normalize_text)\n",
    "    out[\"talla\"] = out[\"talla\"].apply(normalize_text)\n",
    "\n",
    "    # Filtrado a categorías de ropa con sistema de tallas estándar\n",
    "    out = out[out[\"categoria\"].isin(ROPA_CATS)].copy()\n",
    "\n",
    "    # Normalización y validación del espacio de tallas\n",
    "    out[\"talla\"] = out[\"talla\"].map(MAP_TALLA)\n",
    "    out = out[out[\"talla\"].isin(TALLAS_ROPA)].copy()\n",
    "\n",
    "    # Conversión explícita de variables antropométricas a numérico\n",
    "    for col in [\"altura_cm\", \"peso_kg\", \"bmi\"]:\n",
    "        out[col] = pd.to_numeric(out[col], errors=\"coerce\")\n",
    "\n",
    "    # Eliminación de observaciones con valores físicos no plausibles\n",
    "    out = out[\n",
    "        out[\"altura_cm\"].between(145, 210) &\n",
    "        out[\"peso_kg\"].between(40, 180)\n",
    "    ].copy()\n",
    "\n",
    "    # Re-cálculo del BMI como fuente única de verdad\n",
    "    out[\"bmi\"] = out[\"peso_kg\"] / (out[\"altura_cm\"] / 100.0) ** 2\n",
    "\n",
    "    # Validación temporal del evento de compra\n",
    "    out[\"fecha_item\"] = pd.to_datetime(out[\"fecha_item\"], errors=\"coerce\")\n",
    "    out = out[out[\"fecha_item\"].notna()].copy()\n",
    "\n",
    "    # Normalización de la variable objetivo (devolución)\n",
    "    out[\"devuelto\"] = (\n",
    "        pd.to_numeric(out[\"devuelto\"], errors=\"coerce\")\n",
    "        .fillna(0)\n",
    "        .astype(\"int8\")\n",
    "    )\n",
    "\n",
    "    return out.reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_clean = build_df_clean(df_raw)\n",
    "\n",
    "print(f\"df_clean generado: {df_clean.shape[0]} filas, {df_clean.shape[1]} columnas\")\n",
    "print(\"Distribución por categoría:\", df_clean[\"categoria\"].value_counts().to_dict())\n",
    "print(\"Distribución por talla:\", df_clean[\"talla\"].value_counts().to_dict())\n",
    "print(\n",
    "    \"Rango altura (cm):\",\n",
    "    df_clean[\"altura_cm\"].min(),\n",
    "    \"-\",\n",
    "    df_clean[\"altura_cm\"].max()\n",
    ")\n",
    "print(\n",
    "    \"Rango peso (kg):\",\n",
    "    df_clean[\"peso_kg\"].min(),\n",
    "    \"-\",\n",
    "    df_clean[\"peso_kg\"].max()\n",
    ")\n",
    "print(\"Ratio global de devolución:\", round(df_clean[\"devuelto\"].mean(), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b497b5e1-8413-4425-a45d-da697fa4a949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all: (619514, 19) | ratio devolución: 0.3159\n",
      "df_mis: (80469, 19) | ratio devolución: 0.491\n",
      "desajuste\n",
      "-2       320\n",
      "-1     20676\n",
      " 0    539045\n",
      " 1     58679\n",
      " 2       780\n",
      " 3        14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def infer_talla_ideal_ropa(h: np.ndarray, w: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Infere la talla ideal a partir de altura (cm) y peso (kg) usando una métrica\n",
    "    de distancia a los centros de los rangos heurísticos definidos en ROPA_RANGES.\n",
    "    La distancia se normaliza por la amplitud del rango para hacer comparables\n",
    "    variables en escalas distintas.\n",
    "    \"\"\"\n",
    "    h = h.astype(float)\n",
    "    w = w.astype(float)\n",
    "\n",
    "    sizes = TALLAS_ROPA\n",
    "    n = len(h)\n",
    "    k = len(sizes)\n",
    "\n",
    "    h_mid = np.empty(k)\n",
    "    w_mid = np.empty(k)\n",
    "    h_span = np.empty(k)\n",
    "    w_span = np.empty(k)\n",
    "\n",
    "    for j, talla in enumerate(sizes):\n",
    "        h_low, h_high = ROPA_RANGES[talla][\"h\"]\n",
    "        w_low, w_high = ROPA_RANGES[talla][\"w\"]\n",
    "\n",
    "        h_mid[j] = (h_low + h_high) / 2.0\n",
    "        w_mid[j] = (w_low + w_high) / 2.0\n",
    "        h_span[j] = (h_high - h_low)\n",
    "        w_span[j] = (w_high - w_low)\n",
    "\n",
    "    dh = (h.reshape(n, 1) - h_mid.reshape(1, k)) / h_span.reshape(1, k)\n",
    "    dw = (w.reshape(n, 1) - w_mid.reshape(1, k)) / w_span.reshape(1, k)\n",
    "\n",
    "    score = (dh ** 2) * 0.60 + (dw ** 2) * 0.40\n",
    "    best_idx = np.argmin(score, axis=1)\n",
    "\n",
    "    return np.array([sizes[j] for j in best_idx], dtype=object)\n",
    "\n",
    "\n",
    "def build_size_features(df_clean: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Construye variables relacionadas con talla ideal y desajuste entre la talla\n",
    "    comprada y la talla inferida por la heurística.\n",
    "    Devuelve:\n",
    "      - df_all: dataset completo con las nuevas variables\n",
    "      - df_mis: subconjunto con desajuste distinto de cero\n",
    "    \"\"\"\n",
    "    out = df_clean.copy()\n",
    "\n",
    "    out[\"talla_idx\"] = out[\"talla\"].map(TALLA_TO_IDX).astype(\"int8\")\n",
    "\n",
    "    talla_ideal = infer_talla_ideal_ropa(\n",
    "        out[\"altura_cm\"].to_numpy(),\n",
    "        out[\"peso_kg\"].to_numpy()\n",
    "    )\n",
    "    out[\"talla_ideal\"] = talla_ideal\n",
    "    out[\"ideal_idx\"] = pd.Series(out[\"talla_ideal\"]).map(TALLA_TO_IDX).astype(\"int8\")\n",
    "\n",
    "    out[\"desajuste\"] = (out[\"talla_idx\"] - out[\"ideal_idx\"]).astype(\"int8\")\n",
    "    out[\"desajuste_abs\"] = out[\"desajuste\"].abs().astype(\"int8\")\n",
    "\n",
    "    out[\"talla_extrema\"] = out[\"talla\"].isin([\"XS\", \"XL\"]).astype(\"int8\")\n",
    "\n",
    "    df_all = out.reset_index(drop=True)\n",
    "    df_mis = df_all[df_all[\"desajuste_abs\"] > 0].copy().reset_index(drop=True)\n",
    "\n",
    "    return df_all, df_mis\n",
    "\n",
    "\n",
    "df_all, df_mis = build_size_features(df_clean)\n",
    "\n",
    "print(f\"df_all: {df_all.shape} | ratio devolución: {round(df_all['devuelto'].mean(), 4)}\")\n",
    "print(f\"df_mis: {df_mis.shape} | ratio devolución: {round(df_mis['devuelto'].mean(), 4)}\")\n",
    "print(df_all[\"desajuste\"].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac771017-9f82-4783-9cf1-6ab379beddeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all2: (619514, 25)\n",
      "prod_profile: (51, 7)\n",
      "meta: {'global_mean_des': 0.06289607660198156, 'global_mean_abs': 0.1317113091875244, 'min_n': 15, 'prior_strength': 50.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_producto</th>\n",
       "      <th>prod_n</th>\n",
       "      <th>prod_has_history</th>\n",
       "      <th>prod_mean_des_smooth</th>\n",
       "      <th>prod_mean_abs_smooth</th>\n",
       "      <th>prod_bias_dir</th>\n",
       "      <th>prod_bias_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P003</td>\n",
       "      <td>54193</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063956</td>\n",
       "      <td>0.132083</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>54136</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062823</td>\n",
       "      <td>0.130543</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P008</td>\n",
       "      <td>51913</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062316</td>\n",
       "      <td>0.132856</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P013</td>\n",
       "      <td>48626</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064593</td>\n",
       "      <td>0.132993</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P005</td>\n",
       "      <td>43462</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067111</td>\n",
       "      <td>0.133149</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_producto  prod_n  prod_has_history  prod_mean_des_smooth  \\\n",
       "2         P003   54193                 1              0.063956   \n",
       "1         P002   54136                 1              0.062823   \n",
       "7         P008   51913                 1              0.062316   \n",
       "11        P013   48626                 1              0.064593   \n",
       "4         P005   43462                 1              0.067111   \n",
       "\n",
       "    prod_mean_abs_smooth  prod_bias_dir  prod_bias_strength  \n",
       "2               0.132083              1            0.063956  \n",
       "1               0.130543              1            0.062823  \n",
       "7               0.132856              1            0.062316  \n",
       "11              0.132993              1            0.064593  \n",
       "4               0.133149              1            0.067111  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_product_profile_features(\n",
    "    df_in: pd.DataFrame,\n",
    "    prod_col: str = \"id_producto\",\n",
    "    des_col: str = \"desajuste\",\n",
    "    min_n: int = 15,\n",
    "    prior_strength: float = 50.0,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Construye un perfil por producto basado en el desajuste histórico observado.\n",
    "    Se aplica suavizado (shrinkage) hacia la media global para evitar estimaciones\n",
    "    ruidosas en productos con pocas observaciones.\n",
    "\n",
    "    Devuelve:\n",
    "      - out: dataset original con las variables de perfil añadidas\n",
    "      - prof: tabla de perfil por producto\n",
    "      - meta: parámetros globales usados en la construcción\n",
    "    \"\"\"\n",
    "    df = df_in.copy()\n",
    "\n",
    "    global_mean = float(df[des_col].mean())\n",
    "    global_mean_abs = float(df[des_col].abs().mean())\n",
    "\n",
    "    g = df.groupby(prod_col, dropna=False)\n",
    "\n",
    "    prof = (\n",
    "        g[des_col]\n",
    "        .agg(prod_n=\"size\", prod_mean_des=\"mean\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    prof_abs = (\n",
    "        g[des_col]\n",
    "        .agg(prod_mean_abs=lambda s: float(np.mean(np.abs(s))))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    prof[\"prod_mean_abs\"] = prof_abs\n",
    "\n",
    "    n = prof[\"prod_n\"].astype(float)\n",
    "\n",
    "    prof[\"prod_mean_des_smooth\"] = (\n",
    "        (n * prof[\"prod_mean_des\"] + prior_strength * global_mean) / (n + prior_strength)\n",
    "    )\n",
    "    prof[\"prod_mean_abs_smooth\"] = (\n",
    "        (n * prof[\"prod_mean_abs\"] + prior_strength * global_mean_abs) / (n + prior_strength)\n",
    "    )\n",
    "\n",
    "    prof[\"prod_has_history\"] = (prof[\"prod_n\"] >= min_n).astype(\"int8\")\n",
    "    prof[\"prod_bias_dir\"] = np.sign(prof[\"prod_mean_des_smooth\"]).astype(\"int8\")\n",
    "    prof[\"prod_bias_strength\"] = np.abs(prof[\"prod_mean_des_smooth\"]).astype(\"float32\")\n",
    "\n",
    "    prof = prof[\n",
    "        [\n",
    "            prod_col,\n",
    "            \"prod_n\",\n",
    "            \"prod_has_history\",\n",
    "            \"prod_mean_des_smooth\",\n",
    "            \"prod_mean_abs_smooth\",\n",
    "            \"prod_bias_dir\",\n",
    "            \"prod_bias_strength\",\n",
    "        ]\n",
    "    ].copy()\n",
    "\n",
    "    out = df.merge(prof, on=prod_col, how=\"left\")\n",
    "\n",
    "    # Rellenos coherentes para productos sin historial (por ejemplo, productos nuevos)\n",
    "    out[\"prod_n\"] = out[\"prod_n\"].fillna(0).astype(int)\n",
    "    out[\"prod_has_history\"] = out[\"prod_has_history\"].fillna(0).astype(\"int8\")\n",
    "\n",
    "    out[\"prod_mean_des_smooth\"] = out[\"prod_mean_des_smooth\"].fillna(global_mean).astype(\"float32\")\n",
    "    out[\"prod_mean_abs_smooth\"] = out[\"prod_mean_abs_smooth\"].fillna(global_mean_abs).astype(\"float32\")\n",
    "\n",
    "    out[\"prod_bias_dir\"] = out[\"prod_bias_dir\"].fillna(0).astype(\"int8\")\n",
    "    out[\"prod_bias_strength\"] = out[\"prod_bias_strength\"].fillna(abs(global_mean)).astype(\"float32\")\n",
    "\n",
    "    meta = {\n",
    "        \"global_mean_des\": global_mean,\n",
    "        \"global_mean_abs\": global_mean_abs,\n",
    "        \"min_n\": min_n,\n",
    "        \"prior_strength\": prior_strength,\n",
    "    }\n",
    "\n",
    "    return out, prof, meta\n",
    "\n",
    "\n",
    "df_all2, prod_profile, prod_meta = add_product_profile_features(\n",
    "    df_all,\n",
    "    prod_col=\"id_producto\",\n",
    "    des_col=\"desajuste\",\n",
    "    min_n=15,\n",
    "    prior_strength=50.0,\n",
    ")\n",
    "\n",
    "print(f\"df_all2: {df_all2.shape}\")\n",
    "print(f\"prod_profile: {prod_profile.shape}\")\n",
    "print(\"meta:\", prod_meta)\n",
    "\n",
    "prod_profile.sort_values(\"prod_n\", ascending=False).head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f9f08bbe-861a-40a0-aafa-779b78a6ebb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A1] P004 (pantalon) 167/54 -> S (ideal=S)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talla</th>\n",
       "      <th>score</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XS</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L</td>\n",
       "      <td>-2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  talla  score    pct\n",
       "0     S      0  100.0\n",
       "1    XS     -1    0.0\n",
       "2     M     -1    0.0\n",
       "3     L     -2    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A2] P004 (pantalon) 167/54 -> S (ideal=S, bias=+0.062, step=+0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talla</th>\n",
       "      <th>score</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XS</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L</td>\n",
       "      <td>-2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  talla  score    pct\n",
       "0     S      0  100.0\n",
       "1    XS     -1    0.0\n",
       "2     M     -1    0.0\n",
       "3     L     -2    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clamp_idx(idx: int) -> int:\n",
    "    \"\"\"Asegura que un índice de talla cae dentro del rango válido.\"\"\"\n",
    "    return int(max(0, min(len(TALLAS_ROPA) - 1, idx)))\n",
    "\n",
    "\n",
    "def build_product_bias_lookup(prod_profile: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Construye un diccionario id_producto -> sesgo suavizado de desajuste.\n",
    "    Se usa como señal adicional para corregir tallaje sistemático por producto.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        prod_profile\n",
    "        .assign(id_producto=lambda d: d[\"id_producto\"].astype(str))\n",
    "        .set_index(\"id_producto\")[\"prod_mean_des_smooth\"]\n",
    "        .astype(float)\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "\n",
    "def bias_to_step(bias: float, thr: float = 0.25, gain: float = 2.0) -> int:\n",
    "    \"\"\"\n",
    "    Convierte un sesgo continuo en un ajuste discreto de talla en {-1, 0, +1}.\n",
    "    El umbral evita aplicar correcciones por ruido cuando el historial es débil.\n",
    "    \"\"\"\n",
    "    x = gain * float(bias)\n",
    "    if abs(x) < thr:\n",
    "        return 0\n",
    "    return int(np.sign(x))\n",
    "\n",
    "\n",
    "def recommend_A1(\n",
    "    df_like: pd.DataFrame,\n",
    "    id_producto: str,\n",
    "    altura_cm: float,\n",
    "    peso_kg: float,\n",
    "    max_step_ropa: int = 2,\n",
    "    tau: float = 0.06,\n",
    ") -> tuple[str | None, pd.DataFrame, str]:\n",
    "    \"\"\"\n",
    "    Baseline A1: recomienda la talla ideal inferida a partir de altura y peso.\n",
    "    Devuelve la talla recomendada, una tabla de candidatas con puntuación y un\n",
    "    texto resumen para depuración/auditoría.\n",
    "    \"\"\"\n",
    "    sub = df_like[df_like[\"id_producto\"].astype(str) == str(id_producto)]\n",
    "    if sub.empty:\n",
    "        raise ValueError(f\"[A1] id_producto={id_producto} no existe en el dataset de referencia.\")\n",
    "\n",
    "    categoria = str(sub.iloc[0][\"categoria\"]).strip().lower()\n",
    "    if categoria not in ROPA_CATS:\n",
    "        return None, pd.DataFrame(), f\"[A1] Categoría fuera de alcance: {categoria}\"\n",
    "\n",
    "    ideal = infer_talla_ideal_ropa(np.array([altura_cm]), np.array([peso_kg]))[0]\n",
    "    idx_ideal = TALLA_TO_IDX[ideal]\n",
    "\n",
    "    lo = clamp_idx(idx_ideal - max_step_ropa)\n",
    "    hi = clamp_idx(idx_ideal + max_step_ropa)\n",
    "    candidatas = TALLAS_ROPA[lo:hi + 1]\n",
    "\n",
    "    rows = []\n",
    "    for talla in candidatas:\n",
    "        dist = abs(TALLA_TO_IDX[talla] - idx_ideal)\n",
    "        rows.append((talla, -dist))\n",
    "\n",
    "    tab = (\n",
    "        pd.DataFrame(rows, columns=[\"talla\", \"score\"])\n",
    "        .sort_values(\"score\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    s = tab[\"score\"].to_numpy(float)\n",
    "    s = s - s.max()\n",
    "    w = np.exp(s / max(1e-6, tau))\n",
    "    w = w / w.sum()\n",
    "    tab[\"pct\"] = np.round(100 * w, 2)\n",
    "\n",
    "    best = str(tab.loc[0, \"talla\"])\n",
    "    msg = f\"[A1] {id_producto} ({categoria}) {int(altura_cm)}/{int(peso_kg)} -> {best} (ideal={ideal})\"\n",
    "\n",
    "    return best, tab, msg\n",
    "\n",
    "\n",
    "def recommend_A2(\n",
    "    df_like: pd.DataFrame,\n",
    "    id_producto: str,\n",
    "    altura_cm: float,\n",
    "    peso_kg: float,\n",
    "    prod_bias_lookup: dict,\n",
    "    max_step_ropa: int = 2,\n",
    "    tau: float = 0.06,\n",
    "    thr: float = 0.25,\n",
    "    gain: float = 2.0,\n",
    ") -> tuple[str | None, pd.DataFrame, str]:\n",
    "    \"\"\"\n",
    "    Baseline A2: parte de la talla ideal y aplica un ajuste discreto por producto\n",
    "    usando el sesgo histórico suavizado del desajuste.\n",
    "    \"\"\"\n",
    "    sub = df_like[df_like[\"id_producto\"].astype(str) == str(id_producto)]\n",
    "    if sub.empty:\n",
    "        raise ValueError(f\"[A2] id_producto={id_producto} no existe en el dataset de referencia.\")\n",
    "\n",
    "    categoria = str(sub.iloc[0][\"categoria\"]).strip().lower()\n",
    "    if categoria not in ROPA_CATS:\n",
    "        return None, pd.DataFrame(), f\"[A2] Categoría fuera de alcance: {categoria}\"\n",
    "\n",
    "    ideal = infer_talla_ideal_ropa(np.array([altura_cm]), np.array([peso_kg]))[0]\n",
    "    idx_ideal = TALLA_TO_IDX[ideal]\n",
    "\n",
    "    bias = float(prod_bias_lookup.get(str(id_producto), 0.0))\n",
    "    step = bias_to_step(bias, thr=thr, gain=gain)\n",
    "    idx_target = idx_ideal + step\n",
    "\n",
    "    lo = clamp_idx(idx_ideal - max_step_ropa)\n",
    "    hi = clamp_idx(idx_ideal + max_step_ropa)\n",
    "    candidatas = TALLAS_ROPA[lo:hi + 1]\n",
    "\n",
    "    rows = []\n",
    "    for talla in candidatas:\n",
    "        dist = abs(TALLA_TO_IDX[talla] - idx_target)\n",
    "        rows.append((talla, -dist))\n",
    "\n",
    "    tab = (\n",
    "        pd.DataFrame(rows, columns=[\"talla\", \"score\"])\n",
    "        .sort_values(\"score\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    s = tab[\"score\"].to_numpy(float)\n",
    "    s = s - s.max()\n",
    "    w = np.exp(s / max(1e-6, tau))\n",
    "    w = w / w.sum()\n",
    "    tab[\"pct\"] = np.round(100 * w, 2)\n",
    "\n",
    "    best = str(tab.loc[0, \"talla\"])\n",
    "    msg = (\n",
    "        f\"[A2] {id_producto} ({categoria}) {int(altura_cm)}/{int(peso_kg)} -> {best} \"\n",
    "        f\"(ideal={ideal}, bias={bias:+.3f}, step={step:+d})\"\n",
    "    )\n",
    "\n",
    "    return best, tab, msg\n",
    "\n",
    "\n",
    "prod_bias_lookup = build_product_bias_lookup(prod_profile)\n",
    "\n",
    "row = df_all2.sample(1, random_state=7).iloc[0]\n",
    "pid = str(row[\"id_producto\"])\n",
    "h = float(row[\"altura_cm\"])\n",
    "w = float(row[\"peso_kg\"])\n",
    "\n",
    "t1, tab1, msg1 = recommend_A1(df_all2, pid, h, w)\n",
    "t2, tab2, msg2 = recommend_A2(df_all2, pid, h, w, prod_bias_lookup=prod_bias_lookup)\n",
    "\n",
    "print(msg1)\n",
    "display(tab1)\n",
    "\n",
    "print(msg2)\n",
    "display(tab2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c223aa72-eb98-4881-9b03-1fd0b9ebe014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset final guardado en: data/processed/df_all2.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ruta de salida\n",
    "OUTPUT_PATH = \"data/processed/df_all2.pkl\"\n",
    "\n",
    "# Crear carpeta si no existe\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "\n",
    "# Guardar dataset final del pipeline\n",
    "df_all2.to_pickle(OUTPUT_PATH)\n",
    "\n",
    "print(f\"Dataset final guardado en: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd855740-2df9-4193-b413-32891185221f",
   "metadata": {},
   "source": [
    "# modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2562d9b8-2df5-4ef6-b602-766b069cbe50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (331148, 25) 2017-08-01 00:00:00 2023-12-31 00:00:00\n",
      "calib: (96412, 25) 2024-01-01 00:00:00 2024-08-31 00:00:00\n",
      "test : (191954, 25) 2024-09-01 00:00:00 2025-09-30 00:00:00\n",
      "RR train: 0.28916073779699714\n",
      "RR calib: 0.3466373480479608\n",
      "RR test : 0.34667159840378425\n",
      "train_df2: (331148, 25) calib_df2: (96412, 25) test_df2: (191954, 25)\n"
     ]
    }
   ],
   "source": [
    "df_all2[\"fecha_item\"] = pd.to_datetime(df_all2[\"fecha_item\"], errors=\"coerce\")\n",
    "\n",
    "cut_train_end = pd.Timestamp(\"2024-01-01\")\n",
    "cut_calib_end = pd.Timestamp(\"2024-09-01\")\n",
    "\n",
    "train_df = df_all2[df_all2[\"fecha_item\"] < cut_train_end].copy()\n",
    "calib_df = df_all2[(df_all2[\"fecha_item\"] >= cut_train_end) & (df_all2[\"fecha_item\"] < cut_calib_end)].copy()\n",
    "test_df  = df_all2[df_all2[\"fecha_item\"] >= cut_calib_end].copy()\n",
    "\n",
    "print(\"train:\", train_df.shape, train_df[\"fecha_item\"].min(), train_df[\"fecha_item\"].max())\n",
    "print(\"calib:\", calib_df.shape, calib_df[\"fecha_item\"].min(), calib_df[\"fecha_item\"].max())\n",
    "print(\"test :\", test_df.shape, test_df[\"fecha_item\"].min(), test_df[\"fecha_item\"].max())\n",
    "\n",
    "print(\"RR train:\", float(train_df[\"devuelto\"].mean()))\n",
    "print(\"RR calib:\", float(calib_df[\"devuelto\"].mean()))\n",
    "print(\"RR test :\", float(test_df[\"devuelto\"].mean()))\n",
    "\n",
    "\n",
    "def drop_prod_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Elimina columnas derivadas del perfil de producto para evitar colisiones\n",
    "    cuando se recalculan perfiles con distinta partición temporal.\n",
    "    \"\"\"\n",
    "    prod_cols = [c for c in df.columns if c.startswith(\"prod_\")]\n",
    "    return df.drop(columns=prod_cols, errors=\"ignore\").copy()\n",
    "\n",
    "\n",
    "train_base = drop_prod_cols(train_df)\n",
    "calib_base = drop_prod_cols(calib_df)\n",
    "test_base  = drop_prod_cols(test_df)\n",
    "\n",
    "\n",
    "train_df2, prod_profile_train, prod_meta_train = add_product_profile_features(\n",
    "    train_base,\n",
    "    prod_col=\"id_producto\",\n",
    "    des_col=\"desajuste\",\n",
    "    min_n=15,\n",
    "    prior_strength=50.0\n",
    ")\n",
    "\n",
    "global_mean = float(prod_meta_train[\"global_mean_des\"])\n",
    "global_abs  = float(prod_meta_train[\"global_mean_abs\"])\n",
    "\n",
    "\n",
    "def apply_prod_profile(df_base: pd.DataFrame, prod_profile: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aplica un perfil de producto precomputado al dataset, usando valores\n",
    "    globales como fallback para productos sin historial.\n",
    "    \"\"\"\n",
    "    out = df_base.merge(prod_profile, on=\"id_producto\", how=\"left\")\n",
    "\n",
    "    out[\"prod_n\"] = out[\"prod_n\"].fillna(0).astype(int)\n",
    "    out[\"prod_has_history\"] = out[\"prod_has_history\"].fillna(0).astype(\"int8\")\n",
    "\n",
    "    out[\"prod_mean_des_smooth\"] = out[\"prod_mean_des_smooth\"].fillna(global_mean).astype(\"float32\")\n",
    "    out[\"prod_mean_abs_smooth\"] = out[\"prod_mean_abs_smooth\"].fillna(global_abs).astype(\"float32\")\n",
    "\n",
    "    out[\"prod_bias_dir\"] = out[\"prod_bias_dir\"].fillna(0).astype(\"int8\")\n",
    "    out[\"prod_bias_strength\"] = out[\"prod_bias_strength\"].fillna(abs(global_mean)).astype(\"float32\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "calib_df2 = apply_prod_profile(calib_base, prod_profile_train)\n",
    "test_df2  = apply_prod_profile(test_base,  prod_profile_train)\n",
    "\n",
    "print(\"train_df2:\", train_df2.shape, \"calib_df2:\", calib_df2.shape, \"test_df2:\", test_df2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ff1676ca-ad60-4416-96ed-9e403d53d3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrices: (331148, 55) (96412, 55) (191954, 55)\n"
     ]
    }
   ],
   "source": [
    "TARGET = \"devuelto\"\n",
    "\n",
    "cat_features = [\"categoria\", \"id_producto\"]\n",
    "num_features = [\n",
    "    \"altura_cm\", \"peso_kg\", \"bmi\",\n",
    "    \"talla_idx\", \"ideal_idx\",\n",
    "    \"desajuste\", \"desajuste_abs\",\n",
    "    \"talla_extrema\",\n",
    "    \"prod_mean_des_smooth\", \"prod_bias_strength\",\n",
    "    \"prod_has_history\",\n",
    "]\n",
    "\n",
    "X_train = train_df2[cat_features + num_features].copy()\n",
    "y_train = train_df2[TARGET].astype(int).copy()\n",
    "\n",
    "X_cal = calib_df2[cat_features + num_features].copy()\n",
    "y_cal = calib_df2[TARGET].astype(int).copy()\n",
    "\n",
    "X_test = test_df2[cat_features + num_features].copy()\n",
    "y_test = test_df2[TARGET].astype(int).copy()\n",
    "\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]), cat_features),\n",
    "        (\"num\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        ]), num_features),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "Xtr = preprocess.fit_transform(X_train)\n",
    "Xca = preprocess.transform(X_cal)\n",
    "Xte = preprocess.transform(X_test)\n",
    "\n",
    "print(\"Matrices:\", Xtr.shape, Xca.shape, Xte.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "420300d8-ed4f-4609-92c7-7009ba2f61a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.59922\tcalib-logloss:0.64909\n",
      "[200]\ttrain-logloss:0.57093\tcalib-logloss:0.60768\n",
      "[400]\ttrain-logloss:0.56675\tcalib-logloss:0.60737\n",
      "[600]\ttrain-logloss:0.56332\tcalib-logloss:0.60754\n",
      "[648]\ttrain-logloss:0.56247\tcalib-logloss:0.60760\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(Xtr, label=y_train)\n",
    "dcal   = xgb.DMatrix(Xca, label=y_cal)\n",
    "dtest  = xgb.DMatrix(Xte, label=y_test)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"eta\": 0.05,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_child_weight\": 5,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"lambda\": 1.0,\n",
    "    \"alpha\": 0.0,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"seed\": 7,\n",
    "}\n",
    "\n",
    "evals = [(dtrain, \"train\"), (dcal, \"calib\")]\n",
    "\n",
    "booster = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=5000,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=200,\n",
    "    verbose_eval=200,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "05f5e542-87d1-4d87-8f4e-4116c1ca7c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR real calib: 0.3466373480479608 RR pred calib RAW: 0.3099621534347534\n",
      "RR real test : 0.34667159840378425 RR pred test  RAW: 0.3105109930038452\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    p_cal_raw  = booster.predict(dcal,  iteration_range=(0, booster.best_iteration + 1))\n",
    "    p_test_raw = booster.predict(dtest, iteration_range=(0, booster.best_iteration + 1))\n",
    "except TypeError:\n",
    "    p_cal_raw  = booster.predict(dcal,  ntree_limit=getattr(booster, \"best_ntree_limit\", 0) or 0)\n",
    "    p_test_raw = booster.predict(dtest, ntree_limit=getattr(booster, \"best_ntree_limit\", 0) or 0)\n",
    "\n",
    "print(\"RR real calib:\", float(y_cal.mean()), \"RR pred calib RAW:\", float(np.mean(p_cal_raw)))\n",
    "print(\"RR real test :\", float(y_test.mean()), \"RR pred test  RAW:\", float(np.mean(p_test_raw)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7977c753-faf4-4001-baad-adb2dcd1a89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGB calibrado (Platt) ===\n",
      "AUC: 0.6588341948226026\n",
      "PR-AUC: 0.5231333377851516\n",
      "LogLoss: 0.6046991920502619\n",
      "Brier: 0.20771543233581286\n",
      "RR real test: 0.34667159840378425\n",
      "RR pred test: 0.34740813163962375\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-6\n",
    "\n",
    "z_cal = np.log(np.clip(p_cal_raw, eps, 1 - eps) / np.clip(1 - p_cal_raw, eps, 1 - eps)).reshape(-1, 1)\n",
    "z_test = np.log(np.clip(p_test_raw, eps, 1 - eps) / np.clip(1 - p_test_raw, eps, 1 - eps)).reshape(-1, 1)\n",
    "\n",
    "platt = LogisticRegression(max_iter=2000, solver=\"lbfgs\")\n",
    "platt.fit(z_cal, y_cal)\n",
    "\n",
    "p_test_platt = platt.predict_proba(z_test)[:, 1]\n",
    "\n",
    "print(\"=== XGB calibrado (Platt) ===\")\n",
    "print(\"AUC:\", roc_auc_score(y_test, p_test_platt))\n",
    "print(\"PR-AUC:\", average_precision_score(y_test, p_test_platt))\n",
    "print(\"LogLoss:\", log_loss(y_test, p_test_platt))\n",
    "print(\"Brier:\", brier_score_loss(y_test, p_test_platt))\n",
    "print(\"RR real test:\", float(y_test.mean()))\n",
    "print(\"RR pred test:\", float(np.mean(p_test_platt)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "16a8d7ea-f3ce-4ed0-89dd-cd1f7ca97e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGB calibrado (Isotonic) ===\n",
      "AUC: 0.6586505294296866\n",
      "PR-AUC: 0.5149625198702965\n",
      "LogLoss: 0.6051253823544808\n",
      "Brier: 0.20777431113671938\n",
      "RR real test: 0.34667159840378425\n",
      "RR pred test: 0.34717676043510437\n"
     ]
    }
   ],
   "source": [
    "iso = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "iso.fit(p_cal_raw, y_cal)\n",
    "\n",
    "p_test_iso = iso.predict(p_test_raw)\n",
    "\n",
    "print(\"=== XGB calibrado (Isotonic) ===\")\n",
    "print(\"AUC:\", roc_auc_score(y_test, p_test_iso))\n",
    "print(\"PR-AUC:\", average_precision_score(y_test, p_test_iso))\n",
    "print(\"LogLoss:\", log_loss(y_test, p_test_iso))\n",
    "print(\"Brier:\", brier_score_loss(y_test, p_test_iso))\n",
    "print(\"RR real test:\", float(y_test.mean()))\n",
    "print(\"RR pred test:\", float(np.mean(p_test_iso)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5807c63e-7e26-4a74-933c-0ad04ed743ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP peor (residual alto):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_producto</th>\n",
       "      <th>categoria</th>\n",
       "      <th>n</th>\n",
       "      <th>rr_real</th>\n",
       "      <th>rr_pred</th>\n",
       "      <th>residual</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P060</td>\n",
       "      <td>sudadera</td>\n",
       "      <td>2986</td>\n",
       "      <td>0.359009</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.055008</td>\n",
       "      <td>1.180949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>P069</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>3207</td>\n",
       "      <td>0.435610</td>\n",
       "      <td>0.388354</td>\n",
       "      <td>0.047256</td>\n",
       "      <td>1.121682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P058</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>10660</td>\n",
       "      <td>0.401220</td>\n",
       "      <td>0.385203</td>\n",
       "      <td>0.016016</td>\n",
       "      <td>1.041578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>P065</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>4098</td>\n",
       "      <td>0.344802</td>\n",
       "      <td>0.331183</td>\n",
       "      <td>0.013619</td>\n",
       "      <td>1.041122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>P063</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>3050</td>\n",
       "      <td>0.261311</td>\n",
       "      <td>0.250290</td>\n",
       "      <td>0.011022</td>\n",
       "      <td>1.044035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>10841</td>\n",
       "      <td>0.259293</td>\n",
       "      <td>0.250112</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>1.036709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P059</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>3027</td>\n",
       "      <td>0.394780</td>\n",
       "      <td>0.387626</td>\n",
       "      <td>0.007154</td>\n",
       "      <td>1.018457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P006</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>10903</td>\n",
       "      <td>0.264698</td>\n",
       "      <td>0.257756</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>1.026931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P042</td>\n",
       "      <td>camisa</td>\n",
       "      <td>11017</td>\n",
       "      <td>0.553690</td>\n",
       "      <td>0.552786</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>1.001634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P004</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>10814</td>\n",
       "      <td>0.326891</td>\n",
       "      <td>0.326202</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>1.002112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P008</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>13691</td>\n",
       "      <td>0.349865</td>\n",
       "      <td>0.349344</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>1.001492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P047</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>11004</td>\n",
       "      <td>0.625863</td>\n",
       "      <td>0.626275</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>0.999343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P016</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>10848</td>\n",
       "      <td>0.220409</td>\n",
       "      <td>0.222784</td>\n",
       "      <td>-0.002374</td>\n",
       "      <td>0.989342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>13442</td>\n",
       "      <td>0.250186</td>\n",
       "      <td>0.255119</td>\n",
       "      <td>-0.004933</td>\n",
       "      <td>0.980665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P003</td>\n",
       "      <td>sudadera</td>\n",
       "      <td>13760</td>\n",
       "      <td>0.298038</td>\n",
       "      <td>0.303753</td>\n",
       "      <td>-0.005716</td>\n",
       "      <td>0.981184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_producto categoria      n   rr_real   rr_pred  residual      lift\n",
       "15        P060  sudadera   2986  0.359009  0.304000  0.055008  1.180949\n",
       "21        P069    abrigo   3207  0.435610  0.388354  0.047256  1.121682\n",
       "13        P058    abrigo  10660  0.401220  0.385203  0.016016  1.041578\n",
       "19        P065  pantalon   4098  0.344802  0.331183  0.013619  1.041122\n",
       "17        P063  camiseta   3050  0.261311  0.250290  0.011022  1.044035\n",
       "0         P001  camiseta  10841  0.259293  0.250112  0.009181  1.036709\n",
       "14        P059    abrigo   3027  0.394780  0.387626  0.007154  1.018457\n",
       "5         P006  camiseta  10903  0.264698  0.257756  0.006942  1.026931\n",
       "11        P042    camisa  11017  0.553690  0.552786  0.000903  1.001634\n",
       "3         P004  pantalon  10814  0.326891  0.326202  0.000689  1.002112\n",
       "6         P008  pantalon  13691  0.349865  0.349344  0.000521  1.001492\n",
       "12        P047    abrigo  11004  0.625863  0.626275 -0.000411  0.999343\n",
       "8         P016  camiseta  10848  0.220409  0.222784 -0.002374  0.989342\n",
       "1         P002  camiseta  13442  0.250186  0.255119 -0.004933  0.980665\n",
       "2         P003  sudadera  13760  0.298038  0.303753 -0.005716  0.981184"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP mejor (residual bajo):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_producto</th>\n",
       "      <th>categoria</th>\n",
       "      <th>n</th>\n",
       "      <th>rr_real</th>\n",
       "      <th>rr_pred</th>\n",
       "      <th>residual</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>P066</td>\n",
       "      <td>camisa</td>\n",
       "      <td>3052</td>\n",
       "      <td>0.330931</td>\n",
       "      <td>0.358334</td>\n",
       "      <td>-0.027403</td>\n",
       "      <td>0.923526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P020</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>10665</td>\n",
       "      <td>0.372433</td>\n",
       "      <td>0.394179</td>\n",
       "      <td>-0.021746</td>\n",
       "      <td>0.944832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P005</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>10722</td>\n",
       "      <td>0.333054</td>\n",
       "      <td>0.344757</td>\n",
       "      <td>-0.011703</td>\n",
       "      <td>0.966054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>P064</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>6946</td>\n",
       "      <td>0.240858</td>\n",
       "      <td>0.252320</td>\n",
       "      <td>-0.011462</td>\n",
       "      <td>0.954572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>P062</td>\n",
       "      <td>camisa</td>\n",
       "      <td>3130</td>\n",
       "      <td>0.346006</td>\n",
       "      <td>0.355434</td>\n",
       "      <td>-0.009428</td>\n",
       "      <td>0.973475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P013</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>13200</td>\n",
       "      <td>0.361364</td>\n",
       "      <td>0.370695</td>\n",
       "      <td>-0.009331</td>\n",
       "      <td>0.974828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P024</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>10891</td>\n",
       "      <td>0.316867</td>\n",
       "      <td>0.325148</td>\n",
       "      <td>-0.008281</td>\n",
       "      <td>0.974533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P003</td>\n",
       "      <td>sudadera</td>\n",
       "      <td>13760</td>\n",
       "      <td>0.298038</td>\n",
       "      <td>0.303753</td>\n",
       "      <td>-0.005716</td>\n",
       "      <td>0.981184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>13442</td>\n",
       "      <td>0.250186</td>\n",
       "      <td>0.255119</td>\n",
       "      <td>-0.004933</td>\n",
       "      <td>0.980665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P016</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>10848</td>\n",
       "      <td>0.220409</td>\n",
       "      <td>0.222784</td>\n",
       "      <td>-0.002374</td>\n",
       "      <td>0.989342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P047</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>11004</td>\n",
       "      <td>0.625863</td>\n",
       "      <td>0.626275</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>0.999343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P008</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>13691</td>\n",
       "      <td>0.349865</td>\n",
       "      <td>0.349344</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>1.001492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P004</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>10814</td>\n",
       "      <td>0.326891</td>\n",
       "      <td>0.326202</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>1.002112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P042</td>\n",
       "      <td>camisa</td>\n",
       "      <td>11017</td>\n",
       "      <td>0.553690</td>\n",
       "      <td>0.552786</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>1.001634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P006</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>10903</td>\n",
       "      <td>0.264698</td>\n",
       "      <td>0.257756</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>1.026931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_producto categoria      n   rr_real   rr_pred  residual      lift\n",
       "20        P066    camisa   3052  0.330931  0.358334 -0.027403  0.923526\n",
       "9         P020    abrigo  10665  0.372433  0.394179 -0.021746  0.944832\n",
       "4         P005    abrigo  10722  0.333054  0.344757 -0.011703  0.966054\n",
       "18        P064  camiseta   6946  0.240858  0.252320 -0.011462  0.954572\n",
       "16        P062    camisa   3130  0.346006  0.355434 -0.009428  0.973475\n",
       "7         P013    abrigo  13200  0.361364  0.370695 -0.009331  0.974828\n",
       "10        P024  pantalon  10891  0.316867  0.325148 -0.008281  0.974533\n",
       "2         P003  sudadera  13760  0.298038  0.303753 -0.005716  0.981184\n",
       "1         P002  camiseta  13442  0.250186  0.255119 -0.004933  0.980665\n",
       "8         P016  camiseta  10848  0.220409  0.222784 -0.002374  0.989342\n",
       "12        P047    abrigo  11004  0.625863  0.626275 -0.000411  0.999343\n",
       "6         P008  pantalon  13691  0.349865  0.349344  0.000521  1.001492\n",
       "3         P004  pantalon  10814  0.326891  0.326202  0.000689  1.002112\n",
       "11        P042    camisa  11017  0.553690  0.552786  0.000903  1.001634\n",
       "5         P006  camiseta  10903  0.264698  0.257756  0.006942  1.026931"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP peor (lift alto):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_producto</th>\n",
       "      <th>categoria</th>\n",
       "      <th>n</th>\n",
       "      <th>rr_real</th>\n",
       "      <th>rr_pred</th>\n",
       "      <th>residual</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P060</td>\n",
       "      <td>sudadera</td>\n",
       "      <td>2986</td>\n",
       "      <td>0.359009</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.055008</td>\n",
       "      <td>1.180949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>P069</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>3207</td>\n",
       "      <td>0.435610</td>\n",
       "      <td>0.388354</td>\n",
       "      <td>0.047256</td>\n",
       "      <td>1.121682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>P063</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>3050</td>\n",
       "      <td>0.261311</td>\n",
       "      <td>0.250290</td>\n",
       "      <td>0.011022</td>\n",
       "      <td>1.044035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P058</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>10660</td>\n",
       "      <td>0.401220</td>\n",
       "      <td>0.385203</td>\n",
       "      <td>0.016016</td>\n",
       "      <td>1.041578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>P065</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>4098</td>\n",
       "      <td>0.344802</td>\n",
       "      <td>0.331183</td>\n",
       "      <td>0.013619</td>\n",
       "      <td>1.041122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>10841</td>\n",
       "      <td>0.259293</td>\n",
       "      <td>0.250112</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>1.036709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P006</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>10903</td>\n",
       "      <td>0.264698</td>\n",
       "      <td>0.257756</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>1.026931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P059</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>3027</td>\n",
       "      <td>0.394780</td>\n",
       "      <td>0.387626</td>\n",
       "      <td>0.007154</td>\n",
       "      <td>1.018457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P004</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>10814</td>\n",
       "      <td>0.326891</td>\n",
       "      <td>0.326202</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>1.002112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P042</td>\n",
       "      <td>camisa</td>\n",
       "      <td>11017</td>\n",
       "      <td>0.553690</td>\n",
       "      <td>0.552786</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>1.001634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P008</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>13691</td>\n",
       "      <td>0.349865</td>\n",
       "      <td>0.349344</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>1.001492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P047</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>11004</td>\n",
       "      <td>0.625863</td>\n",
       "      <td>0.626275</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>0.999343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P016</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>10848</td>\n",
       "      <td>0.220409</td>\n",
       "      <td>0.222784</td>\n",
       "      <td>-0.002374</td>\n",
       "      <td>0.989342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P003</td>\n",
       "      <td>sudadera</td>\n",
       "      <td>13760</td>\n",
       "      <td>0.298038</td>\n",
       "      <td>0.303753</td>\n",
       "      <td>-0.005716</td>\n",
       "      <td>0.981184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>13442</td>\n",
       "      <td>0.250186</td>\n",
       "      <td>0.255119</td>\n",
       "      <td>-0.004933</td>\n",
       "      <td>0.980665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_producto categoria      n   rr_real   rr_pred  residual      lift\n",
       "15        P060  sudadera   2986  0.359009  0.304000  0.055008  1.180949\n",
       "21        P069    abrigo   3207  0.435610  0.388354  0.047256  1.121682\n",
       "17        P063  camiseta   3050  0.261311  0.250290  0.011022  1.044035\n",
       "13        P058    abrigo  10660  0.401220  0.385203  0.016016  1.041578\n",
       "19        P065  pantalon   4098  0.344802  0.331183  0.013619  1.041122\n",
       "0         P001  camiseta  10841  0.259293  0.250112  0.009181  1.036709\n",
       "5         P006  camiseta  10903  0.264698  0.257756  0.006942  1.026931\n",
       "14        P059    abrigo   3027  0.394780  0.387626  0.007154  1.018457\n",
       "3         P004  pantalon  10814  0.326891  0.326202  0.000689  1.002112\n",
       "11        P042    camisa  11017  0.553690  0.552786  0.000903  1.001634\n",
       "6         P008  pantalon  13691  0.349865  0.349344  0.000521  1.001492\n",
       "12        P047    abrigo  11004  0.625863  0.626275 -0.000411  0.999343\n",
       "8         P016  camiseta  10848  0.220409  0.222784 -0.002374  0.989342\n",
       "2         P003  sudadera  13760  0.298038  0.303753 -0.005716  0.981184\n",
       "1         P002  camiseta  13442  0.250186  0.255119 -0.004933  0.980665"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP mejor (lift bajo):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_producto</th>\n",
       "      <th>categoria</th>\n",
       "      <th>n</th>\n",
       "      <th>rr_real</th>\n",
       "      <th>rr_pred</th>\n",
       "      <th>residual</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>P066</td>\n",
       "      <td>camisa</td>\n",
       "      <td>3052</td>\n",
       "      <td>0.330931</td>\n",
       "      <td>0.358334</td>\n",
       "      <td>-0.027403</td>\n",
       "      <td>0.923526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P020</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>10665</td>\n",
       "      <td>0.372433</td>\n",
       "      <td>0.394179</td>\n",
       "      <td>-0.021746</td>\n",
       "      <td>0.944832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>P064</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>6946</td>\n",
       "      <td>0.240858</td>\n",
       "      <td>0.252320</td>\n",
       "      <td>-0.011462</td>\n",
       "      <td>0.954572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P005</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>10722</td>\n",
       "      <td>0.333054</td>\n",
       "      <td>0.344757</td>\n",
       "      <td>-0.011703</td>\n",
       "      <td>0.966054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>P062</td>\n",
       "      <td>camisa</td>\n",
       "      <td>3130</td>\n",
       "      <td>0.346006</td>\n",
       "      <td>0.355434</td>\n",
       "      <td>-0.009428</td>\n",
       "      <td>0.973475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P024</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>10891</td>\n",
       "      <td>0.316867</td>\n",
       "      <td>0.325148</td>\n",
       "      <td>-0.008281</td>\n",
       "      <td>0.974533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P013</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>13200</td>\n",
       "      <td>0.361364</td>\n",
       "      <td>0.370695</td>\n",
       "      <td>-0.009331</td>\n",
       "      <td>0.974828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>13442</td>\n",
       "      <td>0.250186</td>\n",
       "      <td>0.255119</td>\n",
       "      <td>-0.004933</td>\n",
       "      <td>0.980665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P003</td>\n",
       "      <td>sudadera</td>\n",
       "      <td>13760</td>\n",
       "      <td>0.298038</td>\n",
       "      <td>0.303753</td>\n",
       "      <td>-0.005716</td>\n",
       "      <td>0.981184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P016</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>10848</td>\n",
       "      <td>0.220409</td>\n",
       "      <td>0.222784</td>\n",
       "      <td>-0.002374</td>\n",
       "      <td>0.989342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P047</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>11004</td>\n",
       "      <td>0.625863</td>\n",
       "      <td>0.626275</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>0.999343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P008</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>13691</td>\n",
       "      <td>0.349865</td>\n",
       "      <td>0.349344</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>1.001492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P042</td>\n",
       "      <td>camisa</td>\n",
       "      <td>11017</td>\n",
       "      <td>0.553690</td>\n",
       "      <td>0.552786</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>1.001634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P004</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>10814</td>\n",
       "      <td>0.326891</td>\n",
       "      <td>0.326202</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>1.002112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P059</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>3027</td>\n",
       "      <td>0.394780</td>\n",
       "      <td>0.387626</td>\n",
       "      <td>0.007154</td>\n",
       "      <td>1.018457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_producto categoria      n   rr_real   rr_pred  residual      lift\n",
       "20        P066    camisa   3052  0.330931  0.358334 -0.027403  0.923526\n",
       "9         P020    abrigo  10665  0.372433  0.394179 -0.021746  0.944832\n",
       "18        P064  camiseta   6946  0.240858  0.252320 -0.011462  0.954572\n",
       "4         P005    abrigo  10722  0.333054  0.344757 -0.011703  0.966054\n",
       "16        P062    camisa   3130  0.346006  0.355434 -0.009428  0.973475\n",
       "10        P024  pantalon  10891  0.316867  0.325148 -0.008281  0.974533\n",
       "7         P013    abrigo  13200  0.361364  0.370695 -0.009331  0.974828\n",
       "1         P002  camiseta  13442  0.250186  0.255119 -0.004933  0.980665\n",
       "2         P003  sudadera  13760  0.298038  0.303753 -0.005716  0.981184\n",
       "8         P016  camiseta  10848  0.220409  0.222784 -0.002374  0.989342\n",
       "12        P047    abrigo  11004  0.625863  0.626275 -0.000411  0.999343\n",
       "6         P008  pantalon  13691  0.349865  0.349344  0.000521  1.001492\n",
       "11        P042    camisa  11017  0.553690  0.552786  0.000903  1.001634\n",
       "3         P004  pantalon  10814  0.326891  0.326202  0.000689  1.002112\n",
       "14        P059    abrigo   3027  0.394780  0.387626  0.007154  1.018457"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_scored = test_df2.copy()\n",
    "\n",
    "# Selecciona aquí el score final que vas a usar\n",
    "test_scored[\"p_dev\"] = p_test_platt  # alternativa: p_test_iso\n",
    "\n",
    "prod_eval = (\n",
    "    test_scored\n",
    "    .groupby([\"id_producto\", \"categoria\"], as_index=False)\n",
    "    .agg(\n",
    "        n=(\"devuelto\", \"size\"),\n",
    "        rr_real=(\"devuelto\", \"mean\"),\n",
    "        rr_pred=(\"p_dev\", \"mean\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "prod_eval[\"residual\"] = prod_eval[\"rr_real\"] - prod_eval[\"rr_pred\"]\n",
    "prod_eval[\"lift\"] = prod_eval[\"rr_real\"] / (prod_eval[\"rr_pred\"] + 1e-9)\n",
    "\n",
    "prod_eval_big = prod_eval[prod_eval[\"n\"] >= 500].copy()\n",
    "\n",
    "print(\"TOP peor (residual alto):\")\n",
    "display(prod_eval_big.sort_values(\"residual\", ascending=False).head(15))\n",
    "\n",
    "print(\"TOP mejor (residual bajo):\")\n",
    "display(prod_eval_big.sort_values(\"residual\", ascending=True).head(15))\n",
    "\n",
    "print(\"TOP peor (lift alto):\")\n",
    "display(prod_eval_big.sort_values(\"lift\", ascending=False).head(15))\n",
    "\n",
    "print(\"TOP mejor (lift bajo):\")\n",
    "display(prod_eval_big.sort_values(\"lift\", ascending=True).head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "20047c8b-99e1-42eb-bbda-375395a5f6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo y artefactos guardados en: modelos/xgb_devoluciones\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"modelos\", exist_ok=True)\n",
    "os.makedirs(\"modelos/xgb_devoluciones\", exist_ok=True)\n",
    "\n",
    "MODEL_DIR = \"modelos/xgb_devoluciones\"\n",
    "\n",
    "# Booster (XGBoost)\n",
    "booster.save_model(os.path.join(MODEL_DIR, \"xgb_booster.json\"))\n",
    "\n",
    "# Preprocesado y calibradores\n",
    "import pickle\n",
    "with open(os.path.join(MODEL_DIR, \"preprocess.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(preprocess, f)\n",
    "\n",
    "with open(os.path.join(MODEL_DIR, \"platt.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(platt, f)\n",
    "\n",
    "with open(os.path.join(MODEL_DIR, \"isotonic.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(iso, f)\n",
    "\n",
    "# Perfil de producto entrenado en train\n",
    "train_artifacts = {\n",
    "    \"prod_profile_train\": prod_profile_train,\n",
    "}\n",
    "with open(os.path.join(MODEL_DIR, \"prod_profile_train.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(train_artifacts, f)\n",
    "\n",
    "with open(os.path.join(MODEL_DIR, \"prod_meta_train.json\"), \"w\") as f:\n",
    "    json.dump(prod_meta_train, f, indent=2)\n",
    "\n",
    "# Configuración mínima para reproducibilidad\n",
    "config = {\n",
    "    \"cut_train_end\": str(cut_train_end.date()),\n",
    "    \"cut_calib_end\": str(cut_calib_end.date()),\n",
    "    \"target\": TARGET,\n",
    "    \"cat_features\": cat_features,\n",
    "    \"num_features\": num_features,\n",
    "    \"xgb_params\": params,\n",
    "    \"best_iteration\": int(getattr(booster, \"best_iteration\", -1)),\n",
    "}\n",
    "with open(os.path.join(MODEL_DIR, \"config.json\"), \"w\") as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"Modelo y artefactos guardados en: {MODEL_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acb7e81-5185-4501-a418-ba8c92192da0",
   "metadata": {},
   "source": [
    "# recomendador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92823b5d-27d4-4968-bcf6-b60035b0874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp_idx(idx: int, lo: int = 0, hi: int | None = None) -> int:\n",
    "    \"\"\"Asegura que un índice de talla cae dentro del rango permitido.\"\"\"\n",
    "    if hi is None:\n",
    "        hi = len(TALLAS_ROPA) - 1\n",
    "    return int(max(lo, min(hi, int(idx))))\n",
    "\n",
    "\n",
    "def make_candidates(ideal_idx: int, max_step: int = 2) -> list[str]:\n",
    "    \"\"\"\n",
    "    Genera tallas candidatas alrededor de la talla ideal, restringiendo el salto\n",
    "    máximo permitido.\n",
    "    \"\"\"\n",
    "    lo = clamp_idx(ideal_idx - max_step)\n",
    "    hi = clamp_idx(ideal_idx + max_step)\n",
    "    return [IDX_TO_TALLA[i] for i in range(lo, hi + 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "684975d2-f412-45a3-a8a1-cb1b4b401d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_rows(df_rows: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Puntúa filas con el modelo de devoluciones y devuelve p_dev calibrada.\n",
    "\n",
    "    Requiere en el entorno:\n",
    "      - cat_features, num_features\n",
    "      - preprocess (ColumnTransformer)\n",
    "      - booster (xgboost Booster)\n",
    "      - iso (IsotonicRegression)\n",
    "    \"\"\"\n",
    "    X = df_rows[cat_features + num_features].copy()\n",
    "    Xmat = preprocess.transform(X)\n",
    "\n",
    "    dmat = xgb.DMatrix(Xmat)\n",
    "\n",
    "    try:\n",
    "        p_raw = booster.predict(dmat, iteration_range=(0, booster.best_iteration + 1))\n",
    "    except TypeError:\n",
    "        p_raw = booster.predict(dmat, ntree_limit=getattr(booster, \"best_ntree_limit\", 0) or 0)\n",
    "\n",
    "    return iso.predict(p_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6b9df1f2-8e55-465c-9b71-3f8895368b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_scenarios(df_base: pd.DataFrame, max_step: int = 2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Expande cada compra en múltiples escenarios (uno por talla candidata).\n",
    "\n",
    "    Solo recalcula variables dependientes de la talla:\n",
    "      - talla, talla_idx\n",
    "      - desajuste, desajuste_abs\n",
    "      - talla_extrema\n",
    "\n",
    "    Mantiene fijo:\n",
    "      - ideal_idx\n",
    "      - variables corporales (altura/peso/bmi)\n",
    "      - perfil de producto (prod_*)\n",
    "      - categoría / id_producto\n",
    "    \"\"\"\n",
    "    if \"ideal_idx\" not in df_base.columns:\n",
    "        raise ValueError(\"df_base debe contener la columna ideal_idx.\")\n",
    "\n",
    "    base = df_base.copy().reset_index(drop=False).rename(columns={\"index\": \"_orig_idx\"})\n",
    "\n",
    "    cands = base[\"ideal_idx\"].apply(lambda i: make_candidates(int(i), max_step=max_step))\n",
    "\n",
    "    scen = base.loc[base.index.repeat(cands.str.len())].copy()\n",
    "    scen[\"talla\"] = np.concatenate(cands.values)\n",
    "\n",
    "    scen[\"talla_idx\"] = scen[\"talla\"].map(TALLA_TO_IDX).astype(\"int8\")\n",
    "    scen[\"desajuste\"] = (scen[\"talla_idx\"].astype(int) - scen[\"ideal_idx\"].astype(int)).astype(\"int16\")\n",
    "    scen[\"desajuste_abs\"] = scen[\"desajuste\"].abs().astype(\"int16\")\n",
    "    scen[\"talla_extrema\"] = scen[\"talla\"].isin([\"XS\", \"XL\"]).astype(\"int8\")\n",
    "\n",
    "    return scen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd9abc42-7317-4a01-9530-abb7a2e71d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_sizes(\n",
    "    df_base: pd.DataFrame,\n",
    "    max_step: int = 2,\n",
    "    min_gain: float = 0.01,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Recomienda la talla que minimiza p_dev dentro del vecindario de la talla ideal.\n",
    "\n",
    "    min_gain controla la histeresis:\n",
    "      - si la mejora esperada (delta_p) es menor que min_gain, se mantiene la talla actual.\n",
    "\n",
    "    Devuelve:\n",
    "      - recs: 1 fila por compra con recomendación y métricas\n",
    "      - scen_scored: escenarios con p_dev por talla (útil para auditoría)\n",
    "    \"\"\"\n",
    "    scen = build_scenarios(df_base, max_step=max_step)\n",
    "    scen[\"p_dev\"] = score_rows(scen).astype(\"float32\")\n",
    "\n",
    "    best = (\n",
    "        scen.sort_values([\"_orig_idx\", \"p_dev\"], ascending=[True, True])\n",
    "            .groupby(\"_orig_idx\", as_index=False)\n",
    "            .head(1)\n",
    "            .rename(columns={\"talla\": \"talla_reco\", \"p_dev\": \"p_dev_reco\"})\n",
    "    )\n",
    "\n",
    "    base_scored = df_base.copy().reset_index(drop=False).rename(columns={\"index\": \"_orig_idx\"})\n",
    "    base_scored[\"p_dev_actual\"] = score_rows(base_scored).astype(\"float32\")\n",
    "\n",
    "    keep_cols = [\n",
    "        \"_orig_idx\", \"id_producto\", \"categoria\", \"talla\",\n",
    "        \"altura_cm\", \"peso_kg\", \"ideal_idx\", \"devuelto\", \"p_dev_actual\"\n",
    "    ]\n",
    "\n",
    "    recs = (\n",
    "        base_scored[keep_cols]\n",
    "        .merge(\n",
    "            best[[\"_orig_idx\", \"talla_reco\", \"p_dev_reco\", \"desajuste\", \"desajuste_abs\"]],\n",
    "            on=\"_orig_idx\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    recs[\"delta_p\"] = (recs[\"p_dev_actual\"] - recs[\"p_dev_reco\"]).astype(\"float32\")\n",
    "    recs[\"cambia_talla_raw\"] = (recs[\"talla\"] != recs[\"talla_reco\"]).astype(\"int8\")\n",
    "\n",
    "    # Regla de decisión final (evita cambios por ruido)\n",
    "    recs[\"talla_final\"] = np.where(\n",
    "        recs[\"delta_p\"] >= float(min_gain),\n",
    "        recs[\"talla_reco\"],\n",
    "        recs[\"talla\"],\n",
    "    )\n",
    "    recs[\"cambia_talla\"] = (recs[\"talla_final\"] != recs[\"talla\"]).astype(\"int8\")\n",
    "\n",
    "    # p_dev final esperado (si cambio aplico p_dev_reco; si no, p_dev_actual)\n",
    "    recs[\"p_dev_final\"] = np.where(\n",
    "        recs[\"cambia_talla\"] == 1,\n",
    "        recs[\"p_dev_reco\"],\n",
    "        recs[\"p_dev_actual\"],\n",
    "    ).astype(\"float32\")\n",
    "\n",
    "    recs[\"delta_p_final\"] = (recs[\"p_dev_actual\"] - recs[\"p_dev_final\"]).astype(\"float32\")\n",
    "\n",
    "    return recs, scen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e2e2d222-8e2d-4738-843d-9a12bbade7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejora media esperada (delta_p_final): 0.034451983869075775\n",
      "Pct compras donde cambia talla: 0.17905\n",
      "Mejora media esperada SOLO donde cambia: 0.19241543114185333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_orig_idx</th>\n",
       "      <th>id_producto</th>\n",
       "      <th>categoria</th>\n",
       "      <th>talla</th>\n",
       "      <th>altura_cm</th>\n",
       "      <th>peso_kg</th>\n",
       "      <th>ideal_idx</th>\n",
       "      <th>devuelto</th>\n",
       "      <th>p_dev_actual</th>\n",
       "      <th>talla_reco</th>\n",
       "      <th>p_dev_reco</th>\n",
       "      <th>desajuste</th>\n",
       "      <th>desajuste_abs</th>\n",
       "      <th>delta_p</th>\n",
       "      <th>cambia_talla_raw</th>\n",
       "      <th>talla_final</th>\n",
       "      <th>cambia_talla</th>\n",
       "      <th>p_dev_final</th>\n",
       "      <th>delta_p_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10030</th>\n",
       "      <td>39654</td>\n",
       "      <td>P024</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>S</td>\n",
       "      <td>177.8</td>\n",
       "      <td>81.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>L</td>\n",
       "      <td>0.277466</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.676022</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277466</td>\n",
       "      <td>0.676022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>1865</td>\n",
       "      <td>P024</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>L</td>\n",
       "      <td>162.8</td>\n",
       "      <td>60.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>S</td>\n",
       "      <td>0.259179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629710</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0.259179</td>\n",
       "      <td>0.629710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18270</th>\n",
       "      <td>119804</td>\n",
       "      <td>P058</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>S</td>\n",
       "      <td>181.7</td>\n",
       "      <td>92.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>L</td>\n",
       "      <td>0.327632</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625856</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>0.327632</td>\n",
       "      <td>0.625856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8150</th>\n",
       "      <td>155260</td>\n",
       "      <td>P004</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>S</td>\n",
       "      <td>183.8</td>\n",
       "      <td>95.4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>L</td>\n",
       "      <td>0.272097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.616791</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>0.272097</td>\n",
       "      <td>0.616791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9675</th>\n",
       "      <td>74343</td>\n",
       "      <td>P008</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>L</td>\n",
       "      <td>168.8</td>\n",
       "      <td>66.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>S</td>\n",
       "      <td>0.300976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.587913</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0.300976</td>\n",
       "      <td>0.587913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4022</th>\n",
       "      <td>126006</td>\n",
       "      <td>P005</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>M</td>\n",
       "      <td>157.5</td>\n",
       "      <td>60.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>XS</td>\n",
       "      <td>0.300976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.587913</td>\n",
       "      <td>1</td>\n",
       "      <td>XS</td>\n",
       "      <td>1</td>\n",
       "      <td>0.300976</td>\n",
       "      <td>0.587913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7978</th>\n",
       "      <td>179664</td>\n",
       "      <td>P004</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>XL</td>\n",
       "      <td>169.7</td>\n",
       "      <td>73.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>M</td>\n",
       "      <td>0.277466</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573598</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277466</td>\n",
       "      <td>0.573598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15962</th>\n",
       "      <td>50623</td>\n",
       "      <td>P024</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>L</td>\n",
       "      <td>167.1</td>\n",
       "      <td>66.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>S</td>\n",
       "      <td>0.277466</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573598</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277466</td>\n",
       "      <td>0.573598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>50625</td>\n",
       "      <td>P024</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>L</td>\n",
       "      <td>167.1</td>\n",
       "      <td>66.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>S</td>\n",
       "      <td>0.277466</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573598</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277466</td>\n",
       "      <td>0.573598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6562</th>\n",
       "      <td>161920</td>\n",
       "      <td>P064</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>XL</td>\n",
       "      <td>173.3</td>\n",
       "      <td>78.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>M</td>\n",
       "      <td>0.229630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.565551</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229630</td>\n",
       "      <td>0.565551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16997</th>\n",
       "      <td>65894</td>\n",
       "      <td>P013</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>XL</td>\n",
       "      <td>176.3</td>\n",
       "      <td>83.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>M</td>\n",
       "      <td>0.327632</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561257</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0.327632</td>\n",
       "      <td>0.561257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16602</th>\n",
       "      <td>5601</td>\n",
       "      <td>P058</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>M</td>\n",
       "      <td>157.7</td>\n",
       "      <td>57.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>XS</td>\n",
       "      <td>0.398701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.554788</td>\n",
       "      <td>1</td>\n",
       "      <td>XS</td>\n",
       "      <td>1</td>\n",
       "      <td>0.398701</td>\n",
       "      <td>0.554788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12035</th>\n",
       "      <td>94980</td>\n",
       "      <td>P003</td>\n",
       "      <td>sudadera</td>\n",
       "      <td>M</td>\n",
       "      <td>199.2</td>\n",
       "      <td>118.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>XL</td>\n",
       "      <td>0.300976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.550088</td>\n",
       "      <td>1</td>\n",
       "      <td>XL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.300976</td>\n",
       "      <td>0.550088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12342</th>\n",
       "      <td>179665</td>\n",
       "      <td>P003</td>\n",
       "      <td>sudadera</td>\n",
       "      <td>XL</td>\n",
       "      <td>169.7</td>\n",
       "      <td>73.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>M</td>\n",
       "      <td>0.259179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.536001</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0.259179</td>\n",
       "      <td>0.536001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9696</th>\n",
       "      <td>70911</td>\n",
       "      <td>P047</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>XL</td>\n",
       "      <td>185.0</td>\n",
       "      <td>74.7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>S</td>\n",
       "      <td>0.327632</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.524220</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0.327632</td>\n",
       "      <td>0.524220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16329</th>\n",
       "      <td>30644</td>\n",
       "      <td>P058</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>XL</td>\n",
       "      <td>176.2</td>\n",
       "      <td>73.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>M</td>\n",
       "      <td>0.327632</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523432</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0.327632</td>\n",
       "      <td>0.523432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9194</th>\n",
       "      <td>161918</td>\n",
       "      <td>P001</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>XL</td>\n",
       "      <td>173.3</td>\n",
       "      <td>78.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736746</td>\n",
       "      <td>M</td>\n",
       "      <td>0.229630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.507116</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229630</td>\n",
       "      <td>0.507116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>137146</td>\n",
       "      <td>P008</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>L</td>\n",
       "      <td>163.8</td>\n",
       "      <td>67.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>S</td>\n",
       "      <td>0.349717</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.495353</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0.349717</td>\n",
       "      <td>0.495353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202</th>\n",
       "      <td>125365</td>\n",
       "      <td>P005</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>XL</td>\n",
       "      <td>184.8</td>\n",
       "      <td>85.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>L</td>\n",
       "      <td>0.300976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.494205</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>0.300976</td>\n",
       "      <td>0.494205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4066</th>\n",
       "      <td>51594</td>\n",
       "      <td>P003</td>\n",
       "      <td>sudadera</td>\n",
       "      <td>M</td>\n",
       "      <td>190.0</td>\n",
       "      <td>105.6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>XL</td>\n",
       "      <td>0.300976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.494205</td>\n",
       "      <td>1</td>\n",
       "      <td>XL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.300976</td>\n",
       "      <td>0.494205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       _orig_idx id_producto categoria talla  altura_cm  peso_kg  ideal_idx  \\\n",
       "10030      39654        P024  pantalon     S      177.8     81.5          3   \n",
       "2897        1865        P024  pantalon     L      162.8     60.4          1   \n",
       "18270     119804        P058    abrigo     S      181.7     92.3          3   \n",
       "8150      155260        P004  pantalon     S      183.8     95.4          3   \n",
       "9675       74343        P008  pantalon     L      168.8     66.5          1   \n",
       "4022      126006        P005    abrigo     M      157.5     60.7          0   \n",
       "7978      179664        P004  pantalon    XL      169.7     73.2          2   \n",
       "15962      50623        P024  pantalon     L      167.1     66.6          1   \n",
       "2075       50625        P024  pantalon     L      167.1     66.6          1   \n",
       "6562      161920        P064  camiseta    XL      173.3     78.6          2   \n",
       "16997      65894        P013    abrigo    XL      176.3     83.8          2   \n",
       "16602       5601        P058    abrigo     M      157.7     57.8          0   \n",
       "12035      94980        P003  sudadera     M      199.2    118.0          4   \n",
       "12342     179665        P003  sudadera    XL      169.7     73.2          2   \n",
       "9696       70911        P047    abrigo    XL      185.0     74.7          3   \n",
       "16329      30644        P058    abrigo    XL      176.2     73.6          2   \n",
       "9194      161918        P001  camiseta    XL      173.3     78.6          2   \n",
       "3055      137146        P008  pantalon     L      163.8     67.5          1   \n",
       "6202      125365        P005    abrigo    XL      184.8     85.3          3   \n",
       "4066       51594        P003  sudadera     M      190.0    105.6          4   \n",
       "\n",
       "       devuelto  p_dev_actual talla_reco  p_dev_reco  desajuste  \\\n",
       "10030         1      0.953488          L    0.277466          0   \n",
       "2897          1      0.888889          S    0.259179          0   \n",
       "18270         1      0.953488          L    0.327632          0   \n",
       "8150          1      0.888889          L    0.272097          0   \n",
       "9675          0      0.888889          S    0.300976          0   \n",
       "4022          1      0.888889         XS    0.300976          0   \n",
       "7978          1      0.851064          M    0.277466          0   \n",
       "15962         1      0.851064          S    0.277466          0   \n",
       "2075          1      0.851064          S    0.277466          0   \n",
       "6562          1      0.795181          M    0.229630          0   \n",
       "16997         1      0.888889          M    0.327632          0   \n",
       "16602         1      0.953488         XS    0.398701          0   \n",
       "12035         1      0.851064         XL    0.300976          0   \n",
       "12342         1      0.795181          M    0.259179          0   \n",
       "9696          1      0.851852          S    0.327632         -2   \n",
       "16329         1      0.851064          M    0.327632          0   \n",
       "9194          1      0.736746          M    0.229630          0   \n",
       "3055          1      0.845070          S    0.349717          0   \n",
       "6202          1      0.795181          L    0.300976          0   \n",
       "4066          1      0.795181         XL    0.300976          0   \n",
       "\n",
       "       desajuste_abs   delta_p  cambia_talla_raw talla_final  cambia_talla  \\\n",
       "10030              0  0.676022                 1           L             1   \n",
       "2897               0  0.629710                 1           S             1   \n",
       "18270              0  0.625856                 1           L             1   \n",
       "8150               0  0.616791                 1           L             1   \n",
       "9675               0  0.587913                 1           S             1   \n",
       "4022               0  0.587913                 1          XS             1   \n",
       "7978               0  0.573598                 1           M             1   \n",
       "15962              0  0.573598                 1           S             1   \n",
       "2075               0  0.573598                 1           S             1   \n",
       "6562               0  0.565551                 1           M             1   \n",
       "16997              0  0.561257                 1           M             1   \n",
       "16602              0  0.554788                 1          XS             1   \n",
       "12035              0  0.550088                 1          XL             1   \n",
       "12342              0  0.536001                 1           M             1   \n",
       "9696               2  0.524220                 1           S             1   \n",
       "16329              0  0.523432                 1           M             1   \n",
       "9194               0  0.507116                 1           M             1   \n",
       "3055               0  0.495353                 1           S             1   \n",
       "6202               0  0.494205                 1           L             1   \n",
       "4066               0  0.494205                 1          XL             1   \n",
       "\n",
       "       p_dev_final  delta_p_final  \n",
       "10030     0.277466       0.676022  \n",
       "2897      0.259179       0.629710  \n",
       "18270     0.327632       0.625856  \n",
       "8150      0.272097       0.616791  \n",
       "9675      0.300976       0.587913  \n",
       "4022      0.300976       0.587913  \n",
       "7978      0.277466       0.573598  \n",
       "15962     0.277466       0.573598  \n",
       "2075      0.277466       0.573598  \n",
       "6562      0.229630       0.565551  \n",
       "16997     0.327632       0.561257  \n",
       "16602     0.398701       0.554788  \n",
       "12035     0.300976       0.550088  \n",
       "12342     0.259179       0.536001  \n",
       "9696      0.327632       0.524220  \n",
       "16329     0.327632       0.523432  \n",
       "9194      0.229630       0.507116  \n",
       "3055      0.349717       0.495353  \n",
       "6202      0.300976       0.494205  \n",
       "4066      0.300976       0.494205  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoria</th>\n",
       "      <th>n</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>delta_p_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abrigo</td>\n",
       "      <td>6676</td>\n",
       "      <td>0.235021</td>\n",
       "      <td>0.049749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>camisa</td>\n",
       "      <td>1820</td>\n",
       "      <td>0.356593</td>\n",
       "      <td>0.035243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pantalon</td>\n",
       "      <td>4105</td>\n",
       "      <td>0.122046</td>\n",
       "      <td>0.029020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sudadera</td>\n",
       "      <td>1651</td>\n",
       "      <td>0.119322</td>\n",
       "      <td>0.027005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>camiseta</td>\n",
       "      <td>5748</td>\n",
       "      <td>0.115692</td>\n",
       "      <td>0.022454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  categoria     n  pct_change  delta_p_mean\n",
       "0    abrigo  6676    0.235021      0.049749\n",
       "1    camisa  1820    0.356593      0.035243\n",
       "3  pantalon  4105    0.122046      0.029020\n",
       "4  sudadera  1651    0.119322      0.027005\n",
       "2  camiseta  5748    0.115692      0.022454"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_n = 20000\n",
    "test_small = test_df2.sample(sample_n, random_state=7).copy()\n",
    "\n",
    "recs, scen_scored = recommend_sizes(test_small, max_step=2, min_gain=0.01)\n",
    "\n",
    "print(\"Mejora media esperada (delta_p_final):\", float(recs[\"delta_p_final\"].mean()))\n",
    "print(\"Pct compras donde cambia talla:\", float(recs[\"cambia_talla\"].mean()))\n",
    "print(\n",
    "    \"Mejora media esperada SOLO donde cambia:\",\n",
    "    float(recs.loc[recs[\"cambia_talla\"] == 1, \"delta_p_final\"].mean())\n",
    ")\n",
    "\n",
    "display(recs.sort_values(\"delta_p_final\", ascending=False).head(20))\n",
    "\n",
    "res_cat = (\n",
    "    recs.groupby(\"categoria\", as_index=False)\n",
    "        .agg(\n",
    "            n=(\"delta_p_final\", \"size\"),\n",
    "            pct_change=(\"cambia_talla\", \"mean\"),\n",
    "            delta_p_mean=(\"delta_p_final\", \"mean\"),\n",
    "        )\n",
    "        .sort_values(\"delta_p_mean\", ascending=False)\n",
    ")\n",
    "display(res_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f093229b-d39f-4ddc-a014-0787ae745cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado completado:\n",
      "- data/processed/recs_test_small.pkl\n",
      "- data/processed/scen_test_small.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "\n",
    "recs.to_pickle(\"data/processed/recs_test_small.pkl\")\n",
    "\n",
    "# Escenarios: útil para debug, pero puede crecer mucho si aumentas sample_n\n",
    "scen_scored.to_pickle(\"data/processed/scen_test_small.pkl\")\n",
    "\n",
    "print(\"Guardado completado:\")\n",
    "print(\"- data/processed/recs_test_small.pkl\")\n",
    "print(\"- data/processed/scen_test_small.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576a0d51-5552-4227-ba1b-ce4984f60865",
   "metadata": {},
   "source": [
    "# Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "115eda7a-2e6c-4c80-9e01-4609a8e9beba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cost file cargado\n",
      "- Filas: 905,445\n",
      "- NA en coste_devolucion: 0.00%\n",
      "\n",
      " No hay duplicados por (item_id, ticket_id)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "COST_FILE = \"data/items_devoluciones_ajustadas.csv\"\n",
    "KEYS = [\"item_id\", \"ticket_id\"]\n",
    "\n",
    "items_cost = pd.read_csv(\n",
    "    COST_FILE,\n",
    "    usecols=[\"item_id\", \"ticket_id\", \"coste_devolucion\"]\n",
    ")\n",
    "\n",
    "# Normalización de claves\n",
    "for c in KEYS:\n",
    "    items_cost[c] = items_cost[c].astype(str).str.strip()\n",
    "\n",
    "# Coste a numérico\n",
    "items_cost[\"coste_devolucion\"] = pd.to_numeric(items_cost[\"coste_devolucion\"], errors=\"coerce\")\n",
    "\n",
    "print(\" Cost file cargado\")\n",
    "print(f\"- Filas: {items_cost.shape[0]:,}\")\n",
    "print(f\"- NA en coste_devolucion: {items_cost['coste_devolucion'].isna().mean():.2%}\")\n",
    "\n",
    "# Auditoría de duplicados por clave\n",
    "dup_mask = items_cost.duplicated(subset=KEYS, keep=False)\n",
    "n_dup_rows = int(dup_mask.sum())\n",
    "\n",
    "if n_dup_rows > 0:\n",
    "    n_dup_keys = items_cost.loc[dup_mask, KEYS].drop_duplicates().shape[0]\n",
    "    print(\"\\n Atención: existen claves duplicadas en el fichero de costes\")\n",
    "    print(f\"- Filas duplicadas: {n_dup_rows:,}\")\n",
    "    print(f\"- Claves únicas afectadas: {n_dup_keys:,}\")\n",
    "    print(\"Ejemplo de duplicados:\")\n",
    "    display(items_cost.loc[dup_mask].head(10))\n",
    "else:\n",
    "    print(\"\\n No hay duplicados por (item_id, ticket_id)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f12a8c9b-2477-4a59-90a7-655694558801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tabla de costes preparada para merge\n",
      "- Filas originales: 905,445\n",
      "- Filas tras resolver duplicados: 905,445\n",
      "- Filas colapsadas por duplicados: 0\n",
      "\n",
      "Resumen coste_devolucion (tabla resuelta):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    905445.000000\n",
       "mean          3.105396\n",
       "std           1.122479\n",
       "min           0.530000\n",
       "25%           2.170000\n",
       "50%           2.940000\n",
       "75%           3.970000\n",
       "max           6.910000\n",
       "Name: coste_devolucion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resolver duplicados por clave con una política estable\n",
    "# (conservadora: si hay varias filas, nos quedamos con el máximo coste informado)\n",
    "items_cost_resolved = (\n",
    "    items_cost\n",
    "    .groupby(KEYS, as_index=False)\n",
    "    .agg(coste_devolucion=(\"coste_devolucion\", \"max\"))\n",
    ")\n",
    "\n",
    "resolved_drop = items_cost.shape[0] - items_cost_resolved.shape[0]\n",
    "\n",
    "print(\"\\n Tabla de costes preparada para merge\")\n",
    "print(f\"- Filas originales: {items_cost.shape[0]:,}\")\n",
    "print(f\"- Filas tras resolver duplicados: {items_cost_resolved.shape[0]:,}\")\n",
    "print(f\"- Filas colapsadas por duplicados: {resolved_drop:,}\")\n",
    "\n",
    "print(\"\\nResumen coste_devolucion (tabla resuelta):\")\n",
    "display(items_cost_resolved[\"coste_devolucion\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3c693597-4ad7-4e30-a5c2-5d90eadf5461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Merge completado: coste_devolucion añadido a test_df2\n",
      "- NA rate tras merge (debería ser 0 por fillna): 0.00%\n",
      "- Cobertura de coste (has_coste=1): 100.00%\n",
      "\n",
      "Resumen coste_devolucion (post-merge):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    191954.000000\n",
       "mean          3.465760\n",
       "std           1.123252\n",
       "min           1.490000\n",
       "25%           2.460000\n",
       "50%           3.290000\n",
       "75%           4.440000\n",
       "max           6.910000\n",
       "Name: coste_devolucion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ejemplos:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>devuelto</th>\n",
       "      <th>coste_devolucion</th>\n",
       "      <th>has_coste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T000016-001</td>\n",
       "      <td>T000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T000084-001</td>\n",
       "      <td>T000084</td>\n",
       "      <td>1</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T000975-001</td>\n",
       "      <td>T000975</td>\n",
       "      <td>0</td>\n",
       "      <td>4.42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T001279-001</td>\n",
       "      <td>T001279</td>\n",
       "      <td>0</td>\n",
       "      <td>4.44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T001279-002</td>\n",
       "      <td>T001279</td>\n",
       "      <td>0</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T001368-001</td>\n",
       "      <td>T001368</td>\n",
       "      <td>1</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T001750-001</td>\n",
       "      <td>T001750</td>\n",
       "      <td>0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T003130-001</td>\n",
       "      <td>T003130</td>\n",
       "      <td>0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T003131-001</td>\n",
       "      <td>T003131</td>\n",
       "      <td>0</td>\n",
       "      <td>4.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T003386-001</td>\n",
       "      <td>T003386</td>\n",
       "      <td>0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id ticket_id  devuelto  coste_devolucion  has_coste\n",
       "0  T000016-001   T000016         1              1.93          1\n",
       "1  T000084-001   T000084         1              2.98          1\n",
       "2  T000975-001   T000975         0              4.42          1\n",
       "3  T001279-001   T001279         0              4.44          1\n",
       "4  T001279-002   T001279         0              3.55          1\n",
       "5  T001368-001   T001368         1              1.98          1\n",
       "6  T001750-001   T001750         0              2.89          1\n",
       "7  T003130-001   T003130         0              4.32          1\n",
       "8  T003131-001   T003131         0              4.31          1\n",
       "9  T003386-001   T003386         0              3.30          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_coste_devolucion(df_base: pd.DataFrame, cost_table: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Añade coste_devolucion al dataset base mediante merge por (item_id, ticket_id).\n",
    "    Deja un flag has_coste y rellena NA con 0 para permitir métricas en € sin nulos.\n",
    "    \"\"\"\n",
    "    df = df_base.copy()\n",
    "\n",
    "    # Validación de llaves en df_base\n",
    "    for c in KEYS:\n",
    "        if c not in df.columns:\n",
    "            raise KeyError(f\"El dataset base no contiene la columna '{c}'.\")\n",
    "\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "    out = df.merge(\n",
    "        cost_table,\n",
    "        on=KEYS,\n",
    "        how=\"left\",\n",
    "        validate=\"m:1\"  # muchos items en df_base pueden mapear a una fila de coste\n",
    "    )\n",
    "\n",
    "    out[\"has_coste\"] = out[\"coste_devolucion\"].notna().astype(\"int8\")\n",
    "\n",
    "    # Política para BI: NA -> 0, y lo indicamos con has_coste\n",
    "    out[\"coste_devolucion\"] = out[\"coste_devolucion\"].fillna(0.0).astype(\"float32\")\n",
    "\n",
    "    # Sanity checks\n",
    "    neg_rate = float((out[\"coste_devolucion\"] < 0).mean())\n",
    "    if neg_rate > 0:\n",
    "        print(f\"⚠️ Atención: hay costes negativos ({neg_rate:.2%}). Revisa el fichero de entrada.\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "test_df2_with_cost = add_coste_devolucion(test_df2, items_cost_resolved)\n",
    "\n",
    "print(\"\\n Merge completado: coste_devolucion añadido a test_df2\")\n",
    "print(f\"- NA rate tras merge (debería ser 0 por fillna): {test_df2_with_cost['coste_devolucion'].isna().mean():.2%}\")\n",
    "print(f\"- Cobertura de coste (has_coste=1): {test_df2_with_cost['has_coste'].mean():.2%}\")\n",
    "\n",
    "print(\"\\nResumen coste_devolucion (post-merge):\")\n",
    "display(test_df2_with_cost[\"coste_devolucion\"].describe())\n",
    "\n",
    "print(\"\\nEjemplos:\")\n",
    "display(test_df2_with_cost[[\"item_id\", \"ticket_id\", \"devuelto\", \"coste_devolucion\", \"has_coste\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d0d4777b-b72b-46a0-872e-b64add5c0d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cost file cargado\n",
      "- Filas: 905,445\n",
      "- NA en coste_devolucion: 0.00%\n",
      "\n",
      " No hay duplicados por (item_id, ticket_id)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "COST_FILE = \"data/items_devoluciones_ajustadas.csv\"\n",
    "KEYS = [\"item_id\", \"ticket_id\"]\n",
    "\n",
    "items_cost = pd.read_csv(\n",
    "    COST_FILE,\n",
    "    usecols=[\"item_id\", \"ticket_id\", \"coste_devolucion\"]\n",
    ")\n",
    "\n",
    "# Normalización de claves\n",
    "for c in KEYS:\n",
    "    items_cost[c] = items_cost[c].astype(str).str.strip()\n",
    "\n",
    "# Coste a numérico\n",
    "items_cost[\"coste_devolucion\"] = pd.to_numeric(items_cost[\"coste_devolucion\"], errors=\"coerce\")\n",
    "\n",
    "print(\" Cost file cargado\")\n",
    "print(f\"- Filas: {items_cost.shape[0]:,}\")\n",
    "print(f\"- NA en coste_devolucion: {items_cost['coste_devolucion'].isna().mean():.2%}\")\n",
    "\n",
    "# Auditoría de duplicados por clave\n",
    "dup_mask = items_cost.duplicated(subset=KEYS, keep=False)\n",
    "n_dup_rows = int(dup_mask.sum())\n",
    "\n",
    "if n_dup_rows > 0:\n",
    "    n_dup_keys = items_cost.loc[dup_mask, KEYS].drop_duplicates().shape[0]\n",
    "    print(\"\\n Atención: existen claves duplicadas en el fichero de costes\")\n",
    "    print(f\"- Filas duplicadas: {n_dup_rows:,}\")\n",
    "    print(f\"- Claves únicas afectadas: {n_dup_keys:,}\")\n",
    "    print(\"Ejemplo de duplicados:\")\n",
    "    display(items_cost.loc[dup_mask].head(10))\n",
    "else:\n",
    "    print(\"\\n No hay duplicados por (item_id, ticket_id)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "24daf7f9-5d07-433d-b843-c2c5b962dbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tabla de costes preparada para merge\n",
      "- Filas originales: 905,445\n",
      "- Filas tras resolver duplicados: 905,445\n",
      "- Filas colapsadas por duplicados: 0\n",
      "\n",
      "Resumen coste_devolucion (tabla resuelta):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    905445.000000\n",
       "mean          3.105396\n",
       "std           1.122479\n",
       "min           0.530000\n",
       "25%           2.170000\n",
       "50%           2.940000\n",
       "75%           3.970000\n",
       "max           6.910000\n",
       "Name: coste_devolucion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resolver duplicados por clave con una política estable\n",
    "# (conservadora: si hay varias filas, nos quedamos con el máximo coste informado)\n",
    "items_cost_resolved = (\n",
    "    items_cost\n",
    "    .groupby(KEYS, as_index=False)\n",
    "    .agg(coste_devolucion=(\"coste_devolucion\", \"max\"))\n",
    ")\n",
    "\n",
    "resolved_drop = items_cost.shape[0] - items_cost_resolved.shape[0]\n",
    "\n",
    "print(\"\\n Tabla de costes preparada para merge\")\n",
    "print(f\"- Filas originales: {items_cost.shape[0]:,}\")\n",
    "print(f\"- Filas tras resolver duplicados: {items_cost_resolved.shape[0]:,}\")\n",
    "print(f\"- Filas colapsadas por duplicados: {resolved_drop:,}\")\n",
    "\n",
    "print(\"\\nResumen coste_devolucion (tabla resuelta):\")\n",
    "display(items_cost_resolved[\"coste_devolucion\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7a9cfbb1-604b-4741-bf70-79feab7139b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Merge completado: coste_devolucion añadido a test_df2\n",
      "- NA rate tras merge (debería ser 0 por fillna): 0.00%\n",
      "- Cobertura de coste (has_coste=1): 100.00%\n",
      "\n",
      "Resumen coste_devolucion (post-merge):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    191954.000000\n",
       "mean          3.465760\n",
       "std           1.123252\n",
       "min           1.490000\n",
       "25%           2.460000\n",
       "50%           3.290000\n",
       "75%           4.440000\n",
       "max           6.910000\n",
       "Name: coste_devolucion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ejemplos:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>devuelto</th>\n",
       "      <th>coste_devolucion</th>\n",
       "      <th>has_coste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T000016-001</td>\n",
       "      <td>T000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T000084-001</td>\n",
       "      <td>T000084</td>\n",
       "      <td>1</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T000975-001</td>\n",
       "      <td>T000975</td>\n",
       "      <td>0</td>\n",
       "      <td>4.42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T001279-001</td>\n",
       "      <td>T001279</td>\n",
       "      <td>0</td>\n",
       "      <td>4.44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T001279-002</td>\n",
       "      <td>T001279</td>\n",
       "      <td>0</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T001368-001</td>\n",
       "      <td>T001368</td>\n",
       "      <td>1</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T001750-001</td>\n",
       "      <td>T001750</td>\n",
       "      <td>0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T003130-001</td>\n",
       "      <td>T003130</td>\n",
       "      <td>0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T003131-001</td>\n",
       "      <td>T003131</td>\n",
       "      <td>0</td>\n",
       "      <td>4.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T003386-001</td>\n",
       "      <td>T003386</td>\n",
       "      <td>0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id ticket_id  devuelto  coste_devolucion  has_coste\n",
       "0  T000016-001   T000016         1              1.93          1\n",
       "1  T000084-001   T000084         1              2.98          1\n",
       "2  T000975-001   T000975         0              4.42          1\n",
       "3  T001279-001   T001279         0              4.44          1\n",
       "4  T001279-002   T001279         0              3.55          1\n",
       "5  T001368-001   T001368         1              1.98          1\n",
       "6  T001750-001   T001750         0              2.89          1\n",
       "7  T003130-001   T003130         0              4.32          1\n",
       "8  T003131-001   T003131         0              4.31          1\n",
       "9  T003386-001   T003386         0              3.30          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_coste_devolucion(df_base: pd.DataFrame, cost_table: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Añade coste_devolucion al dataset base mediante merge por (item_id, ticket_id).\n",
    "    Deja un flag has_coste y rellena NA con 0 para permitir métricas en € sin nulos.\n",
    "    \"\"\"\n",
    "    df = df_base.copy()\n",
    "\n",
    "    # Validación de llaves en df_base\n",
    "    for c in KEYS:\n",
    "        if c not in df.columns:\n",
    "            raise KeyError(f\"El dataset base no contiene la columna '{c}'.\")\n",
    "\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "    out = df.merge(\n",
    "        cost_table,\n",
    "        on=KEYS,\n",
    "        how=\"left\",\n",
    "        validate=\"m:1\"  # muchos items en df_base pueden mapear a una fila de coste\n",
    "    )\n",
    "\n",
    "    out[\"has_coste\"] = out[\"coste_devolucion\"].notna().astype(\"int8\")\n",
    "\n",
    "    # Política para BI: NA -> 0, y lo indicamos con has_coste\n",
    "    out[\"coste_devolucion\"] = out[\"coste_devolucion\"].fillna(0.0).astype(\"float32\")\n",
    "\n",
    "    # Sanity checks\n",
    "    neg_rate = float((out[\"coste_devolucion\"] < 0).mean())\n",
    "    if neg_rate > 0:\n",
    "        print(f\"⚠️ Atención: hay costes negativos ({neg_rate:.2%}). Revisa el fichero de entrada.\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "test_df2_with_cost = add_coste_devolucion(test_df2, items_cost_resolved)\n",
    "\n",
    "print(\"\\n Merge completado: coste_devolucion añadido a test_df2\")\n",
    "print(f\"- NA rate tras merge (debería ser 0 por fillna): {test_df2_with_cost['coste_devolucion'].isna().mean():.2%}\")\n",
    "print(f\"- Cobertura de coste (has_coste=1): {test_df2_with_cost['has_coste'].mean():.2%}\")\n",
    "\n",
    "print(\"\\nResumen coste_devolucion (post-merge):\")\n",
    "display(test_df2_with_cost[\"coste_devolucion\"].describe())\n",
    "\n",
    "print(\"\\nEjemplos:\")\n",
    "display(test_df2_with_cost[[\"item_id\", \"ticket_id\", \"devuelto\", \"coste_devolucion\", \"has_coste\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "79bd6ac5-e0e3-47bc-8abe-f51b9ecc8333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " coste_devolucion añadido a test_df2\n",
      "- Cobertura (has_coste=1): 100.00%\n",
      "- coste_devolucion NA rate: 0.00%\n",
      "Resumen coste_devolucion:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    191954.000000\n",
       "mean          3.465760\n",
       "std           1.123252\n",
       "min           1.490000\n",
       "25%           2.460000\n",
       "50%           3.290000\n",
       "75%           4.440000\n",
       "max           6.910000\n",
       "Name: coste_devolucion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "COST_FILE = \"data/items_devoluciones_ajustadas.csv\"\n",
    "KEYS = [\"item_id\", \"ticket_id\"]\n",
    "\n",
    "# 1) Cargar costes\n",
    "items_cost = pd.read_csv(COST_FILE, usecols=[\"item_id\", \"ticket_id\", \"coste_devolucion\"]).copy()\n",
    "\n",
    "for c in KEYS:\n",
    "    items_cost[c] = items_cost[c].astype(str).str.strip()\n",
    "\n",
    "items_cost[\"coste_devolucion\"] = pd.to_numeric(items_cost[\"coste_devolucion\"], errors=\"coerce\")\n",
    "\n",
    "# 2) Resolver duplicados por clave (conservador: máximo coste)\n",
    "items_cost = (\n",
    "    items_cost\n",
    "    .groupby(KEYS, as_index=False)\n",
    "    .agg(coste_devolucion=(\"coste_devolucion\", \"max\"))\n",
    ")\n",
    "\n",
    "# 3) Merge a test_df2 (y reasignar)\n",
    "for c in KEYS:\n",
    "    if c not in test_df2.columns:\n",
    "        raise KeyError(f\"test_df2 no tiene '{c}'. No puedo mergear coste.\")\n",
    "    test_df2[c] = test_df2[c].astype(str).str.strip()\n",
    "\n",
    "test_df2 = test_df2.merge(items_cost, on=KEYS, how=\"left\", validate=\"m:1\")\n",
    "\n",
    "# 4) Flags y NA policy\n",
    "test_df2[\"has_coste\"] = test_df2[\"coste_devolucion\"].notna().astype(\"int8\")\n",
    "test_df2[\"coste_devolucion\"] = test_df2[\"coste_devolucion\"].fillna(0.0).astype(\"float32\")\n",
    "\n",
    "print(\" coste_devolucion añadido a test_df2\")\n",
    "print(f\"- Cobertura (has_coste=1): {test_df2['has_coste'].mean():.2%}\")\n",
    "print(f\"- coste_devolucion NA rate: {test_df2['coste_devolucion'].isna().mean():.2%}\")\n",
    "print(\"Resumen coste_devolucion:\")\n",
    "display(test_df2[\"coste_devolucion\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "84c640f4-f068-4de6-ba4c-e1123286c9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checks OK: test_df2 y recs tienen las columnas mínimas para construir el dataset BI.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Carpeta de salida para BI\n",
    "BI_DIR = \"data/bi\"\n",
    "os.makedirs(BI_DIR, exist_ok=True)\n",
    "\n",
    "# Checks mínimos para evitar merges rotos\n",
    "required_base_cols = [\"item_id\", \"ticket_id\", \"fecha_item\", \"categoria\", \"id_producto\", \"talla\", \"devuelto\", \"coste_devolucion\"]\n",
    "missing_base = [c for c in required_base_cols if c not in test_df2.columns]\n",
    "if missing_base:\n",
    "    raise KeyError(f\"test_df2 no tiene columnas necesarias: {missing_base}\")\n",
    "\n",
    "required_recs_cols = [\"_orig_idx\", \"talla_final\", \"p_dev_actual\", \"p_dev_final\", \"delta_p_final\", \"cambia_talla\"]\n",
    "missing_recs = [c for c in required_recs_cols if c not in recs.columns]\n",
    "if missing_recs:\n",
    "    raise KeyError(f\"recs no tiene columnas necesarias: {missing_recs}\")\n",
    "\n",
    "print(\" Checks OK: test_df2 y recs tienen las columnas mínimas para construir el dataset BI.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4fd9eb43-7a4f-4a4b-8b5c-3b026437e497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset BI (items) creado.\n",
      "- Filas: 191,954\n",
      "- Columnas: 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_orig_idx</th>\n",
       "      <th>item_id</th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>canal</th>\n",
       "      <th>sku</th>\n",
       "      <th>id_producto</th>\n",
       "      <th>categoria</th>\n",
       "      <th>fecha_item</th>\n",
       "      <th>talla</th>\n",
       "      <th>...</th>\n",
       "      <th>p_dev_final</th>\n",
       "      <th>delta_p</th>\n",
       "      <th>delta_p_final</th>\n",
       "      <th>cambia_talla_raw</th>\n",
       "      <th>cambia_talla</th>\n",
       "      <th>p_dev_global</th>\n",
       "      <th>expected_cost_global</th>\n",
       "      <th>expected_savings_talla</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>T000016-001</td>\n",
       "      <td>T000016</td>\n",
       "      <td>C000010</td>\n",
       "      <td>online</td>\n",
       "      <td>P001-BEI-M</td>\n",
       "      <td>P001</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>T000084-001</td>\n",
       "      <td>T000084</td>\n",
       "      <td>C000059</td>\n",
       "      <td>online</td>\n",
       "      <td>P004-NAV-S</td>\n",
       "      <td>P004</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>T000975-001</td>\n",
       "      <td>T000975</td>\n",
       "      <td>C000657</td>\n",
       "      <td>online</td>\n",
       "      <td>P020-BLK-XL</td>\n",
       "      <td>P020</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>2024-10-05</td>\n",
       "      <td>XL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>T001279-001</td>\n",
       "      <td>T001279</td>\n",
       "      <td>C000874</td>\n",
       "      <td>online</td>\n",
       "      <td>P020-BRN-M</td>\n",
       "      <td>P020</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>T001279-002</td>\n",
       "      <td>T001279</td>\n",
       "      <td>C000874</td>\n",
       "      <td>online</td>\n",
       "      <td>P003-BRN-M</td>\n",
       "      <td>P003</td>\n",
       "      <td>sudadera</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _orig_idx      item_id ticket_id customer_id   canal          sku  \\\n",
       "0          0  T000016-001   T000016     C000010  online   P001-BEI-M   \n",
       "1          1  T000084-001   T000084     C000059  online   P004-NAV-S   \n",
       "2          2  T000975-001   T000975     C000657  online  P020-BLK-XL   \n",
       "3          3  T001279-001   T001279     C000874  online   P020-BRN-M   \n",
       "4          4  T001279-002   T001279     C000874  online   P003-BRN-M   \n",
       "\n",
       "  id_producto categoria fecha_item talla  ...  p_dev_final  delta_p  \\\n",
       "0        P001  camiseta 2024-10-31     M  ...          NaN      NaN   \n",
       "1        P004  pantalon 2024-11-06     S  ...          NaN      NaN   \n",
       "2        P020    abrigo 2024-10-05    XL  ...          NaN      NaN   \n",
       "3        P020    abrigo 2025-02-17     M  ...          NaN      NaN   \n",
       "4        P003  sudadera 2025-02-17     M  ...          NaN      NaN   \n",
       "\n",
       "   delta_p_final  cambia_talla_raw  cambia_talla  p_dev_global  \\\n",
       "0            NaN               NaN           NaN           NaN   \n",
       "1            NaN               NaN           NaN           NaN   \n",
       "2            NaN               NaN           NaN           NaN   \n",
       "3            NaN               NaN           NaN           NaN   \n",
       "4            NaN               NaN           NaN           NaN   \n",
       "\n",
       "   expected_cost_global  expected_savings_talla  year    month  \n",
       "0                   NaN                     NaN  2024  2024-10  \n",
       "1                   NaN                     NaN  2024  2024-11  \n",
       "2                   NaN                     NaN  2024  2024-10  \n",
       "3                   NaN                     NaN  2025  2025-02  \n",
       "4                   NaN                     NaN  2025  2025-02  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_bi_item_dataset(df_base: pd.DataFrame, recs: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Devuelve un dataset plano a nivel item, listo para exportar a Power BI.\n",
    "    Une recs con el universo base mediante _orig_idx (índice original del df_base).\n",
    "    \"\"\"\n",
    "    base = df_base.copy().reset_index(drop=False).rename(columns={\"index\": \"_orig_idx\"})\n",
    "\n",
    "    # Selección de columnas base: añadimos las que suelen interesar en BI si existen\n",
    "    base_cols = [\n",
    "        \"_orig_idx\",\n",
    "        \"item_id\", \"ticket_id\", \"customer_id\", \"canal\",\n",
    "        \"sku\", \"id_producto\", \"categoria\",\n",
    "        \"fecha_item\",\n",
    "        \"talla\", \"altura_cm\", \"peso_kg\", \"bmi\",\n",
    "        \"ideal_idx\", \"talla_idx\", \"desajuste\", \"desajuste_abs\", \"talla_extrema\",\n",
    "        \"devuelto\",\n",
    "        \"coste_devolucion\",\n",
    "        \"p_dev_global\",  # puede no existir, lo gestionamos abajo\n",
    "    ]\n",
    "    base_cols = [c for c in base_cols if c in base.columns]\n",
    "\n",
    "    # Parte de recs: lo que genera el recomendador\n",
    "    recs_cols = [\n",
    "        \"_orig_idx\",\n",
    "        \"talla_reco\", \"talla_final\",\n",
    "        \"p_dev_actual\", \"p_dev_reco\", \"p_dev_final\",\n",
    "        \"delta_p\", \"delta_p_final\",\n",
    "        \"cambia_talla_raw\", \"cambia_talla\",\n",
    "    ]\n",
    "    recs_cols = [c for c in recs_cols if c in recs.columns]\n",
    "\n",
    "    out = (\n",
    "        base[base_cols]\n",
    "        .merge(recs[recs_cols], on=\"_orig_idx\", how=\"left\", validate=\"1:1\")\n",
    "    )\n",
    "\n",
    "    # Seguridad: si no hay p_dev_global, lo dejamos como NaN y seguimos (para BI igual sirve)\n",
    "    if \"p_dev_global\" not in out.columns:\n",
    "        out[\"p_dev_global\"] = np.nan\n",
    "\n",
    "    # Métricas económicas (esperadas)\n",
    "    out[\"expected_cost_global\"] = (out[\"p_dev_global\"] * out[\"coste_devolucion\"]).astype(\"float64\")\n",
    "    out[\"expected_savings_talla\"] = (out[\"delta_p_final\"] * out[\"coste_devolucion\"]).astype(\"float64\")\n",
    "\n",
    "    # Métricas auxiliares de BI\n",
    "    out[\"year\"] = pd.to_datetime(out[\"fecha_item\"]).dt.year\n",
    "    out[\"month\"] = pd.to_datetime(out[\"fecha_item\"]).dt.to_period(\"M\").astype(str)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "bi_items = build_bi_item_dataset(test_df2, recs)\n",
    "\n",
    "print(\" Dataset BI (items) creado.\")\n",
    "print(f\"- Filas: {bi_items.shape[0]:,}\")\n",
    "print(f\"- Columnas: {bi_items.shape[1]:,}\")\n",
    "display(bi_items.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ed16fdf5-b5a8-4ad4-96b6-3ea0dc630011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESUMEN EJECUTIVO — Recomendador de tallas + modelo de devoluciones\n",
      "Universo analizado: 191,954 items\n",
      "Intervención (cambio de talla final): 3,581 items (17.90%)\n",
      "\n",
      "Impacto económico esperado (sin A/B; probabilidad × coste):\n",
      "- Ahorro esperado total por talla (adopción 100%): 2,602.65 €\n",
      "- Ahorro esperado total ajustado por adopción (100%): 2,602.65 €\n",
      "\n",
      "Impacto medio (útil para producto/UX):\n",
      "- Ahorro medio por item (incluyendo no intervenidos): 0.1301 €\n",
      "- Ahorro medio por item intervenido: 0.73 €\n",
      "\n",
      "A nivel pedido (ticket):\n",
      "- % pedidos con al menos 1 recomendación: 2.65%\n",
      "- Ahorro medio por pedido intervenido: 0.74 €\n",
      "\n",
      "Contexto (modelo global): p_dev_global no está disponible en este dataset (se omite share atacable).\n",
      "\n",
      "Lectura recomendada:\n",
      "- La métrica 'por item intervenido' es la más representativa del valor cuando el sistema actúa.\n",
      "- La métrica global incluye muchos items sin intervención y por eso se diluye.\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "def print_exec_summary(bi_items: pd.DataFrame, adoption_rate: float = 1.0) -> None:\n",
    "    \"\"\"\n",
    "    Imprime un resumen ejecutivo con métricas en formato negocio.\n",
    "    adoption_rate permite simular aceptación realista (0.2, 0.4, 0.6...).\n",
    "    \"\"\"\n",
    "    df = bi_items.copy()\n",
    "\n",
    "    n_items = len(df)\n",
    "    pct_interv = float(df[\"cambia_talla\"].mean())\n",
    "    n_interv = int(df[\"cambia_talla\"].sum())\n",
    "\n",
    "    total_savings = float(df[\"expected_savings_talla\"].sum())\n",
    "    total_savings_adopt = total_savings * float(adoption_rate)\n",
    "\n",
    "    mean_savings_item_all = float(df[\"expected_savings_talla\"].mean())\n",
    "    mean_savings_item_interv = float(df.loc[df[\"cambia_talla\"] == 1, \"expected_savings_talla\"].mean()) if n_interv > 0 else 0.0\n",
    "\n",
    "    # Métricas por pedido (si ticket_id existe)\n",
    "    if \"ticket_id\" in df.columns:\n",
    "        per_ticket = (\n",
    "            df.groupby(\"ticket_id\", as_index=False)\n",
    "              .agg(\n",
    "                  n_items=(\"item_id\", \"size\") if \"item_id\" in df.columns else (\"ticket_id\", \"size\"),\n",
    "                  n_interv=(\"cambia_talla\", \"sum\"),\n",
    "                  savings=(\"expected_savings_talla\", \"sum\"),\n",
    "              )\n",
    "        )\n",
    "        per_ticket[\"has_interv\"] = (per_ticket[\"n_interv\"] > 0).astype(int)\n",
    "\n",
    "        pct_tickets_interv = float(per_ticket[\"has_interv\"].mean())\n",
    "        mean_savings_ticket_interv = float(per_ticket.loc[per_ticket[\"has_interv\"] == 1, \"savings\"].mean()) if per_ticket[\"has_interv\"].sum() > 0 else 0.0\n",
    "    else:\n",
    "        pct_tickets_interv = np.nan\n",
    "        mean_savings_ticket_interv = np.nan\n",
    "\n",
    "    # Share atacable si existe p_dev_global\n",
    "    has_global = df[\"p_dev_global\"].notna().any()\n",
    "    if has_global:\n",
    "        total_expected_cost = float(df[\"expected_cost_global\"].sum())\n",
    "        share_cost_addr = (total_savings / total_expected_cost) if total_expected_cost > 0 else np.nan\n",
    "    else:\n",
    "        total_expected_cost = np.nan\n",
    "        share_cost_addr = np.nan\n",
    "\n",
    "    print(\"RESUMEN EJECUTIVO — Recomendador de tallas + modelo de devoluciones\")\n",
    "    print(f\"Universo analizado: {n_items:,} items\")\n",
    "    print(f\"Intervención (cambio de talla final): {n_interv:,} items ({pct_interv:.2%})\")\n",
    "\n",
    "    print(\"\\nImpacto económico esperado (sin A/B; probabilidad × coste):\")\n",
    "    print(f\"- Ahorro esperado total por talla (adopción 100%): {total_savings:,.2f} €\")\n",
    "    print(f\"- Ahorro esperado total ajustado por adopción ({adoption_rate:.0%}): {total_savings_adopt:,.2f} €\")\n",
    "\n",
    "    print(\"\\nImpacto medio (útil para producto/UX):\")\n",
    "    print(f\"- Ahorro medio por item (incluyendo no intervenidos): {mean_savings_item_all:,.4f} €\")\n",
    "    print(f\"- Ahorro medio por item intervenido: {mean_savings_item_interv:,.2f} €\")\n",
    "\n",
    "    if not np.isnan(pct_tickets_interv):\n",
    "        print(\"\\nA nivel pedido (ticket):\")\n",
    "        print(f\"- % pedidos con al menos 1 recomendación: {pct_tickets_interv:.2%}\")\n",
    "        print(f\"- Ahorro medio por pedido intervenido: {mean_savings_ticket_interv:,.2f} €\")\n",
    "\n",
    "    if has_global:\n",
    "        print(\"\\nContexto (modelo global):\")\n",
    "        print(f\"- Coste esperado total de devoluciones: {total_expected_cost:,.2f} €\")\n",
    "        print(f\"- Share del coste atacable por talla: {share_cost_addr:.2%}\")\n",
    "    else:\n",
    "        print(\"\\nContexto (modelo global): p_dev_global no está disponible en este dataset (se omite share atacable).\")\n",
    "\n",
    "    print(\"\\nLectura recomendada:\")\n",
    "    print(\"- La métrica 'por item intervenido' es la más representativa del valor cuando el sistema actúa.\")\n",
    "    print(\"- La métrica global incluye muchos items sin intervención y por eso se diluye.\")\n",
    "    print(\"=\" * 72)\n",
    "\n",
    "\n",
    "print_exec_summary(bi_items, adoption_rate=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4509aa31-32c6-40d5-9ff4-db27bbc6d28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tabla por categoría (ordenada por ahorro total esperado):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoria</th>\n",
       "      <th>n_items</th>\n",
       "      <th>pct_interv</th>\n",
       "      <th>savings_total</th>\n",
       "      <th>savings_mean_item</th>\n",
       "      <th>savings_mean_interv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abrigo</td>\n",
       "      <td>62485</td>\n",
       "      <td>0.235021</td>\n",
       "      <td>1583.959292</td>\n",
       "      <td>0.237262</td>\n",
       "      <td>1.009534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pantalon</td>\n",
       "      <td>39494</td>\n",
       "      <td>0.122046</td>\n",
       "      <td>385.982118</td>\n",
       "      <td>0.094027</td>\n",
       "      <td>0.770423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>camiseta</td>\n",
       "      <td>56030</td>\n",
       "      <td>0.115692</td>\n",
       "      <td>291.269217</td>\n",
       "      <td>0.050673</td>\n",
       "      <td>0.437999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>camisa</td>\n",
       "      <td>17199</td>\n",
       "      <td>0.356593</td>\n",
       "      <td>175.032288</td>\n",
       "      <td>0.096172</td>\n",
       "      <td>0.269695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sudadera</td>\n",
       "      <td>16746</td>\n",
       "      <td>0.119322</td>\n",
       "      <td>166.406744</td>\n",
       "      <td>0.100791</td>\n",
       "      <td>0.844704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  categoria  n_items  pct_interv  savings_total  savings_mean_item  \\\n",
       "0    abrigo    62485    0.235021    1583.959292           0.237262   \n",
       "3  pantalon    39494    0.122046     385.982118           0.094027   \n",
       "2  camiseta    56030    0.115692     291.269217           0.050673   \n",
       "1    camisa    17199    0.356593     175.032288           0.096172   \n",
       "4  sudadera    16746    0.119322     166.406744           0.100791   \n",
       "\n",
       "   savings_mean_interv  \n",
       "0             1.009534  \n",
       "3             0.770423  \n",
       "2             0.437999  \n",
       "1             0.269695  \n",
       "4             0.844704  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top productos (n>=500) por ahorro total esperado:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_producto</th>\n",
       "      <th>categoria</th>\n",
       "      <th>n</th>\n",
       "      <th>pct_interv</th>\n",
       "      <th>savings_total</th>\n",
       "      <th>savings_mean_interv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P047</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>11004</td>\n",
       "      <td>0.770728</td>\n",
       "      <td>710.552472</td>\n",
       "      <td>0.779970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P013</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>13200</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>247.490754</td>\n",
       "      <td>1.374949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P058</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>10660</td>\n",
       "      <td>0.121542</td>\n",
       "      <td>186.394098</td>\n",
       "      <td>1.285477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P005</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>10722</td>\n",
       "      <td>0.110052</td>\n",
       "      <td>179.835725</td>\n",
       "      <td>1.416029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P020</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>10665</td>\n",
       "      <td>0.119963</td>\n",
       "      <td>170.010256</td>\n",
       "      <td>1.297788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P003</td>\n",
       "      <td>sudadera</td>\n",
       "      <td>13760</td>\n",
       "      <td>0.122076</td>\n",
       "      <td>140.374251</td>\n",
       "      <td>0.840564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P008</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>13691</td>\n",
       "      <td>0.125884</td>\n",
       "      <td>137.147260</td>\n",
       "      <td>0.770490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P042</td>\n",
       "      <td>camisa</td>\n",
       "      <td>11017</td>\n",
       "      <td>0.479381</td>\n",
       "      <td>122.076099</td>\n",
       "      <td>0.218774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P024</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>10891</td>\n",
       "      <td>0.119755</td>\n",
       "      <td>108.008666</td>\n",
       "      <td>0.788384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P004</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>10814</td>\n",
       "      <td>0.124432</td>\n",
       "      <td>105.841834</td>\n",
       "      <td>0.772568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>13442</td>\n",
       "      <td>0.112868</td>\n",
       "      <td>66.981992</td>\n",
       "      <td>0.426637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P006</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>10903</td>\n",
       "      <td>0.117031</td>\n",
       "      <td>60.618284</td>\n",
       "      <td>0.452375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P016</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>10848</td>\n",
       "      <td>0.122711</td>\n",
       "      <td>59.820112</td>\n",
       "      <td>0.446419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>10841</td>\n",
       "      <td>0.118962</td>\n",
       "      <td>57.145256</td>\n",
       "      <td>0.429664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P059</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>3027</td>\n",
       "      <td>0.124601</td>\n",
       "      <td>47.903358</td>\n",
       "      <td>1.228291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>P069</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>3207</td>\n",
       "      <td>0.106825</td>\n",
       "      <td>41.772630</td>\n",
       "      <td>1.160351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>P065</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>4098</td>\n",
       "      <td>0.109865</td>\n",
       "      <td>34.984358</td>\n",
       "      <td>0.713966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>P064</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>6946</td>\n",
       "      <td>0.091298</td>\n",
       "      <td>28.621934</td>\n",
       "      <td>0.447218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>P066</td>\n",
       "      <td>camisa</td>\n",
       "      <td>3052</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>27.865931</td>\n",
       "      <td>0.535883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P060</td>\n",
       "      <td>sudadera</td>\n",
       "      <td>2986</td>\n",
       "      <td>0.106007</td>\n",
       "      <td>26.032494</td>\n",
       "      <td>0.867750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_producto categoria      n  pct_interv  savings_total  \\\n",
       "12        P047    abrigo  11004    0.770728     710.552472   \n",
       "7         P013    abrigo  13200    0.128114     247.490754   \n",
       "13        P058    abrigo  10660    0.121542     186.394098   \n",
       "4         P005    abrigo  10722    0.110052     179.835725   \n",
       "9         P020    abrigo  10665    0.119963     170.010256   \n",
       "2         P003  sudadera  13760    0.122076     140.374251   \n",
       "6         P008  pantalon  13691    0.125884     137.147260   \n",
       "11        P042    camisa  11017    0.479381     122.076099   \n",
       "10        P024  pantalon  10891    0.119755     108.008666   \n",
       "3         P004  pantalon  10814    0.124432     105.841834   \n",
       "1         P002  camiseta  13442    0.112868      66.981992   \n",
       "5         P006  camiseta  10903    0.117031      60.618284   \n",
       "8         P016  camiseta  10848    0.122711      59.820112   \n",
       "0         P001  camiseta  10841    0.118962      57.145256   \n",
       "14        P059    abrigo   3027    0.124601      47.903358   \n",
       "21        P069    abrigo   3207    0.106825      41.772630   \n",
       "19        P065  pantalon   4098    0.109865      34.984358   \n",
       "18        P064  camiseta   6946    0.091298      28.621934   \n",
       "20        P066    camisa   3052    0.166667      27.865931   \n",
       "15        P060  sudadera   2986    0.106007      26.032494   \n",
       "\n",
       "    savings_mean_interv  \n",
       "12             0.779970  \n",
       "7              1.374949  \n",
       "13             1.285477  \n",
       "4              1.416029  \n",
       "9              1.297788  \n",
       "2              0.840564  \n",
       "6              0.770490  \n",
       "11             0.218774  \n",
       "10             0.788384  \n",
       "3              0.772568  \n",
       "1              0.426637  \n",
       "5              0.452375  \n",
       "8              0.446419  \n",
       "0              0.429664  \n",
       "14             1.228291  \n",
       "21             1.160351  \n",
       "19             0.713966  \n",
       "18             0.447218  \n",
       "20             0.535883  \n",
       "15             0.867750  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_aggregations(bi_items: pd.DataFrame, min_n_prod: int = 500):\n",
    "    df = bi_items.copy()\n",
    "\n",
    "    by_cat = (\n",
    "        df.groupby(\"categoria\", as_index=False)\n",
    "          .agg(\n",
    "              n_items=(\"ticket_id\", \"size\") if \"ticket_id\" in df.columns else (\"categoria\", \"size\"),\n",
    "              pct_interv=(\"cambia_talla\", \"mean\"),\n",
    "              savings_total=(\"expected_savings_talla\", \"sum\"),\n",
    "              savings_mean_item=(\"expected_savings_talla\", \"mean\"),\n",
    "              savings_mean_interv=(\"expected_savings_talla\", lambda s: float(np.mean(s[df.loc[s.index, \"cambia_talla\"] == 1])) if df.loc[s.index, \"cambia_talla\"].sum() > 0 else 0.0),\n",
    "          )\n",
    "          .sort_values(\"savings_total\", ascending=False)\n",
    "    )\n",
    "\n",
    "    by_prod = (\n",
    "        df.groupby([\"id_producto\", \"categoria\"], as_index=False)\n",
    "          .agg(\n",
    "              n=(\"categoria\", \"size\"),\n",
    "              pct_interv=(\"cambia_talla\", \"mean\"),\n",
    "              savings_total=(\"expected_savings_talla\", \"sum\"),\n",
    "              savings_mean_interv=(\"expected_savings_talla\", lambda s: float(np.mean(s[df.loc[s.index, \"cambia_talla\"] == 1])) if df.loc[s.index, \"cambia_talla\"].sum() > 0 else 0.0),\n",
    "          )\n",
    "    )\n",
    "    by_prod_big = by_prod[by_prod[\"n\"] >= int(min_n_prod)].sort_values(\"savings_total\", ascending=False)\n",
    "\n",
    "    return by_cat, by_prod_big\n",
    "\n",
    "\n",
    "by_cat, by_prod_big = build_aggregations(bi_items, min_n_prod=500)\n",
    "\n",
    "print(\"\\n Tabla por categoría (ordenada por ahorro total esperado):\")\n",
    "display(by_cat)\n",
    "\n",
    "print(\"\\n Top productos (n>=500) por ahorro total esperado:\")\n",
    "display(by_prod_big.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c97d4147-f926-46e4-befc-d2e805a8c19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[min_gain=0.000] intervención=18.56% | ahorro_total(adop)=2,603.46 €\n",
      "[min_gain=0.005] intervención=18.02% | ahorro_total(adop)=2,603.32 €\n",
      "[min_gain=0.010] intervención=17.90% | ahorro_total(adop)=2,602.65 €\n",
      "[min_gain=0.020] intervención=17.52% | ahorro_total(adop)=2,598.21 €\n",
      "[min_gain=0.050] intervención=16.02% | ahorro_total(adop)=2,561.79 €\n",
      "\n",
      " Curva fricción vs ahorro (lista para Power BI):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scope</th>\n",
       "      <th>min_gain</th>\n",
       "      <th>pct_interv</th>\n",
       "      <th>savings_total_adj_adoption</th>\n",
       "      <th>savings_mean_item_adj_adoption</th>\n",
       "      <th>savings_mean_interv_item_adj_adoption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>muestra n=20,000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.18560</td>\n",
       "      <td>2603.460727</td>\n",
       "      <td>0.130173</td>\n",
       "      <td>0.701363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>muestra n=20,000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.18015</td>\n",
       "      <td>2603.320173</td>\n",
       "      <td>0.130166</td>\n",
       "      <td>0.722542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>muestra n=20,000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.17905</td>\n",
       "      <td>2602.649661</td>\n",
       "      <td>0.130132</td>\n",
       "      <td>0.726794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>muestra n=20,000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.17515</td>\n",
       "      <td>2598.207219</td>\n",
       "      <td>0.129910</td>\n",
       "      <td>0.741709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>muestra n=20,000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.16025</td>\n",
       "      <td>2561.785789</td>\n",
       "      <td>0.128089</td>\n",
       "      <td>0.799309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              scope  min_gain  pct_interv  savings_total_adj_adoption  \\\n",
       "0  muestra n=20,000     0.000     0.18560                 2603.460727   \n",
       "1  muestra n=20,000     0.005     0.18015                 2603.320173   \n",
       "2  muestra n=20,000     0.010     0.17905                 2602.649661   \n",
       "3  muestra n=20,000     0.020     0.17515                 2598.207219   \n",
       "4  muestra n=20,000     0.050     0.16025                 2561.785789   \n",
       "\n",
       "   savings_mean_item_adj_adoption  savings_mean_interv_item_adj_adoption  \n",
       "0                        0.130173                               0.701363  \n",
       "1                        0.130166                               0.722542  \n",
       "2                        0.130132                               0.726794  \n",
       "3                        0.129910                               0.741709  \n",
       "4                        0.128089                               0.799309  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_threshold_sweep(\n",
    "    df_base: pd.DataFrame,\n",
    "    gains: list[float],\n",
    "    max_step: int = 2,\n",
    "    adoption_rate: float = 1.0,\n",
    "    sample_n: int | None = 20000,\n",
    "    seed: int = 7,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ejecuta el recomendador con distintos umbrales min_gain y devuelve una tabla resumen.\n",
    "    \"\"\"\n",
    "    if sample_n is not None:\n",
    "        df_eval = df_base.sample(sample_n, random_state=seed).copy()\n",
    "        scope = f\"muestra n={sample_n:,}\"\n",
    "    else:\n",
    "        df_eval = df_base.copy()\n",
    "        scope = f\"universo completo n={len(df_eval):,}\"\n",
    "\n",
    "    rows = []\n",
    "    for g in gains:\n",
    "        recs_g, _ = recommend_sizes(df_eval, max_step=max_step, min_gain=float(g))\n",
    "        bi_g = build_bi_item_dataset(df_eval, recs_g)\n",
    "\n",
    "        n_items = len(bi_g)\n",
    "        pct_interv = float(bi_g[\"cambia_talla\"].mean())\n",
    "        savings_total = float(bi_g[\"expected_savings_talla\"].sum()) * float(adoption_rate)\n",
    "        savings_per_item = float(bi_g[\"expected_savings_talla\"].mean()) * float(adoption_rate)\n",
    "        savings_per_interv = float(bi_g.loc[bi_g[\"cambia_talla\"] == 1, \"expected_savings_talla\"].mean()) * float(adoption_rate) if bi_g[\"cambia_talla\"].sum() > 0 else 0.0\n",
    "\n",
    "        rows.append({\n",
    "            \"scope\": scope,\n",
    "            \"min_gain\": float(g),\n",
    "            \"pct_interv\": pct_interv,\n",
    "            \"savings_total_adj_adoption\": savings_total,\n",
    "            \"savings_mean_item_adj_adoption\": savings_per_item,\n",
    "            \"savings_mean_interv_item_adj_adoption\": savings_per_interv,\n",
    "        })\n",
    "\n",
    "        print(f\"[min_gain={g:.3f}] intervención={pct_interv:.2%} | ahorro_total(adop)={savings_total:,.2f} €\")\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "gains = [0.00, 0.005, 0.01, 0.02, 0.05]\n",
    "threshold_curve = run_threshold_sweep(\n",
    "    test_df2,\n",
    "    gains=gains,\n",
    "    max_step=2,\n",
    "    adoption_rate=1.0,\n",
    "    sample_n=20000,   # sube o pon None para todo el test\n",
    "    seed=7\n",
    ")\n",
    "\n",
    "print(\"\\n Curva fricción vs ahorro (lista para Power BI):\")\n",
    "display(threshold_curve)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "24febe18-2d51-4400-b380-8ddb34c9a72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Exportación completada (Power BI ready):\n",
      "- data/bi\\bi_items.csv\n",
      "- data/bi\\by_category.csv\n",
      "- data/bi\\by_product_top.csv\n",
      "- data/bi\\threshold_curve.csv\n"
     ]
    }
   ],
   "source": [
    "bi_items_path = os.path.join(BI_DIR, \"bi_items.csv\")\n",
    "by_cat_path = os.path.join(BI_DIR, \"by_category.csv\")\n",
    "by_prod_path = os.path.join(BI_DIR, \"by_product_top.csv\")\n",
    "curve_path = os.path.join(BI_DIR, \"threshold_curve.csv\")\n",
    "\n",
    "bi_items.to_csv(bi_items_path, index=False)\n",
    "by_cat.to_csv(by_cat_path, index=False)\n",
    "by_prod_big.to_csv(by_prod_path, index=False)\n",
    "threshold_curve.to_csv(curve_path, index=False)\n",
    "\n",
    "print(\"\\n Exportación completada (Power BI ready):\")\n",
    "print(f\"- {bi_items_path}\")\n",
    "print(f\"- {by_cat_path}\")\n",
    "print(f\"- {by_prod_path}\")\n",
    "print(f\"- {curve_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab54d33-352b-42f2-aeab-3f8b70144531",
   "metadata": {},
   "source": [
    "# KPIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "33ec6250-9fdf-4310-a67d-66780c79f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "BI_DIR = \"data/bi\"\n",
    "os.makedirs(BI_DIR, exist_ok=True)\n",
    "\n",
    "KEYS = [\"item_id\", \"ticket_id\"]\n",
    "\n",
    "def _require_cols(df: pd.DataFrame, cols: list[str], df_name: str = \"df\"):\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"{df_name} no tiene columnas necesarias: {missing}\")\n",
    "\n",
    "def _pick_global_pred():\n",
    "    if \"global_pred_test\" in globals():\n",
    "        return global_pred_test.copy(), \"global_pred_test\"\n",
    "    if \"global_pred\" in globals():\n",
    "        return global_pred.copy(), \"global_pred\"\n",
    "    raise NameError(\"No encuentro global_pred_test ni global_pred en memoria. Crea/carga predicciones globales primero.\")\n",
    "\n",
    "def _consolidate_cost(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    # Detecta coste: coste_devolucion o coste_devolucion_x/y\n",
    "    if \"coste_devolucion\" in out.columns:\n",
    "        cost = out[\"coste_devolucion\"]\n",
    "    else:\n",
    "        cands = [c for c in out.columns if c.startswith(\"coste_devolucion\")]\n",
    "        if not cands:\n",
    "            raise KeyError(\"No encuentro coste_devolucion ni variantes coste_devolucion_x/y.\")\n",
    "        # si hay x/y, bfill elige la primera no nula por fila\n",
    "        cost = out[cands].bfill(axis=1).iloc[:, 0] if len(cands) > 1 else out[cands[0]]\n",
    "\n",
    "    out[\"coste_devolucion\"] = pd.to_numeric(cost, errors=\"coerce\").fillna(0.0).astype(\"float32\")\n",
    "    out[\"has_coste\"] = (out[\"coste_devolucion\"] > 0).astype(\"int8\")\n",
    "\n",
    "    # Limpia columnas coste duplicadas\n",
    "    drop_cols = [c for c in out.columns if c.startswith(\"coste_devolucion\") and c != \"coste_devolucion\"]\n",
    "    out = out.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "    return out\n",
    "\n",
    "def _print_exec_kpis(bi_items: pd.DataFrame, title: str):\n",
    "    df = bi_items.copy()\n",
    "    df[\"cambia_talla\"] = pd.to_numeric(df[\"cambia_talla\"], errors=\"coerce\").fillna(0).astype(\"int8\")\n",
    "    df[\"expected_savings_talla\"] = pd.to_numeric(df[\"expected_savings_talla\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    n_items = len(df)\n",
    "    n_orders = df[\"ticket_id\"].nunique() if \"ticket_id\" in df.columns else np.nan\n",
    "    pct_item = float(df[\"cambia_talla\"].mean())\n",
    "    pct_order = float(df.groupby(\"ticket_id\")[\"cambia_talla\"].max().mean()) if \"ticket_id\" in df.columns else np.nan\n",
    "    savings_total = float(df[\"expected_savings_talla\"].sum())\n",
    "    savings_item = float(df[\"expected_savings_talla\"].mean())\n",
    "    savings_interv = float(df.loc[df[\"cambia_talla\"] == 1, \"expected_savings_talla\"].mean()) if df[\"cambia_talla\"].sum() > 0 else 0.0\n",
    "\n",
    "    p0 = float(pd.to_numeric(df[\"p_dev_actual\"], errors=\"coerce\").dropna().mean()) if \"p_dev_actual\" in df.columns else np.nan\n",
    "    p1 = float(pd.to_numeric(df[\"p_dev_final\"], errors=\"coerce\").dropna().mean()) if \"p_dev_final\" in df.columns else np.nan\n",
    "\n",
    "    print(f\"✅ {title}\")\n",
    "    print(f\"- Items: {n_items:,} | Pedidos: {n_orders:,}\")\n",
    "    print(f\"- Intervención: {pct_item:.2%} (items) | {pct_order:.2%} (pedidos)\")\n",
    "    print(f\"- Ahorro esperado total (talla): {savings_total:,.2f} €\")\n",
    "    print(f\"- Ahorro medio: {savings_item:,.2f} € por item | {savings_interv:,.2f} € por intervención\")\n",
    "    if not np.isnan(p0) and not np.isnan(p1):\n",
    "        print(f\"- Riesgo medio sin reco: {p0:.4f} | con reco: {p1:.4f} | Δp: {(p0 - p1):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0ed84237-c5b2-48bc-bb65-9f296823717c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CHECK UNIVERSO ===\n",
      "test_df2 existe: True\n",
      "test_df2 filas: 191954\n",
      "canales: {'online': 191954}\n",
      "fecha range: 2024-09-01 00:00:00 -> 2025-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"=== CHECK UNIVERSO ===\")\n",
    "print(\"test_df2 existe:\", \"test_df2\" in globals())\n",
    "if \"test_df2\" in globals():\n",
    "    print(\"test_df2 filas:\", len(test_df2))\n",
    "    print(\"canales:\", test_df2[\"canal\"].value_counts(dropna=False).head(5).to_dict() if \"canal\" in test_df2.columns else \"no canal\")\n",
    "    print(\"fecha range:\", test_df2[\"fecha_item\"].min(), \"->\", test_df2[\"fecha_item\"].max() if \"fecha_item\" in test_df2.columns else \"no fecha\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "df3da328-3e99-4821-af94-3cc18605bdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Predicciones globales (test del modelo global) creadas\n",
      "- Filas: 226362\n",
      "- Media p_dev_global: 0.5012995004653931\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>p_dev_global</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T378172-001</td>\n",
       "      <td>T378172</td>\n",
       "      <td>0.539345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T378172-002</td>\n",
       "      <td>T378172</td>\n",
       "      <td>0.309950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T378174-001</td>\n",
       "      <td>T378174</td>\n",
       "      <td>0.559957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id ticket_id  p_dev_global\n",
       "0  T378172-001   T378172      0.539345\n",
       "1  T378172-002   T378172      0.309950\n",
       "2  T378174-001   T378174      0.559957"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "GLOBAL_DATA_DIR = \"data/processed/devoluciones\"\n",
    "GLOBAL_MODEL_PATH = \"modelos/devoluciones/xgb_final.json\"\n",
    "\n",
    "X_TEST_PATH = os.path.join(GLOBAL_DATA_DIR, \"X_test.parquet\")\n",
    "TEST_INDEX_PATH = os.path.join(GLOBAL_DATA_DIR, \"test_index.parquet\")\n",
    "\n",
    "X_test_global = pd.read_parquet(X_TEST_PATH)\n",
    "test_index = pd.read_parquet(TEST_INDEX_PATH)\n",
    "\n",
    "required_idx_cols = [\"item_id\", \"ticket_id\"]\n",
    "missing = [c for c in required_idx_cols if c not in test_index.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"test_index.parquet no tiene columnas necesarias: {missing}\")\n",
    "\n",
    "if len(X_test_global) != len(test_index):\n",
    "    raise ValueError(f\"X_test ({len(X_test_global):,}) y test_index ({len(test_index):,}) no tienen la misma longitud.\")\n",
    "\n",
    "booster_global = xgb.Booster()\n",
    "booster_global.load_model(GLOBAL_MODEL_PATH)\n",
    "\n",
    "dtest_global = xgb.DMatrix(X_test_global)\n",
    "p_dev_global_test = booster_global.predict(dtest_global)\n",
    "\n",
    "global_pred_test = test_index[[\"item_id\", \"ticket_id\"]].copy()\n",
    "for c in [\"item_id\", \"ticket_id\"]:\n",
    "    global_pred_test[c] = global_pred_test[c].astype(str).str.strip()\n",
    "\n",
    "global_pred_test[\"p_dev_global\"] = pd.to_numeric(pd.Series(p_dev_global_test), errors=\"coerce\").astype(\"float32\")\n",
    "global_pred_test = global_pred_test.drop_duplicates(subset=[\"item_id\", \"ticket_id\"])\n",
    "\n",
    "print(\" Predicciones globales (test del modelo global) creadas\")\n",
    "print(\"- Filas:\", len(global_pred_test))\n",
    "print(\"- Media p_dev_global:\", float(global_pred_test[\"p_dev_global\"].mean()))\n",
    "display(global_pred_test.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6e85f25b-cdb6-4747-968e-e8d81f7b53ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test_df2_aligned creado\n",
      "- Filas: 191954\n",
      "- Cobertura p_dev_global: 69.68%\n",
      "- Media p_dev_global (no-NA): 0.5495098233222961\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# FULL | Alinear score global al universo del recomendador\n",
    "# =========================================================\n",
    "\n",
    "_require_cols(test_df2, KEYS, df_name=\"test_df2\")\n",
    "\n",
    "global_pred_use, global_pred_name = _pick_global_pred()\n",
    "_require_cols(global_pred_use, KEYS + [\"p_dev_global\"], df_name=global_pred_name)\n",
    "\n",
    "# Normaliza llaves\n",
    "for c in KEYS:\n",
    "    global_pred_use[c] = global_pred_use[c].astype(str).str.strip()\n",
    "\n",
    "test_df2_aligned = test_df2.copy()\n",
    "for c in KEYS:\n",
    "    test_df2_aligned[c] = test_df2_aligned[c].astype(str).str.strip()\n",
    "\n",
    "# Merge\n",
    "test_df2_aligned = test_df2_aligned.merge(\n",
    "    global_pred_use[KEYS + [\"p_dev_global\"]],\n",
    "    on=KEYS,\n",
    "    how=\"left\",\n",
    "    validate=\"m:1\"\n",
    ")\n",
    "\n",
    "cov = float(test_df2_aligned[\"p_dev_global\"].notna().mean())\n",
    "print(\" test_df2_aligned creado\")\n",
    "print(\"- Filas:\", len(test_df2_aligned))\n",
    "print(f\"- Cobertura p_dev_global: {cov:.2%}\")\n",
    "print(\"- Media p_dev_global (no-NA):\", float(pd.to_numeric(test_df2_aligned[\"p_dev_global\"], errors=\"coerce\").dropna().mean()) if cov > 0 else 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3c773b09-5d9f-4084-9312-7a8d4038f7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " recs_full generado\n",
      "- Filas recs_full: 191954\n",
      "- % intervención (items): 0.18784187878345854\n",
      "- Δp medio (todo): 0.03465647250413895\n",
      "- Δp medio (solo intervención): 0.184498131275177\n"
     ]
    }
   ],
   "source": [
    "# FULL | Recomendaciones definitivas para KPIs\n",
    "\n",
    "MIN_GAIN_PORTADA = 0.0   # pon 0.0 si quieres el comportamiento ~18% intervención\n",
    "\n",
    "recs_full, scen_full = recommend_sizes(\n",
    "    test_df2,         # usa el universo original del recomendador\n",
    "    max_step=2,\n",
    "    min_gain=float(MIN_GAIN_PORTADA)\n",
    ")\n",
    "\n",
    "print(\" recs_full generado\")\n",
    "print(\"- Filas recs_full:\", len(recs_full))\n",
    "print(\"- % intervención (items):\", float(pd.to_numeric(recs_full[\"cambia_talla\"], errors=\"coerce\").fillna(0).mean()))\n",
    "print(\"- Δp medio (todo):\", float(pd.to_numeric(recs_full[\"delta_p_final\"], errors=\"coerce\").fillna(0).mean()))\n",
    "print(\"- Δp medio (solo intervención):\",\n",
    "      float(pd.to_numeric(recs_full.loc[recs_full[\"cambia_talla\"] == 1, \"delta_p_final\"], errors=\"coerce\").fillna(0).mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ae610d27-a6f7-49b2-90a8-004b72741edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bi_items_full creado\n",
      "✅ PÁGINA 1 | RESUMEN EJECUTIVO (FULL)\n",
      "- Items: 191,954 | Pedidos: 132,024\n",
      "- Intervención: 18.78% (items) | 22.10% (pedidos)\n",
      "- Ahorro esperado total (talla): 25,074.35 €\n",
      "- Ahorro medio: 0.13 € por item | 0.70 € por intervención\n",
      "- Riesgo medio sin reco: 0.3472 | con reco: 0.3125 | Δp: 0.0347\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# FULL | Dataset BI definitivo (Power BI ready)\n",
    "# =========================================================\n",
    "\n",
    "base = test_df2_aligned.copy()\n",
    "\n",
    "# Coste + fecha\n",
    "_require_cols(base, [\"fecha_item\"], df_name=\"test_df2_aligned\")\n",
    "base[\"fecha_item\"] = pd.to_datetime(base[\"fecha_item\"], errors=\"coerce\")\n",
    "if base[\"fecha_item\"].isna().mean() > 0:\n",
    "    raise ValueError(\"Hay NA en fecha_item tras parseo. Revisa test_df2_aligned.\")\n",
    "\n",
    "base = _consolidate_cost(base)\n",
    "\n",
    "# Índice estable para merge con recs_full\n",
    "base = base.reset_index(drop=True).reset_index().rename(columns={\"index\": \"_orig_idx\"})\n",
    "\n",
    "recs_keep = recs_full[[\n",
    "    \"_orig_idx\", \"talla_reco\", \"talla_final\", \"cambia_talla\",\n",
    "    \"delta_p_final\", \"p_dev_actual\", \"p_dev_final\"\n",
    "]].copy()\n",
    "\n",
    "bi_items_full = base.merge(recs_keep, on=\"_orig_idx\", how=\"left\", validate=\"1:1\")\n",
    "\n",
    "# Limpieza defensiva\n",
    "bi_items_full[\"cambia_talla\"] = pd.to_numeric(bi_items_full[\"cambia_talla\"], errors=\"coerce\").fillna(0).astype(\"int8\")\n",
    "bi_items_full[\"delta_p_final\"] = pd.to_numeric(bi_items_full[\"delta_p_final\"], errors=\"coerce\").fillna(0.0).astype(\"float32\")\n",
    "\n",
    "# Métricas económicas\n",
    "bi_items_full[\"expected_savings_talla\"] = (bi_items_full[\"delta_p_final\"] * bi_items_full[\"coste_devolucion\"]).astype(\"float32\")\n",
    "\n",
    "bi_items_full[\"p_dev_global\"] = pd.to_numeric(bi_items_full[\"p_dev_global\"], errors=\"coerce\")\n",
    "bi_items_full[\"expected_cost_global\"] = (bi_items_full[\"p_dev_global\"] * bi_items_full[\"coste_devolucion\"]).astype(\"float32\")\n",
    "\n",
    "# Tiempo\n",
    "bi_items_full[\"year\"] = bi_items_full[\"fecha_item\"].dt.year.astype(\"int16\")\n",
    "bi_items_full[\"month\"] = bi_items_full[\"fecha_item\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "print(\" bi_items_full creado\")\n",
    "_print_exec_kpis(bi_items_full, title=\"PÁGINA 1 | RESUMEN EJECUTIVO (FULL)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ede1ef12-508e-44f7-9885-70debb9560df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PORTADA | Contexto modelo global (sin mezclar universos)\n",
      "- Cobertura p_dev_global: 69.68%\n",
      "- Coste esperado total devoluciones (cubierto): 262,662.19 €\n",
      "- Ahorro talla (solo cubiertos): 17,386.57 €\n",
      "- % del ahorro dentro de cubiertos: 69.34%\n",
      "- Share coste atacable por talla (cubierto): 6.62%\n"
     ]
    }
   ],
   "source": [
    "# PORTADA | Share atacable por talla (solo universo cubierto)\n",
    "\n",
    "df = bi_items_full.copy()\n",
    "\n",
    "cov = df[\"p_dev_global\"].notna()\n",
    "coverage = float(cov.mean())\n",
    "\n",
    "savings_all = float(df[\"expected_savings_talla\"].sum())\n",
    "savings_cov = float(df.loc[cov, \"expected_savings_talla\"].sum())\n",
    "cost_cov = float(df.loc[cov, \"expected_cost_global\"].sum())\n",
    "\n",
    "share_cov = float(savings_cov / (cost_cov + 1e-9))\n",
    "share_savings_covered = float(savings_cov / (savings_all + 1e-9))\n",
    "\n",
    "print(\" PORTADA | Contexto modelo global (sin mezclar universos)\")\n",
    "print(f\"- Cobertura p_dev_global: {coverage:.2%}\")\n",
    "print(f\"- Coste esperado total devoluciones (cubierto): {cost_cov:,.2f} €\")\n",
    "print(f\"- Ahorro talla (solo cubiertos): {savings_cov:,.2f} €\")\n",
    "print(f\"- % del ahorro dentro de cubiertos: {share_savings_covered:.2%}\")\n",
    "print(f\"- Share coste atacable por talla (cubierto): {share_cov:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8028d603-c417-4ea6-8ce4-4dec577d4984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kpi</th>\n",
       "      <th>valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Items analizados</td>\n",
       "      <td>191,954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pedidos analizados</td>\n",
       "      <td>132,024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>% items con recomendación</td>\n",
       "      <td>18.78%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>% pedidos afectados</td>\n",
       "      <td>22.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ahorro esperado total (talla)</td>\n",
       "      <td>25,074.35 €</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ahorro medio por item</td>\n",
       "      <td>0.13 €</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ahorro medio por intervención</td>\n",
       "      <td>0.70 €</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Riesgo medio sin recomendador (p_dev_actual)</td>\n",
       "      <td>0.3472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Riesgo medio con recomendador (p_dev_final)</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Δp medio (todo el universo)</td>\n",
       "      <td>0.0347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cobertura p_dev_global (items)</td>\n",
       "      <td>69.68%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Coste esperado total devoluciones (cubierto)</td>\n",
       "      <td>262,662.19 €</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Share coste atacable por talla (cubierto)</td>\n",
       "      <td>6.62%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             kpi         valor\n",
       "0                               Items analizados       191,954\n",
       "1                             Pedidos analizados       132,024\n",
       "2                      % items con recomendación        18.78%\n",
       "3                            % pedidos afectados        22.10%\n",
       "4                  Ahorro esperado total (talla)   25,074.35 €\n",
       "5                          Ahorro medio por item        0.13 €\n",
       "6                  Ahorro medio por intervención        0.70 €\n",
       "7   Riesgo medio sin recomendador (p_dev_actual)        0.3472\n",
       "8    Riesgo medio con recomendador (p_dev_final)        0.3125\n",
       "9                    Δp medio (todo el universo)        0.0347\n",
       "10                Cobertura p_dev_global (items)        69.68%\n",
       "11  Coste esperado total devoluciones (cubierto)  262,662.19 €\n",
       "12     Share coste atacable por talla (cubierto)         6.62%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Exportado: data/bi\\kpi_portada.csv\n"
     ]
    }
   ],
   "source": [
    "# PORTADA | Tabla KPI exportable\n",
    "\n",
    "df = bi_items_full.copy()\n",
    "\n",
    "items = int(len(df))\n",
    "orders = int(df[\"ticket_id\"].nunique())\n",
    "pct_items = float(df[\"cambia_talla\"].mean())\n",
    "pct_orders = float(df.groupby(\"ticket_id\")[\"cambia_talla\"].max().mean())\n",
    "\n",
    "savings_total = float(df[\"expected_savings_talla\"].sum())\n",
    "savings_item = float(df[\"expected_savings_talla\"].mean())\n",
    "savings_interv = float(df.loc[df[\"cambia_talla\"] == 1, \"expected_savings_talla\"].mean()) if df[\"cambia_talla\"].sum() > 0 else 0.0\n",
    "\n",
    "p0 = float(pd.to_numeric(df[\"p_dev_actual\"], errors=\"coerce\").dropna().mean())\n",
    "p1 = float(pd.to_numeric(df[\"p_dev_final\"], errors=\"coerce\").dropna().mean())\n",
    "delta_p = float(p0 - p1)\n",
    "\n",
    "cov = df[\"p_dev_global\"].notna()\n",
    "coverage = float(cov.mean())\n",
    "cost_cov = float(df.loc[cov, \"expected_cost_global\"].sum())\n",
    "savings_cov = float(df.loc[cov, \"expected_savings_talla\"].sum())\n",
    "share_cov = float(savings_cov / (cost_cov + 1e-9))\n",
    "\n",
    "kpi_portada = pd.DataFrame({\n",
    "    \"kpi\": [\n",
    "        \"Items analizados\",\n",
    "        \"Pedidos analizados\",\n",
    "        \"% items con recomendación\",\n",
    "        \"% pedidos afectados\",\n",
    "        \"Ahorro esperado total (talla)\",\n",
    "        \"Ahorro medio por item\",\n",
    "        \"Ahorro medio por intervención\",\n",
    "        \"Riesgo medio sin recomendador (p_dev_actual)\",\n",
    "        \"Riesgo medio con recomendador (p_dev_final)\",\n",
    "        \"Δp medio (todo el universo)\",\n",
    "        \"Cobertura p_dev_global (items)\",\n",
    "        \"Coste esperado total devoluciones (cubierto)\",\n",
    "        \"Share coste atacable por talla (cubierto)\"\n",
    "    ],\n",
    "    \"valor\": [\n",
    "        f\"{items:,}\",\n",
    "        f\"{orders:,}\",\n",
    "        f\"{pct_items:.2%}\",\n",
    "        f\"{pct_orders:.2%}\",\n",
    "        f\"{savings_total:,.2f} €\",\n",
    "        f\"{savings_item:,.2f} €\",\n",
    "        f\"{savings_interv:,.2f} €\",\n",
    "        f\"{p0:.4f}\",\n",
    "        f\"{p1:.4f}\",\n",
    "        f\"{delta_p:.4f}\",\n",
    "        f\"{coverage:.2%}\",\n",
    "        f\"{cost_cov:,.2f} €\",\n",
    "        f\"{share_cov:.2%}\",\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(kpi_portada)\n",
    "\n",
    "kpi_portada.to_csv(os.path.join(BI_DIR, \"kpi_portada.csv\"), index=False)\n",
    "print(\" Exportado:\", os.path.join(BI_DIR, \"kpi_portada.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2045bd98-7755-49e1-aac6-0bc6f0824f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " KPI portada exportados (Power BI ready)\n",
      "- data/bi\\kpi_portada_long.csv\n",
      "- data/bi\\kpi_portada_wide.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kpi</th>\n",
       "      <th>value_num</th>\n",
       "      <th>unit</th>\n",
       "      <th>value_text</th>\n",
       "      <th>format_hint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Items analizados</td>\n",
       "      <td>191954.000000</td>\n",
       "      <td>count</td>\n",
       "      <td>191954</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pedidos analizados</td>\n",
       "      <td>132024.000000</td>\n",
       "      <td>count</td>\n",
       "      <td>132024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>% items con recomendación</td>\n",
       "      <td>0.187842</td>\n",
       "      <td>pct</td>\n",
       "      <td>0.187842</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>% pedidos afectados</td>\n",
       "      <td>0.221036</td>\n",
       "      <td>pct</td>\n",
       "      <td>0.221036</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ahorro esperado total (talla)</td>\n",
       "      <td>25074.347656</td>\n",
       "      <td>eur</td>\n",
       "      <td>25074.35</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ahorro medio por item</td>\n",
       "      <td>0.130627</td>\n",
       "      <td>eur</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ahorro medio por intervención</td>\n",
       "      <td>0.695409</td>\n",
       "      <td>eur</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Riesgo medio sin recomendador (p_dev_actual)</td>\n",
       "      <td>0.347177</td>\n",
       "      <td>prob</td>\n",
       "      <td>0.347177</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Riesgo medio con recomendador (p_dev_final)</td>\n",
       "      <td>0.312520</td>\n",
       "      <td>prob</td>\n",
       "      <td>0.312520</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Δp medio (todo el universo)</td>\n",
       "      <td>0.034656</td>\n",
       "      <td>prob</td>\n",
       "      <td>0.034656</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cobertura p_dev_global (items)</td>\n",
       "      <td>0.696818</td>\n",
       "      <td>pct</td>\n",
       "      <td>0.696818</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Coste esperado total devoluciones (cubierto)</td>\n",
       "      <td>262662.187500</td>\n",
       "      <td>eur</td>\n",
       "      <td>262662.19</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Share coste atacable por talla (cubierto)</td>\n",
       "      <td>0.066194</td>\n",
       "      <td>pct</td>\n",
       "      <td>0.066194</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             kpi      value_num   unit  \\\n",
       "0                               Items analizados  191954.000000  count   \n",
       "1                             Pedidos analizados  132024.000000  count   \n",
       "2                      % items con recomendación       0.187842    pct   \n",
       "3                            % pedidos afectados       0.221036    pct   \n",
       "4                  Ahorro esperado total (talla)   25074.347656    eur   \n",
       "5                          Ahorro medio por item       0.130627    eur   \n",
       "6                  Ahorro medio por intervención       0.695409    eur   \n",
       "7   Riesgo medio sin recomendador (p_dev_actual)       0.347177   prob   \n",
       "8    Riesgo medio con recomendador (p_dev_final)       0.312520   prob   \n",
       "9                    Δp medio (todo el universo)       0.034656   prob   \n",
       "10                Cobertura p_dev_global (items)       0.696818    pct   \n",
       "11  Coste esperado total devoluciones (cubierto)  262662.187500    eur   \n",
       "12     Share coste atacable por talla (cubierto)       0.066194    pct   \n",
       "\n",
       "   value_text format_hint  \n",
       "0      191954           0  \n",
       "1      132024           0  \n",
       "2    0.187842       0.00%  \n",
       "3    0.221036       0.00%  \n",
       "4    25074.35        0.00  \n",
       "5        0.13        0.00  \n",
       "6        0.70        0.00  \n",
       "7    0.347177      0.0000  \n",
       "8    0.312520      0.0000  \n",
       "9    0.034656      0.0000  \n",
       "10   0.696818       0.00%  \n",
       "11  262662.19        0.00  \n",
       "12   0.066194       0.00%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>items_analizados</th>\n",
       "      <th>pedidos_analizados</th>\n",
       "      <th>pct_items_reco</th>\n",
       "      <th>pct_pedidos_afectados</th>\n",
       "      <th>ahorro_total_talla_eur</th>\n",
       "      <th>ahorro_medio_item_eur</th>\n",
       "      <th>ahorro_medio_interv_eur</th>\n",
       "      <th>riesgo_medio_sin_reco</th>\n",
       "      <th>riesgo_medio_con_reco</th>\n",
       "      <th>delta_p_medio</th>\n",
       "      <th>cobertura_p_dev_global</th>\n",
       "      <th>coste_esperado_total_cubierto_eur</th>\n",
       "      <th>share_coste_atacable_talla_cubierto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>191954</td>\n",
       "      <td>132024</td>\n",
       "      <td>0.187842</td>\n",
       "      <td>0.221036</td>\n",
       "      <td>25074.347656</td>\n",
       "      <td>0.130627</td>\n",
       "      <td>0.695409</td>\n",
       "      <td>0.347177</td>\n",
       "      <td>0.31252</td>\n",
       "      <td>0.034656</td>\n",
       "      <td>0.696818</td>\n",
       "      <td>262662.1875</td>\n",
       "      <td>0.066194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   items_analizados  pedidos_analizados  pct_items_reco  \\\n",
       "0            191954              132024        0.187842   \n",
       "\n",
       "   pct_pedidos_afectados  ahorro_total_talla_eur  ahorro_medio_item_eur  \\\n",
       "0               0.221036            25074.347656               0.130627   \n",
       "\n",
       "   ahorro_medio_interv_eur  riesgo_medio_sin_reco  riesgo_medio_con_reco  \\\n",
       "0                 0.695409               0.347177                0.31252   \n",
       "\n",
       "   delta_p_medio  cobertura_p_dev_global  coste_esperado_total_cubierto_eur  \\\n",
       "0       0.034656                0.696818                        262662.1875   \n",
       "\n",
       "   share_coste_atacable_talla_cubierto  \n",
       "0                             0.066194  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PORTADA | KPIs \"Power BI ready\" (wide + long)\n",
    "# - Wide: 1 fila, 1 columna por KPI (ideal para tarjetas)\n",
    "# - Long: 1 fila por KPI, con valor_num + valor_text (más flexible)\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = bi_items_full.copy()\n",
    "\n",
    "required = [\n",
    "    \"ticket_id\", \"cambia_talla\", \"expected_savings_talla\",\n",
    "    \"p_dev_actual\", \"p_dev_final\",\n",
    "]\n",
    "missing = [c for c in required if c not in df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"bi_items_full no tiene columnas necesarias: {missing}\")\n",
    "\n",
    "# básicos\n",
    "items = int(len(df))\n",
    "orders = int(df[\"ticket_id\"].nunique())\n",
    "\n",
    "pct_items = float(pd.to_numeric(df[\"cambia_talla\"], errors=\"coerce\").fillna(0).mean())\n",
    "pct_orders = float(df.groupby(\"ticket_id\")[\"cambia_talla\"].max().mean())\n",
    "\n",
    "savings_total = float(pd.to_numeric(df[\"expected_savings_talla\"], errors=\"coerce\").fillna(0).sum())\n",
    "savings_item = float(pd.to_numeric(df[\"expected_savings_talla\"], errors=\"coerce\").fillna(0).mean())\n",
    "\n",
    "if int(df[\"cambia_talla\"].sum()) > 0:\n",
    "    savings_interv = float(df.loc[df[\"cambia_talla\"] == 1, \"expected_savings_talla\"].mean())\n",
    "else:\n",
    "    savings_interv = 0.0\n",
    "\n",
    "p0 = float(pd.to_numeric(df[\"p_dev_actual\"], errors=\"coerce\").dropna().mean())\n",
    "p1 = float(pd.to_numeric(df[\"p_dev_final\"], errors=\"coerce\").dropna().mean())\n",
    "delta_p = float(p0 - p1)\n",
    "\n",
    "# opcional: contexto global (solo si existe)\n",
    "has_global = (\"p_dev_global\" in df.columns) and (\"expected_cost_global\" in df.columns)\n",
    "if has_global:\n",
    "    cov = df[\"p_dev_global\"].notna()\n",
    "    coverage = float(cov.mean())\n",
    "    cost_cov = float(pd.to_numeric(df.loc[cov, \"expected_cost_global\"], errors=\"coerce\").fillna(0).sum())\n",
    "    savings_cov = float(pd.to_numeric(df.loc[cov, \"expected_savings_talla\"], errors=\"coerce\").fillna(0).sum())\n",
    "    share_cov = float(savings_cov / (cost_cov + 1e-9))\n",
    "else:\n",
    "    coverage = np.nan\n",
    "    cost_cov = np.nan\n",
    "    share_cov = np.nan\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1) LONG: una fila por KPI (numérico + texto + unidad)\n",
    "# ---------------------------------------------------------\n",
    "kpi_specs = [\n",
    "    (\"Items analizados\", items, \"count\"),\n",
    "    (\"Pedidos analizados\", orders, \"count\"),\n",
    "    (\"% items con recomendación\", pct_items, \"pct\"),\n",
    "    (\"% pedidos afectados\", pct_orders, \"pct\"),\n",
    "    (\"Ahorro esperado total (talla)\", savings_total, \"eur\"),\n",
    "    (\"Ahorro medio por item\", savings_item, \"eur\"),\n",
    "    (\"Ahorro medio por intervención\", savings_interv, \"eur\"),\n",
    "    (\"Riesgo medio sin recomendador (p_dev_actual)\", p0, \"prob\"),\n",
    "    (\"Riesgo medio con recomendador (p_dev_final)\", p1, \"prob\"),\n",
    "    (\"Δp medio (todo el universo)\", delta_p, \"prob\"),\n",
    "    (\"Cobertura p_dev_global (items)\", coverage, \"pct\"),\n",
    "    (\"Coste esperado total devoluciones (cubierto)\", cost_cov, \"eur\"),\n",
    "    (\"Share coste atacable por talla (cubierto)\", share_cov, \"pct\"),\n",
    "]\n",
    "\n",
    "def _format_value(x: float, unit: str) -> str:\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    if unit == \"count\":\n",
    "        return f\"{int(round(float(x))):,}\".replace(\",\", \"\")\n",
    "    if unit == \"eur\":\n",
    "        return f\"{float(x):.2f}\"\n",
    "    if unit == \"pct\":\n",
    "        return f\"{float(x):.6f}\"  # en Power BI lo formateas como %\n",
    "    if unit == \"prob\":\n",
    "        return f\"{float(x):.6f}\"\n",
    "    return str(x)\n",
    "\n",
    "kpi_long = pd.DataFrame(\n",
    "    [{\n",
    "        \"kpi\": name,\n",
    "        \"value_num\": (np.nan if pd.isna(val) else float(val)),\n",
    "        \"unit\": unit,\n",
    "        \"value_text\": _format_value(val, unit),\n",
    "    } for (name, val, unit) in kpi_specs]\n",
    ")\n",
    "\n",
    "# Sugerencia de formato para Power BI (opcional, ayuda a documentar)\n",
    "fmt_map = {\"count\": \"0\", \"eur\": \"0.00\", \"pct\": \"0.00%\", \"prob\": \"0.0000\"}\n",
    "kpi_long[\"format_hint\"] = kpi_long[\"unit\"].map(fmt_map).fillna(\"\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2) WIDE: 1 fila con columnas numéricas (tarjetas directas)\n",
    "# ---------------------------------------------------------\n",
    "kpi_wide = pd.DataFrame([{\n",
    "    \"items_analizados\": items,\n",
    "    \"pedidos_analizados\": orders,\n",
    "    \"pct_items_reco\": pct_items,\n",
    "    \"pct_pedidos_afectados\": pct_orders,\n",
    "    \"ahorro_total_talla_eur\": savings_total,\n",
    "    \"ahorro_medio_item_eur\": savings_item,\n",
    "    \"ahorro_medio_interv_eur\": savings_interv,\n",
    "    \"riesgo_medio_sin_reco\": p0,\n",
    "    \"riesgo_medio_con_reco\": p1,\n",
    "    \"delta_p_medio\": delta_p,\n",
    "    \"cobertura_p_dev_global\": coverage,\n",
    "    \"coste_esperado_total_cubierto_eur\": cost_cov,\n",
    "    \"share_coste_atacable_talla_cubierto\": share_cov,\n",
    "}])\n",
    "\n",
    "# Export\n",
    "os.makedirs(BI_DIR, exist_ok=True)\n",
    "\n",
    "path_long = os.path.join(BI_DIR, \"kpi_portada_long.csv\")\n",
    "path_wide = os.path.join(BI_DIR, \"kpi_portada_wide.csv\")\n",
    "\n",
    "kpi_long.to_csv(path_long, index=False)\n",
    "kpi_wide.to_csv(path_wide, index=False)\n",
    "\n",
    "print(\" KPI portada exportados (Power BI ready)\")\n",
    "print(\"-\", path_long)\n",
    "print(\"-\", path_wide)\n",
    "\n",
    "display(kpi_long)\n",
    "display(kpi_wide)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5eaccc96-fcd4-4dd0-b619-578f9847900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PÁGINA 2 | Tablas listas\n",
      "- by_category: (5, 7)\n",
      "- by_product_top: (22, 7)\n",
      "- month_summary: (13, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoria</th>\n",
       "      <th>n_items</th>\n",
       "      <th>n_orders</th>\n",
       "      <th>pct_interv</th>\n",
       "      <th>savings_total</th>\n",
       "      <th>savings_mean_item</th>\n",
       "      <th>savings_mean_interv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abrigo</td>\n",
       "      <td>62485</td>\n",
       "      <td>55514</td>\n",
       "      <td>0.251964</td>\n",
       "      <td>14933.295898</td>\n",
       "      <td>0.238990</td>\n",
       "      <td>0.948507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pantalon</td>\n",
       "      <td>39494</td>\n",
       "      <td>36590</td>\n",
       "      <td>0.128374</td>\n",
       "      <td>3867.003418</td>\n",
       "      <td>0.097914</td>\n",
       "      <td>0.762723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>camiseta</td>\n",
       "      <td>56030</td>\n",
       "      <td>50327</td>\n",
       "      <td>0.120667</td>\n",
       "      <td>2871.069092</td>\n",
       "      <td>0.051242</td>\n",
       "      <td>0.424652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>camisa</td>\n",
       "      <td>17199</td>\n",
       "      <td>16606</td>\n",
       "      <td>0.372696</td>\n",
       "      <td>1763.111938</td>\n",
       "      <td>0.102512</td>\n",
       "      <td>0.275056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sudadera</td>\n",
       "      <td>16746</td>\n",
       "      <td>16203</td>\n",
       "      <td>0.123731</td>\n",
       "      <td>1639.867310</td>\n",
       "      <td>0.097926</td>\n",
       "      <td>0.791442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  categoria  n_items  n_orders  pct_interv  savings_total  savings_mean_item  \\\n",
       "0    abrigo    62485     55514    0.251964   14933.295898           0.238990   \n",
       "1  pantalon    39494     36590    0.128374    3867.003418           0.097914   \n",
       "2  camiseta    56030     50327    0.120667    2871.069092           0.051242   \n",
       "3    camisa    17199     16606    0.372696    1763.111938           0.102512   \n",
       "4  sudadera    16746     16203    0.123731    1639.867310           0.097926   \n",
       "\n",
       "   savings_mean_interv  \n",
       "0             0.948507  \n",
       "1             0.762723  \n",
       "2             0.424652  \n",
       "3             0.275056  \n",
       "4             0.791442  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_producto</th>\n",
       "      <th>categoria</th>\n",
       "      <th>n_items</th>\n",
       "      <th>n_orders</th>\n",
       "      <th>pct_interv</th>\n",
       "      <th>savings_total</th>\n",
       "      <th>savings_mean_interv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P047</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>11004</td>\n",
       "      <td>10789</td>\n",
       "      <td>0.848237</td>\n",
       "      <td>6711.040527</td>\n",
       "      <td>0.718989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P013</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>13200</td>\n",
       "      <td>12866</td>\n",
       "      <td>0.122576</td>\n",
       "      <td>2112.063721</td>\n",
       "      <td>1.305355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P020</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>10665</td>\n",
       "      <td>10460</td>\n",
       "      <td>0.123019</td>\n",
       "      <td>1744.149536</td>\n",
       "      <td>1.329382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P005</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>10722</td>\n",
       "      <td>10498</td>\n",
       "      <td>0.122738</td>\n",
       "      <td>1729.842285</td>\n",
       "      <td>1.314470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P058</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>10660</td>\n",
       "      <td>10424</td>\n",
       "      <td>0.124953</td>\n",
       "      <td>1612.811279</td>\n",
       "      <td>1.210819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P008</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>13691</td>\n",
       "      <td>13334</td>\n",
       "      <td>0.130889</td>\n",
       "      <td>1381.661011</td>\n",
       "      <td>0.771016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P003</td>\n",
       "      <td>sudadera</td>\n",
       "      <td>13760</td>\n",
       "      <td>13411</td>\n",
       "      <td>0.123837</td>\n",
       "      <td>1342.200562</td>\n",
       "      <td>0.787676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P042</td>\n",
       "      <td>camisa</td>\n",
       "      <td>11017</td>\n",
       "      <td>10773</td>\n",
       "      <td>0.508941</td>\n",
       "      <td>1245.537598</td>\n",
       "      <td>0.222140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P024</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>10891</td>\n",
       "      <td>10661</td>\n",
       "      <td>0.133505</td>\n",
       "      <td>1121.135620</td>\n",
       "      <td>0.771070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P004</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>10814</td>\n",
       "      <td>10603</td>\n",
       "      <td>0.120862</td>\n",
       "      <td>974.602295</td>\n",
       "      <td>0.745679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P002</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>13442</td>\n",
       "      <td>13092</td>\n",
       "      <td>0.120146</td>\n",
       "      <td>681.258118</td>\n",
       "      <td>0.421832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P016</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>10848</td>\n",
       "      <td>10624</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>591.799072</td>\n",
       "      <td>0.436430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P006</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>10903</td>\n",
       "      <td>10648</td>\n",
       "      <td>0.120792</td>\n",
       "      <td>572.973694</td>\n",
       "      <td>0.435060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P001</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>10841</td>\n",
       "      <td>10629</td>\n",
       "      <td>0.118808</td>\n",
       "      <td>532.958008</td>\n",
       "      <td>0.413787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P069</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>3207</td>\n",
       "      <td>3161</td>\n",
       "      <td>0.135329</td>\n",
       "      <td>523.081299</td>\n",
       "      <td>1.205256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P059</td>\n",
       "      <td>abrigo</td>\n",
       "      <td>3027</td>\n",
       "      <td>2992</td>\n",
       "      <td>0.131483</td>\n",
       "      <td>500.307251</td>\n",
       "      <td>1.257053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>P065</td>\n",
       "      <td>pantalon</td>\n",
       "      <td>4098</td>\n",
       "      <td>4029</td>\n",
       "      <td>0.126159</td>\n",
       "      <td>389.604584</td>\n",
       "      <td>0.753587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>P064</td>\n",
       "      <td>camiseta</td>\n",
       "      <td>6946</td>\n",
       "      <td>6795</td>\n",
       "      <td>0.119637</td>\n",
       "      <td>349.477875</td>\n",
       "      <td>0.420551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>P060</td>\n",
       "      <td>sudadera</td>\n",
       "      <td>2986</td>\n",
       "      <td>2950</td>\n",
       "      <td>0.123242</td>\n",
       "      <td>297.666687</td>\n",
       "      <td>0.808877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>P066</td>\n",
       "      <td>camisa</td>\n",
       "      <td>3052</td>\n",
       "      <td>3006</td>\n",
       "      <td>0.134010</td>\n",
       "      <td>263.302612</td>\n",
       "      <td>0.643772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_producto categoria  n_items  n_orders  pct_interv  savings_total  \\\n",
       "0         P047    abrigo    11004     10789    0.848237    6711.040527   \n",
       "1         P013    abrigo    13200     12866    0.122576    2112.063721   \n",
       "2         P020    abrigo    10665     10460    0.123019    1744.149536   \n",
       "3         P005    abrigo    10722     10498    0.122738    1729.842285   \n",
       "4         P058    abrigo    10660     10424    0.124953    1612.811279   \n",
       "5         P008  pantalon    13691     13334    0.130889    1381.661011   \n",
       "6         P003  sudadera    13760     13411    0.123837    1342.200562   \n",
       "7         P042    camisa    11017     10773    0.508941    1245.537598   \n",
       "8         P024  pantalon    10891     10661    0.133505    1121.135620   \n",
       "9         P004  pantalon    10814     10603    0.120862     974.602295   \n",
       "10        P002  camiseta    13442     13092    0.120146     681.258118   \n",
       "11        P016  camiseta    10848     10624    0.125000     591.799072   \n",
       "12        P006  camiseta    10903     10648    0.120792     572.973694   \n",
       "13        P001  camiseta    10841     10629    0.118808     532.958008   \n",
       "14        P069    abrigo     3207      3161    0.135329     523.081299   \n",
       "15        P059    abrigo     3027      2992    0.131483     500.307251   \n",
       "16        P065  pantalon     4098      4029    0.126159     389.604584   \n",
       "17        P064  camiseta     6946      6795    0.119637     349.477875   \n",
       "18        P060  sudadera     2986      2950    0.123242     297.666687   \n",
       "19        P066    camisa     3052      3006    0.134010     263.302612   \n",
       "\n",
       "    savings_mean_interv  \n",
       "0              0.718989  \n",
       "1              1.305355  \n",
       "2              1.329382  \n",
       "3              1.314470  \n",
       "4              1.210819  \n",
       "5              0.771016  \n",
       "6              0.787676  \n",
       "7              0.222140  \n",
       "8              0.771070  \n",
       "9              0.745679  \n",
       "10             0.421832  \n",
       "11             0.436430  \n",
       "12             0.435060  \n",
       "13             0.413787  \n",
       "14             1.205256  \n",
       "15             1.257053  \n",
       "16             0.753587  \n",
       "17             0.420551  \n",
       "18             0.808877  \n",
       "19             0.643772  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>n_items</th>\n",
       "      <th>n_orders</th>\n",
       "      <th>pct_interv</th>\n",
       "      <th>savings_total</th>\n",
       "      <th>savings_mean_item</th>\n",
       "      <th>savings_mean_interv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-09</td>\n",
       "      <td>12388</td>\n",
       "      <td>8593</td>\n",
       "      <td>0.190911</td>\n",
       "      <td>1664.296875</td>\n",
       "      <td>0.134347</td>\n",
       "      <td>0.703720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-10</td>\n",
       "      <td>13174</td>\n",
       "      <td>9141</td>\n",
       "      <td>0.194019</td>\n",
       "      <td>1766.463135</td>\n",
       "      <td>0.134087</td>\n",
       "      <td>0.691105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-11</td>\n",
       "      <td>15934</td>\n",
       "      <td>11053</td>\n",
       "      <td>0.186206</td>\n",
       "      <td>2086.595703</td>\n",
       "      <td>0.130952</td>\n",
       "      <td>0.703268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>16226</td>\n",
       "      <td>11275</td>\n",
       "      <td>0.186614</td>\n",
       "      <td>2128.842041</td>\n",
       "      <td>0.131199</td>\n",
       "      <td>0.703052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025-01</td>\n",
       "      <td>15393</td>\n",
       "      <td>10674</td>\n",
       "      <td>0.182680</td>\n",
       "      <td>2038.308716</td>\n",
       "      <td>0.132418</td>\n",
       "      <td>0.724861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025-02</td>\n",
       "      <td>15300</td>\n",
       "      <td>10336</td>\n",
       "      <td>0.205294</td>\n",
       "      <td>2244.334717</td>\n",
       "      <td>0.146689</td>\n",
       "      <td>0.714529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025-03</td>\n",
       "      <td>15164</td>\n",
       "      <td>10471</td>\n",
       "      <td>0.181812</td>\n",
       "      <td>1943.428467</td>\n",
       "      <td>0.128161</td>\n",
       "      <td>0.704907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025-04</td>\n",
       "      <td>14808</td>\n",
       "      <td>10143</td>\n",
       "      <td>0.183482</td>\n",
       "      <td>1918.897705</td>\n",
       "      <td>0.129585</td>\n",
       "      <td>0.706256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025-05</td>\n",
       "      <td>14827</td>\n",
       "      <td>10184</td>\n",
       "      <td>0.183584</td>\n",
       "      <td>1892.314087</td>\n",
       "      <td>0.127626</td>\n",
       "      <td>0.695193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025-06</td>\n",
       "      <td>15030</td>\n",
       "      <td>10390</td>\n",
       "      <td>0.179375</td>\n",
       "      <td>1826.288086</td>\n",
       "      <td>0.121510</td>\n",
       "      <td>0.677407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025-07</td>\n",
       "      <td>17040</td>\n",
       "      <td>11801</td>\n",
       "      <td>0.186737</td>\n",
       "      <td>2161.657227</td>\n",
       "      <td>0.126858</td>\n",
       "      <td>0.679339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025-08</td>\n",
       "      <td>14252</td>\n",
       "      <td>9609</td>\n",
       "      <td>0.192675</td>\n",
       "      <td>1778.747803</td>\n",
       "      <td>0.124807</td>\n",
       "      <td>0.647760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year    month  n_items  n_orders  pct_interv  savings_total  \\\n",
       "0   2024  2024-09    12388      8593    0.190911    1664.296875   \n",
       "1   2024  2024-10    13174      9141    0.194019    1766.463135   \n",
       "2   2024  2024-11    15934     11053    0.186206    2086.595703   \n",
       "3   2024  2024-12    16226     11275    0.186614    2128.842041   \n",
       "4   2025  2025-01    15393     10674    0.182680    2038.308716   \n",
       "5   2025  2025-02    15300     10336    0.205294    2244.334717   \n",
       "6   2025  2025-03    15164     10471    0.181812    1943.428467   \n",
       "7   2025  2025-04    14808     10143    0.183482    1918.897705   \n",
       "8   2025  2025-05    14827     10184    0.183584    1892.314087   \n",
       "9   2025  2025-06    15030     10390    0.179375    1826.288086   \n",
       "10  2025  2025-07    17040     11801    0.186737    2161.657227   \n",
       "11  2025  2025-08    14252      9609    0.192675    1778.747803   \n",
       "\n",
       "    savings_mean_item  savings_mean_interv  \n",
       "0            0.134347             0.703720  \n",
       "1            0.134087             0.691105  \n",
       "2            0.130952             0.703268  \n",
       "3            0.131199             0.703052  \n",
       "4            0.132418             0.724861  \n",
       "5            0.146689             0.714529  \n",
       "6            0.128161             0.704907  \n",
       "7            0.129585             0.706256  \n",
       "8            0.127626             0.695193  \n",
       "9            0.121510             0.677407  \n",
       "10           0.126858             0.679339  \n",
       "11           0.124807             0.647760  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Exportados: by_category.csv, by_product_top.csv, month_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# PÁGINA 2 | Tablas de priorización\n",
    "\n",
    "\n",
    "df = bi_items_full.copy()\n",
    "\n",
    "_require_cols(df, [\"categoria\", \"id_producto\", \"ticket_id\", \"cambia_talla\", \"expected_savings_talla\", \"year\", \"month\"], df_name=\"bi_items_full\")\n",
    "\n",
    "by_category = (\n",
    "    df.groupby(\"categoria\", as_index=False)\n",
    "      .agg(\n",
    "          n_items=(\"ticket_id\", \"size\"),\n",
    "          n_orders=(\"ticket_id\", \"nunique\"),\n",
    "          pct_interv=(\"cambia_talla\", \"mean\"),\n",
    "          savings_total=(\"expected_savings_talla\", \"sum\"),\n",
    "          savings_mean_item=(\"expected_savings_talla\", \"mean\"),\n",
    "          savings_mean_interv=(\"expected_savings_talla\",\n",
    "                              lambda s: float(np.mean(s[df.loc[s.index, \"cambia_talla\"] == 1]))\n",
    "                              if df.loc[s.index, \"cambia_talla\"].sum() > 0 else 0.0),\n",
    "      )\n",
    "      .sort_values(\"savings_total\", ascending=False)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "by_product_top = (\n",
    "    df.groupby([\"id_producto\", \"categoria\"], as_index=False)\n",
    "      .agg(\n",
    "          n_items=(\"ticket_id\", \"size\"),\n",
    "          n_orders=(\"ticket_id\", \"nunique\"),\n",
    "          pct_interv=(\"cambia_talla\", \"mean\"),\n",
    "          savings_total=(\"expected_savings_talla\", \"sum\"),\n",
    "          savings_mean_interv=(\"expected_savings_talla\",\n",
    "                              lambda s: float(np.mean(s[df.loc[s.index, \"cambia_talla\"] == 1]))\n",
    "                              if df.loc[s.index, \"cambia_talla\"].sum() > 0 else 0.0),\n",
    "      )\n",
    ")\n",
    "\n",
    "MIN_N_PROD = 500\n",
    "by_product_top = (\n",
    "    by_product_top[by_product_top[\"n_items\"] >= MIN_N_PROD]\n",
    "    .sort_values(\"savings_total\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "month_summary = (\n",
    "    df.groupby([\"year\", \"month\"], as_index=False)\n",
    "      .agg(\n",
    "          n_items=(\"ticket_id\", \"size\"),\n",
    "          n_orders=(\"ticket_id\", \"nunique\"),\n",
    "          pct_interv=(\"cambia_talla\", \"mean\"),\n",
    "          savings_total=(\"expected_savings_talla\", \"sum\"),\n",
    "          savings_mean_item=(\"expected_savings_talla\", \"mean\"),\n",
    "          savings_mean_interv=(\"expected_savings_talla\",\n",
    "                              lambda s: float(np.mean(s[df.loc[s.index, \"cambia_talla\"] == 1]))\n",
    "                              if df.loc[s.index, \"cambia_talla\"].sum() > 0 else 0.0),\n",
    "      )\n",
    "      .sort_values([\"year\", \"month\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\" PÁGINA 2 | Tablas listas\")\n",
    "print(\"- by_category:\", by_category.shape)\n",
    "print(\"- by_product_top:\", by_product_top.shape)\n",
    "print(\"- month_summary:\", month_summary.shape)\n",
    "\n",
    "display(by_category)\n",
    "display(by_product_top.head(20))\n",
    "display(month_summary.head(12))\n",
    "\n",
    "by_category.to_csv(os.path.join(BI_DIR, \"by_category.csv\"), index=False)\n",
    "by_product_top.to_csv(os.path.join(BI_DIR, \"by_product_top.csv\"), index=False)\n",
    "month_summary.to_csv(os.path.join(BI_DIR, \"month_summary.csv\"), index=False)\n",
    "\n",
    "print(\" Exportados: by_category.csv, by_product_top.csv, month_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0a48a164-e5b1-4cf8-9197-861c8112dc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PÁGINA 2 | Top 10 por categoría: (22, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoria</th>\n",
       "      <th>id_producto</th>\n",
       "      <th>n_items</th>\n",
       "      <th>n_orders</th>\n",
       "      <th>pct_interv</th>\n",
       "      <th>savings_total</th>\n",
       "      <th>savings_mean_interv</th>\n",
       "      <th>rank_in_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abrigo</td>\n",
       "      <td>P047</td>\n",
       "      <td>11004</td>\n",
       "      <td>10789</td>\n",
       "      <td>0.848237</td>\n",
       "      <td>6711.040527</td>\n",
       "      <td>0.718989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abrigo</td>\n",
       "      <td>P013</td>\n",
       "      <td>13200</td>\n",
       "      <td>12866</td>\n",
       "      <td>0.122576</td>\n",
       "      <td>2112.063721</td>\n",
       "      <td>1.305355</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abrigo</td>\n",
       "      <td>P020</td>\n",
       "      <td>10665</td>\n",
       "      <td>10460</td>\n",
       "      <td>0.123019</td>\n",
       "      <td>1744.149536</td>\n",
       "      <td>1.329382</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abrigo</td>\n",
       "      <td>P005</td>\n",
       "      <td>10722</td>\n",
       "      <td>10498</td>\n",
       "      <td>0.122738</td>\n",
       "      <td>1729.842285</td>\n",
       "      <td>1.314470</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abrigo</td>\n",
       "      <td>P058</td>\n",
       "      <td>10660</td>\n",
       "      <td>10424</td>\n",
       "      <td>0.124953</td>\n",
       "      <td>1612.811279</td>\n",
       "      <td>1.210819</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abrigo</td>\n",
       "      <td>P069</td>\n",
       "      <td>3207</td>\n",
       "      <td>3161</td>\n",
       "      <td>0.135329</td>\n",
       "      <td>523.081299</td>\n",
       "      <td>1.205256</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abrigo</td>\n",
       "      <td>P059</td>\n",
       "      <td>3027</td>\n",
       "      <td>2992</td>\n",
       "      <td>0.131483</td>\n",
       "      <td>500.307251</td>\n",
       "      <td>1.257053</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>camisa</td>\n",
       "      <td>P042</td>\n",
       "      <td>11017</td>\n",
       "      <td>10773</td>\n",
       "      <td>0.508941</td>\n",
       "      <td>1245.537598</td>\n",
       "      <td>0.222140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>camisa</td>\n",
       "      <td>P066</td>\n",
       "      <td>3052</td>\n",
       "      <td>3006</td>\n",
       "      <td>0.134010</td>\n",
       "      <td>263.302612</td>\n",
       "      <td>0.643772</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>camisa</td>\n",
       "      <td>P062</td>\n",
       "      <td>3130</td>\n",
       "      <td>3092</td>\n",
       "      <td>0.125879</td>\n",
       "      <td>254.271744</td>\n",
       "      <td>0.645360</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>camiseta</td>\n",
       "      <td>P002</td>\n",
       "      <td>13442</td>\n",
       "      <td>13092</td>\n",
       "      <td>0.120146</td>\n",
       "      <td>681.258118</td>\n",
       "      <td>0.421832</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>camiseta</td>\n",
       "      <td>P016</td>\n",
       "      <td>10848</td>\n",
       "      <td>10624</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>591.799072</td>\n",
       "      <td>0.436430</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>camiseta</td>\n",
       "      <td>P006</td>\n",
       "      <td>10903</td>\n",
       "      <td>10648</td>\n",
       "      <td>0.120792</td>\n",
       "      <td>572.973694</td>\n",
       "      <td>0.435060</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>camiseta</td>\n",
       "      <td>P001</td>\n",
       "      <td>10841</td>\n",
       "      <td>10629</td>\n",
       "      <td>0.118808</td>\n",
       "      <td>532.958008</td>\n",
       "      <td>0.413787</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>camiseta</td>\n",
       "      <td>P064</td>\n",
       "      <td>6946</td>\n",
       "      <td>6795</td>\n",
       "      <td>0.119637</td>\n",
       "      <td>349.477875</td>\n",
       "      <td>0.420551</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>camiseta</td>\n",
       "      <td>P063</td>\n",
       "      <td>3050</td>\n",
       "      <td>3007</td>\n",
       "      <td>0.116066</td>\n",
       "      <td>142.602356</td>\n",
       "      <td>0.402832</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pantalon</td>\n",
       "      <td>P008</td>\n",
       "      <td>13691</td>\n",
       "      <td>13334</td>\n",
       "      <td>0.130889</td>\n",
       "      <td>1381.661011</td>\n",
       "      <td>0.771016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pantalon</td>\n",
       "      <td>P024</td>\n",
       "      <td>10891</td>\n",
       "      <td>10661</td>\n",
       "      <td>0.133505</td>\n",
       "      <td>1121.135620</td>\n",
       "      <td>0.771070</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pantalon</td>\n",
       "      <td>P004</td>\n",
       "      <td>10814</td>\n",
       "      <td>10603</td>\n",
       "      <td>0.120862</td>\n",
       "      <td>974.602295</td>\n",
       "      <td>0.745679</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pantalon</td>\n",
       "      <td>P065</td>\n",
       "      <td>4098</td>\n",
       "      <td>4029</td>\n",
       "      <td>0.126159</td>\n",
       "      <td>389.604584</td>\n",
       "      <td>0.753587</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sudadera</td>\n",
       "      <td>P003</td>\n",
       "      <td>13760</td>\n",
       "      <td>13411</td>\n",
       "      <td>0.123837</td>\n",
       "      <td>1342.200562</td>\n",
       "      <td>0.787676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sudadera</td>\n",
       "      <td>P060</td>\n",
       "      <td>2986</td>\n",
       "      <td>2950</td>\n",
       "      <td>0.123242</td>\n",
       "      <td>297.666687</td>\n",
       "      <td>0.808877</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   categoria id_producto  n_items  n_orders  pct_interv  savings_total  \\\n",
       "0     abrigo        P047    11004     10789    0.848237    6711.040527   \n",
       "1     abrigo        P013    13200     12866    0.122576    2112.063721   \n",
       "2     abrigo        P020    10665     10460    0.123019    1744.149536   \n",
       "3     abrigo        P005    10722     10498    0.122738    1729.842285   \n",
       "4     abrigo        P058    10660     10424    0.124953    1612.811279   \n",
       "5     abrigo        P069     3207      3161    0.135329     523.081299   \n",
       "6     abrigo        P059     3027      2992    0.131483     500.307251   \n",
       "7     camisa        P042    11017     10773    0.508941    1245.537598   \n",
       "8     camisa        P066     3052      3006    0.134010     263.302612   \n",
       "9     camisa        P062     3130      3092    0.125879     254.271744   \n",
       "10  camiseta        P002    13442     13092    0.120146     681.258118   \n",
       "11  camiseta        P016    10848     10624    0.125000     591.799072   \n",
       "12  camiseta        P006    10903     10648    0.120792     572.973694   \n",
       "13  camiseta        P001    10841     10629    0.118808     532.958008   \n",
       "14  camiseta        P064     6946      6795    0.119637     349.477875   \n",
       "15  camiseta        P063     3050      3007    0.116066     142.602356   \n",
       "16  pantalon        P008    13691     13334    0.130889    1381.661011   \n",
       "17  pantalon        P024    10891     10661    0.133505    1121.135620   \n",
       "18  pantalon        P004    10814     10603    0.120862     974.602295   \n",
       "19  pantalon        P065     4098      4029    0.126159     389.604584   \n",
       "20  sudadera        P003    13760     13411    0.123837    1342.200562   \n",
       "21  sudadera        P060     2986      2950    0.123242     297.666687   \n",
       "\n",
       "    savings_mean_interv  rank_in_cat  \n",
       "0              0.718989            1  \n",
       "1              1.305355            2  \n",
       "2              1.329382            3  \n",
       "3              1.314470            4  \n",
       "4              1.210819            5  \n",
       "5              1.205256            6  \n",
       "6              1.257053            7  \n",
       "7              0.222140            1  \n",
       "8              0.643772            2  \n",
       "9              0.645360            3  \n",
       "10             0.421832            1  \n",
       "11             0.436430            2  \n",
       "12             0.435060            3  \n",
       "13             0.413787            4  \n",
       "14             0.420551            5  \n",
       "15             0.402832            6  \n",
       "16             0.771016            1  \n",
       "17             0.771070            2  \n",
       "18             0.745679            3  \n",
       "19             0.753587            4  \n",
       "20             0.787676            1  \n",
       "21             0.808877            2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Exportado: data/bi\\by_product_top_by_category.csv\n"
     ]
    }
   ],
   "source": [
    "# PÁGINA 2 | Top productos por categoría\n",
    "\n",
    "df = bi_items_full.copy()\n",
    "\n",
    "by_product_cat = (\n",
    "    df.groupby([\"categoria\", \"id_producto\"], as_index=False)\n",
    "      .agg(\n",
    "          n_items=(\"ticket_id\", \"size\"),\n",
    "          n_orders=(\"ticket_id\", \"nunique\"),\n",
    "          pct_interv=(\"cambia_talla\", \"mean\"),\n",
    "          savings_total=(\"expected_savings_talla\", \"sum\"),\n",
    "          savings_mean_interv=(\"expected_savings_talla\",\n",
    "                              lambda s: float(np.mean(s[df.loc[s.index, \"cambia_talla\"] == 1]))\n",
    "                              if df.loc[s.index, \"cambia_talla\"].sum() > 0 else 0.0),\n",
    "      )\n",
    ")\n",
    "\n",
    "by_product_cat[\"rank_in_cat\"] = (\n",
    "    by_product_cat.groupby(\"categoria\")[\"savings_total\"]\n",
    "    .rank(method=\"first\", ascending=False)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "TOPN = 10\n",
    "by_product_top_by_category = (\n",
    "    by_product_cat[by_product_cat[\"rank_in_cat\"] <= TOPN]\n",
    "    .sort_values([\"categoria\", \"rank_in_cat\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\" PÁGINA 2 | Top {TOPN} por categoría:\", by_product_top_by_category.shape)\n",
    "display(by_product_top_by_category.head(30))\n",
    "\n",
    "by_product_top_by_category.to_csv(os.path.join(BI_DIR, \"by_product_top_by_category.csv\"), index=False)\n",
    "print(\" Exportado:\", os.path.join(BI_DIR, \"by_product_top_by_category.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "40ee74e7-caa1-41e2-a606-096f9e73b032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Exportado dataset base: data/bi\\bi_items.csv\n",
      "\n",
      " Archivos en data/bi:\n",
      "- data/bi\\altura_quintiles.csv\n",
      "- data/bi\\bi_items.csv\n",
      "- data/bi\\bmi_quintiles.csv\n",
      "- data/bi\\by_category.csv\n",
      "- data/bi\\by_product_top.csv\n",
      "- data/bi\\by_product_top_by_category.csv\n",
      "- data/bi\\category_daily.csv\n",
      "- data/bi\\channel_daily.csv\n",
      "- data/bi\\channel_overview.csv\n",
      "- data/bi\\customer_daily.csv\n",
      "- data/bi\\customer_monthly.csv\n",
      "- data/bi\\geo_daily.csv\n",
      "- data/bi\\geo_daily_cat_canal.csv\n",
      "- data/bi\\geo_daily_cat_talla.csv\n",
      "- data/bi\\geo_mix_prov.csv\n",
      "- data/bi\\geo_prov_cat_talla.csv\n",
      "- data/bi\\geo_provincia_overview.csv\n",
      "- data/bi\\impact_percentiles_interv.csv\n",
      "- data/bi\\impact_summary.csv\n",
      "- data/bi\\items_global_diagnostico.csv\n",
      "- data/bi\\items_model_global.csv\n",
      "- data/bi\\items_model_global.parquet\n",
      "- data/bi\\items_model_global_enriched.csv\n",
      "- data/bi\\items_model_global_enriched.parquet\n",
      "- data/bi\\kpi_portada.csv\n",
      "- data/bi\\kpi_portada_long.csv\n",
      "- data/bi\\kpi_portada_wide.csv\n",
      "- data/bi\\month_summary.csv\n",
      "- data/bi\\preds_global_item_level.csv\n",
      "- data/bi\\returns_by_category.csv\n",
      "- data/bi\\returns_by_product.csv\n",
      "- data/bi\\returns_by_talla.csv\n",
      "- data/bi\\risk_deciles.csv\n",
      "- data/bi\\savings_concentration.csv\n",
      "- data/bi\\store_monthly_overview.csv\n",
      "- data/bi\\talla_extremos.csv\n",
      "- data/bi\\threshold_curve.csv\n"
     ]
    }
   ],
   "source": [
    "bi_items_full.to_csv(os.path.join(BI_DIR, \"bi_items.csv\"), index=False)\n",
    "print(\" Exportado dataset base:\", os.path.join(BI_DIR, \"bi_items.csv\"))\n",
    "\n",
    "print(\"\\n Archivos en data/bi:\")\n",
    "for f in sorted(os.listdir(BI_DIR)):\n",
    "    print(\"-\", os.path.join(BI_DIR, f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "69c8d8ae-cc9a-49ef-8063-ab6037a581a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PÁGINA 3 | Dataset listo\n",
      "- Items: 191954\n",
      "- % intervención: 0.18784187878345854\n",
      "- Ahorro total (€): 25074.34765625\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = bi_items_full.copy()\n",
    "\n",
    "needed = [\n",
    "    \"ticket_id\", \"categoria\", \"talla\", \"altura_cm\", \"peso_kg\", \"bmi\",\n",
    "    \"cambia_talla\", \"delta_p_final\", \"expected_savings_talla\"\n",
    "]\n",
    "for c in needed:\n",
    "    if c not in df.columns:\n",
    "        raise KeyError(f\"bi_items_full no tiene '{c}'. Revisa la construcción del dataset.\")\n",
    "\n",
    "df[\"cambia_talla\"] = pd.to_numeric(df[\"cambia_talla\"], errors=\"coerce\").fillna(0).astype(\"int8\")\n",
    "df[\"delta_p_final\"] = pd.to_numeric(df[\"delta_p_final\"], errors=\"coerce\").fillna(0.0).astype(\"float32\")\n",
    "df[\"expected_savings_talla\"] = pd.to_numeric(df[\"expected_savings_talla\"], errors=\"coerce\").fillna(0.0).astype(\"float32\")\n",
    "\n",
    "print(\" PÁGINA 3 | Dataset listo\")\n",
    "print(\"- Items:\", len(df))\n",
    "print(\"- % intervención:\", float(df[\"cambia_talla\"].mean()))\n",
    "print(\"- Ahorro total (€):\", float(df[\"expected_savings_talla\"].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b1fa3581-c10b-4817-9427-20a33003d8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PÁGINA 3 | Impact summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grupo</th>\n",
       "      <th>n_items</th>\n",
       "      <th>pct_items</th>\n",
       "      <th>delta_p_mean</th>\n",
       "      <th>savings_total</th>\n",
       "      <th>savings_mean_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No intervención</td>\n",
       "      <td>155897</td>\n",
       "      <td>81.22%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Intervención</td>\n",
       "      <td>36057</td>\n",
       "      <td>18.78%</td>\n",
       "      <td>0.184498</td>\n",
       "      <td>25074.347656</td>\n",
       "      <td>0.695409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             grupo  n_items pct_items  delta_p_mean  savings_total  \\\n",
       "0  No intervención   155897    81.22%      0.000000       0.000000   \n",
       "1     Intervención    36057    18.78%      0.184498   25074.347656   \n",
       "\n",
       "   savings_mean_item  \n",
       "0           0.000000  \n",
       "1           0.695409  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Exportado: data/bi\\impact_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# PÁGINA 3.1 | Intervención vs No intervención\n",
    "\n",
    "def _pct(x): \n",
    "    return f\"{100*x:.2f}%\"\n",
    "\n",
    "impact_summary = pd.DataFrame([\n",
    "    {\n",
    "        \"grupo\": \"No intervención\",\n",
    "        \"n_items\": int((df[\"cambia_talla\"] == 0).sum()),\n",
    "        \"pct_items\": float((df[\"cambia_talla\"] == 0).mean()),\n",
    "        \"delta_p_mean\": float(df.loc[df[\"cambia_talla\"] == 0, \"delta_p_final\"].mean()),\n",
    "        \"savings_total\": float(df.loc[df[\"cambia_talla\"] == 0, \"expected_savings_talla\"].sum()),\n",
    "        \"savings_mean_item\": float(df.loc[df[\"cambia_talla\"] == 0, \"expected_savings_talla\"].mean()),\n",
    "    },\n",
    "    {\n",
    "        \"grupo\": \"Intervención\",\n",
    "        \"n_items\": int((df[\"cambia_talla\"] == 1).sum()),\n",
    "        \"pct_items\": float((df[\"cambia_talla\"] == 1).mean()),\n",
    "        \"delta_p_mean\": float(df.loc[df[\"cambia_talla\"] == 1, \"delta_p_final\"].mean()),\n",
    "        \"savings_total\": float(df.loc[df[\"cambia_talla\"] == 1, \"expected_savings_talla\"].sum()),\n",
    "        \"savings_mean_item\": float(df.loc[df[\"cambia_talla\"] == 1, \"expected_savings_talla\"].mean()),\n",
    "    }\n",
    "])\n",
    "\n",
    "impact_summary[\"pct_items\"] = impact_summary[\"pct_items\"].apply(_pct)\n",
    "\n",
    "print(\" PÁGINA 3 | Impact summary\")\n",
    "display(impact_summary)\n",
    "\n",
    "impact_summary.to_csv(os.path.join(BI_DIR, \"impact_summary.csv\"), index=False)\n",
    "print(\" Exportado:\", os.path.join(BI_DIR, \"impact_summary.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8409b1bc-00ac-4667-a225-e48c8924548a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PÁGINA 3 | Extremos vs no extremos\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segmento</th>\n",
       "      <th>n_items</th>\n",
       "      <th>n_orders</th>\n",
       "      <th>pct_interv</th>\n",
       "      <th>delta_p_mean</th>\n",
       "      <th>savings_total</th>\n",
       "      <th>savings_mean_interv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No extrema</td>\n",
       "      <td>157182</td>\n",
       "      <td>108131</td>\n",
       "      <td>0.183183</td>\n",
       "      <td>0.030444</td>\n",
       "      <td>17986.158203</td>\n",
       "      <td>0.624671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extrema</td>\n",
       "      <td>34772</td>\n",
       "      <td>23893</td>\n",
       "      <td>0.208904</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>7088.188965</td>\n",
       "      <td>0.975797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     segmento  n_items  n_orders  pct_interv  delta_p_mean  savings_total  \\\n",
       "0  No extrema   157182    108131    0.183183      0.030444   17986.158203   \n",
       "1     Extrema    34772     23893    0.208904      0.053700    7088.188965   \n",
       "\n",
       "   savings_mean_interv  \n",
       "0             0.624671  \n",
       "1             0.975797  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Exportado: data/bi\\talla_extremos.csv\n"
     ]
    }
   ],
   "source": [
    "# PÁGINA 3.2 | Tallas extremas vs no extremas\n",
    "\n",
    "df[\"talla_extrema\"] = df[\"talla\"].isin([\"XS\", \"XL\"]).astype(\"int8\")\n",
    "\n",
    "extreme_table = (\n",
    "    df.groupby(\"talla_extrema\", as_index=False)\n",
    "      .agg(\n",
    "          n_items=(\"ticket_id\", \"size\"),\n",
    "          n_orders=(\"ticket_id\", \"nunique\"),\n",
    "          pct_interv=(\"cambia_talla\", \"mean\"),\n",
    "          delta_p_mean=(\"delta_p_final\", \"mean\"),\n",
    "          savings_total=(\"expected_savings_talla\", \"sum\"),\n",
    "          savings_mean_interv=(\"expected_savings_talla\",\n",
    "                              lambda s: float(np.mean(s[df.loc[s.index, \"cambia_talla\"] == 1]))\n",
    "                              if df.loc[s.index, \"cambia_talla\"].sum() > 0 else 0.0),\n",
    "      )\n",
    ")\n",
    "\n",
    "extreme_table[\"segmento\"] = extreme_table[\"talla_extrema\"].map({0: \"No extrema\", 1: \"Extrema\"})\n",
    "extreme_table = extreme_table[[\"segmento\", \"n_items\", \"n_orders\", \"pct_interv\", \"delta_p_mean\", \"savings_total\", \"savings_mean_interv\"]]\n",
    "\n",
    "print(\" PÁGINA 3 | Extremos vs no extremos\")\n",
    "display(extreme_table)\n",
    "\n",
    "extreme_table.to_csv(os.path.join(BI_DIR, \"talla_extremos.csv\"), index=False)\n",
    "print(\" Exportado:\", os.path.join(BI_DIR, \"talla_extremos.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "12db73dc-651d-4218-a4fc-63ec9d564d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PÁGINA 3 | BMI quintiles\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmi_quintil</th>\n",
       "      <th>n_items</th>\n",
       "      <th>pct_interv</th>\n",
       "      <th>delta_p_mean</th>\n",
       "      <th>savings_total</th>\n",
       "      <th>savings_mean_interv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>38393</td>\n",
       "      <td>0.217019</td>\n",
       "      <td>0.036819</td>\n",
       "      <td>5309.074707</td>\n",
       "      <td>0.637191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>38390</td>\n",
       "      <td>0.198593</td>\n",
       "      <td>0.036967</td>\n",
       "      <td>5408.622070</td>\n",
       "      <td>0.709420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>38401</td>\n",
       "      <td>0.187443</td>\n",
       "      <td>0.037661</td>\n",
       "      <td>5558.407715</td>\n",
       "      <td>0.772216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>38380</td>\n",
       "      <td>0.167952</td>\n",
       "      <td>0.030348</td>\n",
       "      <td>4313.814453</td>\n",
       "      <td>0.669223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>38390</td>\n",
       "      <td>0.168195</td>\n",
       "      <td>0.031485</td>\n",
       "      <td>4484.428711</td>\n",
       "      <td>0.694507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bmi_quintil  n_items  pct_interv  delta_p_mean  savings_total  \\\n",
       "0          Q1    38393    0.217019      0.036819    5309.074707   \n",
       "1          Q2    38390    0.198593      0.036967    5408.622070   \n",
       "2          Q3    38401    0.187443      0.037661    5558.407715   \n",
       "3          Q4    38380    0.167952      0.030348    4313.814453   \n",
       "4          Q5    38390    0.168195      0.031485    4484.428711   \n",
       "\n",
       "   savings_mean_interv  \n",
       "0             0.637191  \n",
       "1             0.709420  \n",
       "2             0.772216  \n",
       "3             0.669223  \n",
       "4             0.694507  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Exportado: data/bi\\bmi_quintiles.csv\n"
     ]
    }
   ],
   "source": [
    "# PÁGINA 3.3 | Quintiles de BMI\n",
    "\n",
    "df_bmi = df.copy()\n",
    "df_bmi[\"bmi\"] = pd.to_numeric(df_bmi[\"bmi\"], errors=\"coerce\")\n",
    "df_bmi = df_bmi[df_bmi[\"bmi\"].notna()].copy()\n",
    "\n",
    "df_bmi[\"bmi_quintil\"] = pd.qcut(df_bmi[\"bmi\"], q=5, labels=[f\"Q{i}\" for i in range(1, 6)])\n",
    "\n",
    "bmi_table = (\n",
    "    df_bmi.groupby(\"bmi_quintil\", as_index=False, observed=False)\n",
    "          .agg(\n",
    "              n_items=(\"ticket_id\", \"size\"),\n",
    "              pct_interv=(\"cambia_talla\", \"mean\"),\n",
    "              delta_p_mean=(\"delta_p_final\", \"mean\"),\n",
    "              savings_total=(\"expected_savings_talla\", \"sum\"),\n",
    "              savings_mean_interv=(\"expected_savings_talla\",\n",
    "                                  lambda s: float(np.mean(s[df_bmi.loc[s.index, \"cambia_talla\"] == 1]))\n",
    "                                  if df_bmi.loc[s.index, \"cambia_talla\"].sum() > 0 else 0.0),\n",
    "          )\n",
    ")\n",
    "\n",
    "print(\" PÁGINA 3 | BMI quintiles\")\n",
    "display(bmi_table)\n",
    "\n",
    "bmi_table.to_csv(os.path.join(BI_DIR, \"bmi_quintiles.csv\"), index=False)\n",
    "print(\" Exportado:\", os.path.join(BI_DIR, \"bmi_quintiles.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "09c31a00-49d2-4d68-9e0f-aa459069969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PÁGINA 3 | Altura quintiles\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>altura_quintil</th>\n",
       "      <th>n_items</th>\n",
       "      <th>pct_interv</th>\n",
       "      <th>delta_p_mean</th>\n",
       "      <th>savings_total</th>\n",
       "      <th>savings_mean_interv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>39045</td>\n",
       "      <td>0.261109</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>6286.635254</td>\n",
       "      <td>0.616639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>38264</td>\n",
       "      <td>0.121707</td>\n",
       "      <td>0.014905</td>\n",
       "      <td>2237.173828</td>\n",
       "      <td>0.480390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>38048</td>\n",
       "      <td>0.253417</td>\n",
       "      <td>0.046049</td>\n",
       "      <td>6562.776855</td>\n",
       "      <td>0.680645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>38777</td>\n",
       "      <td>0.117699</td>\n",
       "      <td>0.029775</td>\n",
       "      <td>4468.647949</td>\n",
       "      <td>0.979108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>37820</td>\n",
       "      <td>0.185061</td>\n",
       "      <td>0.037616</td>\n",
       "      <td>5519.113770</td>\n",
       "      <td>0.788557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  altura_quintil  n_items  pct_interv  delta_p_mean  savings_total  \\\n",
       "0             Q1    39045    0.261109      0.044892    6286.635254   \n",
       "1             Q2    38264    0.121707      0.014905    2237.173828   \n",
       "2             Q3    38048    0.253417      0.046049    6562.776855   \n",
       "3             Q4    38777    0.117699      0.029775    4468.647949   \n",
       "4             Q5    37820    0.185061      0.037616    5519.113770   \n",
       "\n",
       "   savings_mean_interv  \n",
       "0             0.616639  \n",
       "1             0.480390  \n",
       "2             0.680645  \n",
       "3             0.979108  \n",
       "4             0.788557  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Exportado: data/bi\\altura_quintiles.csv\n"
     ]
    }
   ],
   "source": [
    "# PÁGINA 3.4 | Quintiles de Altura\n",
    "\n",
    "df_h = df.copy()\n",
    "df_h[\"altura_cm\"] = pd.to_numeric(df_h[\"altura_cm\"], errors=\"coerce\")\n",
    "df_h = df_h[df_h[\"altura_cm\"].notna()].copy()\n",
    "\n",
    "df_h[\"altura_quintil\"] = pd.qcut(df_h[\"altura_cm\"], q=5, labels=[f\"Q{i}\" for i in range(1, 6)])\n",
    "\n",
    "altura_table = (\n",
    "    df_h.groupby(\"altura_quintil\", as_index=False, observed=False)\n",
    "        .agg(\n",
    "            n_items=(\"ticket_id\", \"size\"),\n",
    "            pct_interv=(\"cambia_talla\", \"mean\"),\n",
    "            delta_p_mean=(\"delta_p_final\", \"mean\"),\n",
    "            savings_total=(\"expected_savings_talla\", \"sum\"),\n",
    "            savings_mean_interv=(\"expected_savings_talla\",\n",
    "                                lambda s: float(np.mean(s[df_h.loc[s.index, \"cambia_talla\"] == 1]))\n",
    "                                if df_h.loc[s.index, \"cambia_talla\"].sum() > 0 else 0.0),\n",
    "        )\n",
    ")\n",
    "\n",
    "print(\" PÁGINA 3 | Altura quintiles\")\n",
    "display(altura_table)\n",
    "\n",
    "altura_table.to_csv(os.path.join(BI_DIR, \"altura_quintiles.csv\"), index=False)\n",
    "print(\" Exportado:\", os.path.join(BI_DIR, \"altura_quintiles.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "23513a06-e1a6-41c9-b290-c3175b1887c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PÁGINA 3 | Riesgo global por deciles\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>risk_decile</th>\n",
       "      <th>n_items</th>\n",
       "      <th>pct_interv</th>\n",
       "      <th>delta_p_mean</th>\n",
       "      <th>savings_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13376</td>\n",
       "      <td>0.007177</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>15.580882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13376</td>\n",
       "      <td>0.013457</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>51.604553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13375</td>\n",
       "      <td>0.034841</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>162.788498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13376</td>\n",
       "      <td>0.057865</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>329.474854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13376</td>\n",
       "      <td>0.091283</td>\n",
       "      <td>0.015654</td>\n",
       "      <td>606.241577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>13375</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.024108</td>\n",
       "      <td>1049.237915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>13376</td>\n",
       "      <td>0.264279</td>\n",
       "      <td>0.042712</td>\n",
       "      <td>2101.927002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>13375</td>\n",
       "      <td>0.312822</td>\n",
       "      <td>0.056478</td>\n",
       "      <td>2973.012695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>13376</td>\n",
       "      <td>0.371112</td>\n",
       "      <td>0.069669</td>\n",
       "      <td>3603.990723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>13376</td>\n",
       "      <td>0.577751</td>\n",
       "      <td>0.120945</td>\n",
       "      <td>6492.715332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  risk_decile  n_items  pct_interv  delta_p_mean  savings_total\n",
       "0           1    13376    0.007177      0.000448      15.580882\n",
       "1           2    13376    0.013457      0.001406      51.604553\n",
       "2           3    13375    0.034841      0.004510     162.788498\n",
       "3           4    13376    0.057865      0.009108     329.474854\n",
       "4           5    13376    0.091283      0.015654     606.241577\n",
       "5           6    13375    0.144000      0.024108    1049.237915\n",
       "6           7    13376    0.264279      0.042712    2101.927002\n",
       "7           8    13375    0.312822      0.056478    2973.012695\n",
       "8           9    13376    0.371112      0.069669    3603.990723\n",
       "9          10    13376    0.577751      0.120945    6492.715332"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Exportado: data/bi\\risk_deciles.csv\n"
     ]
    }
   ],
   "source": [
    "# PÁGINA 3.5 | Intervención por deciles de riesgo global\n",
    "\n",
    "if \"p_dev_global\" not in df.columns:\n",
    "    print(\" No existe p_dev_global en bi_items_full. Esta tabla no se puede generar.\")\n",
    "else:\n",
    "    df_r = df.copy()\n",
    "    df_r[\"p_dev_global\"] = pd.to_numeric(df_r[\"p_dev_global\"], errors=\"coerce\")\n",
    "    df_r = df_r[df_r[\"p_dev_global\"].notna()].copy()\n",
    "\n",
    "    if len(df_r) == 0:\n",
    "        print(\" p_dev_global está todo NA. Revisa el merge del modelo global.\")\n",
    "    else:\n",
    "        df_r[\"risk_decile\"] = pd.qcut(df_r[\"p_dev_global\"], q=10, labels=[i for i in range(1, 11)])\n",
    "\n",
    "        risk_table = (\n",
    "            df_r.groupby(\"risk_decile\", as_index=False, observed=False)\n",
    "                .agg(\n",
    "                    n_items=(\"ticket_id\", \"size\"),\n",
    "                    pct_interv=(\"cambia_talla\", \"mean\"),\n",
    "                    delta_p_mean=(\"delta_p_final\", \"mean\"),\n",
    "                    savings_total=(\"expected_savings_talla\", \"sum\"),\n",
    "                )\n",
    "        )\n",
    "\n",
    "        print(\" PÁGINA 3 | Riesgo global por deciles\")\n",
    "        display(risk_table)\n",
    "\n",
    "        risk_table.to_csv(os.path.join(BI_DIR, \"risk_deciles.csv\"), index=False)\n",
    "        print(\" Exportado:\", os.path.join(BI_DIR, \"risk_deciles.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8d35456f-899c-4a58-a771-eb745a586d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PÁGINA 3 | Percentiles de delta_p_final (solo intervención)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentil</th>\n",
       "      <th>delta_p_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P25</td>\n",
       "      <td>0.081811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P50</td>\n",
       "      <td>0.188258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P75</td>\n",
       "      <td>0.261063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P90</td>\n",
       "      <td>0.336538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P95</td>\n",
       "      <td>0.390156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P99</td>\n",
       "      <td>0.452681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  percentil  delta_p_final\n",
       "0       P25       0.081811\n",
       "1       P50       0.188258\n",
       "2       P75       0.261063\n",
       "3       P90       0.336538\n",
       "4       P95       0.390156\n",
       "5       P99       0.452681"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PÁGINA 3 | Concentración del ahorro (solo intervención)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_frac_interv</th>\n",
       "      <th>share_ahorro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top 1%</td>\n",
       "      <td>0.034507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Top 5%</td>\n",
       "      <td>0.143062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Top 10%</td>\n",
       "      <td>0.254063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Top 20%</td>\n",
       "      <td>0.433335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  top_frac_interv  share_ahorro\n",
       "0          Top 1%      0.034507\n",
       "1          Top 5%      0.143062\n",
       "2         Top 10%      0.254063\n",
       "3         Top 20%      0.433335"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Exportados:\n",
      "- data/bi\\impact_percentiles_interv.csv\n",
      "- data/bi\\savings_concentration.csv\n"
     ]
    }
   ],
   "source": [
    "# PÁGINA 3.6 | Distribución del impacto y concentración del ahorro\n",
    "\n",
    "df_i = df[df[\"cambia_talla\"] == 1].copy()\n",
    "\n",
    "if len(df_i) == 0:\n",
    "    print(\" No hay intervenciones (cambia_talla=1). Revisa min_gain.\")\n",
    "else:\n",
    "    deltas = df_i[\"delta_p_final\"].to_numpy()\n",
    "\n",
    "    pct = np.percentile(deltas, [25, 50, 75, 90, 95, 99])\n",
    "    dist_table = pd.DataFrame({\n",
    "        \"percentil\": [\"P25\", \"P50\", \"P75\", \"P90\", \"P95\", \"P99\"],\n",
    "        \"delta_p_final\": pct\n",
    "    })\n",
    "\n",
    "    # Concentración del ahorro: top X% intervenciones\n",
    "    df_i_sorted = df_i.sort_values(\"expected_savings_talla\", ascending=False).reset_index(drop=True)\n",
    "    total_savings = float(df_i_sorted[\"expected_savings_talla\"].sum())\n",
    "\n",
    "    def _share_top(frac: float) -> float:\n",
    "        k = max(1, int(len(df_i_sorted) * frac))\n",
    "        return float(df_i_sorted.iloc[:k][\"expected_savings_talla\"].sum() / (total_savings + 1e-9))\n",
    "\n",
    "    conc_table = pd.DataFrame({\n",
    "        \"top_frac_interv\": [\"Top 1%\", \"Top 5%\", \"Top 10%\", \"Top 20%\"],\n",
    "        \"share_ahorro\": [_share_top(0.01), _share_top(0.05), _share_top(0.10), _share_top(0.20)]\n",
    "    })\n",
    "\n",
    "    print(\" PÁGINA 3 | Percentiles de delta_p_final (solo intervención)\")\n",
    "    display(dist_table)\n",
    "\n",
    "    print(\" PÁGINA 3 | Concentración del ahorro (solo intervención)\")\n",
    "    display(conc_table)\n",
    "\n",
    "    dist_table.to_csv(os.path.join(BI_DIR, \"impact_percentiles_interv.csv\"), index=False)\n",
    "    conc_table.to_csv(os.path.join(BI_DIR, \"savings_concentration.csv\"), index=False)\n",
    "\n",
    "    print(\" Exportados:\")\n",
    "    print(\"-\", os.path.join(BI_DIR, \"impact_percentiles_interv.csv\"))\n",
    "    print(\"-\", os.path.join(BI_DIR, \"savings_concentration.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8e0dd638-c879-4514-b869-089cbdd34974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoria</th>\n",
       "      <th>id_producto</th>\n",
       "      <th>n_items</th>\n",
       "      <th>n_orders</th>\n",
       "      <th>pct_interv</th>\n",
       "      <th>savings_total</th>\n",
       "      <th>savings_mean_interv</th>\n",
       "      <th>rank_in_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abrigo</td>\n",
       "      <td>P047</td>\n",
       "      <td>11004</td>\n",
       "      <td>10789</td>\n",
       "      <td>0.848237</td>\n",
       "      <td>6711.040527</td>\n",
       "      <td>0.718989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abrigo</td>\n",
       "      <td>P013</td>\n",
       "      <td>13200</td>\n",
       "      <td>12866</td>\n",
       "      <td>0.122576</td>\n",
       "      <td>2112.063721</td>\n",
       "      <td>1.305355</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abrigo</td>\n",
       "      <td>P020</td>\n",
       "      <td>10665</td>\n",
       "      <td>10460</td>\n",
       "      <td>0.123019</td>\n",
       "      <td>1744.149536</td>\n",
       "      <td>1.329382</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abrigo</td>\n",
       "      <td>P005</td>\n",
       "      <td>10722</td>\n",
       "      <td>10498</td>\n",
       "      <td>0.122738</td>\n",
       "      <td>1729.842285</td>\n",
       "      <td>1.314470</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abrigo</td>\n",
       "      <td>P058</td>\n",
       "      <td>10660</td>\n",
       "      <td>10424</td>\n",
       "      <td>0.124953</td>\n",
       "      <td>1612.811279</td>\n",
       "      <td>1.210819</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abrigo</td>\n",
       "      <td>P069</td>\n",
       "      <td>3207</td>\n",
       "      <td>3161</td>\n",
       "      <td>0.135329</td>\n",
       "      <td>523.081299</td>\n",
       "      <td>1.205256</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abrigo</td>\n",
       "      <td>P059</td>\n",
       "      <td>3027</td>\n",
       "      <td>2992</td>\n",
       "      <td>0.131483</td>\n",
       "      <td>500.307251</td>\n",
       "      <td>1.257053</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>camisa</td>\n",
       "      <td>P042</td>\n",
       "      <td>11017</td>\n",
       "      <td>10773</td>\n",
       "      <td>0.508941</td>\n",
       "      <td>1245.537598</td>\n",
       "      <td>0.222140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>camisa</td>\n",
       "      <td>P066</td>\n",
       "      <td>3052</td>\n",
       "      <td>3006</td>\n",
       "      <td>0.134010</td>\n",
       "      <td>263.302612</td>\n",
       "      <td>0.643772</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>camisa</td>\n",
       "      <td>P062</td>\n",
       "      <td>3130</td>\n",
       "      <td>3092</td>\n",
       "      <td>0.125879</td>\n",
       "      <td>254.271744</td>\n",
       "      <td>0.645360</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>camiseta</td>\n",
       "      <td>P002</td>\n",
       "      <td>13442</td>\n",
       "      <td>13092</td>\n",
       "      <td>0.120146</td>\n",
       "      <td>681.258118</td>\n",
       "      <td>0.421832</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>camiseta</td>\n",
       "      <td>P016</td>\n",
       "      <td>10848</td>\n",
       "      <td>10624</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>591.799072</td>\n",
       "      <td>0.436430</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>camiseta</td>\n",
       "      <td>P006</td>\n",
       "      <td>10903</td>\n",
       "      <td>10648</td>\n",
       "      <td>0.120792</td>\n",
       "      <td>572.973694</td>\n",
       "      <td>0.435060</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>camiseta</td>\n",
       "      <td>P001</td>\n",
       "      <td>10841</td>\n",
       "      <td>10629</td>\n",
       "      <td>0.118808</td>\n",
       "      <td>532.958008</td>\n",
       "      <td>0.413787</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>camiseta</td>\n",
       "      <td>P064</td>\n",
       "      <td>6946</td>\n",
       "      <td>6795</td>\n",
       "      <td>0.119637</td>\n",
       "      <td>349.477875</td>\n",
       "      <td>0.420551</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>camiseta</td>\n",
       "      <td>P063</td>\n",
       "      <td>3050</td>\n",
       "      <td>3007</td>\n",
       "      <td>0.116066</td>\n",
       "      <td>142.602356</td>\n",
       "      <td>0.402832</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pantalon</td>\n",
       "      <td>P008</td>\n",
       "      <td>13691</td>\n",
       "      <td>13334</td>\n",
       "      <td>0.130889</td>\n",
       "      <td>1381.661011</td>\n",
       "      <td>0.771016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pantalon</td>\n",
       "      <td>P024</td>\n",
       "      <td>10891</td>\n",
       "      <td>10661</td>\n",
       "      <td>0.133505</td>\n",
       "      <td>1121.135620</td>\n",
       "      <td>0.771070</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pantalon</td>\n",
       "      <td>P004</td>\n",
       "      <td>10814</td>\n",
       "      <td>10603</td>\n",
       "      <td>0.120862</td>\n",
       "      <td>974.602295</td>\n",
       "      <td>0.745679</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pantalon</td>\n",
       "      <td>P065</td>\n",
       "      <td>4098</td>\n",
       "      <td>4029</td>\n",
       "      <td>0.126159</td>\n",
       "      <td>389.604584</td>\n",
       "      <td>0.753587</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sudadera</td>\n",
       "      <td>P003</td>\n",
       "      <td>13760</td>\n",
       "      <td>13411</td>\n",
       "      <td>0.123837</td>\n",
       "      <td>1342.200562</td>\n",
       "      <td>0.787676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sudadera</td>\n",
       "      <td>P060</td>\n",
       "      <td>2986</td>\n",
       "      <td>2950</td>\n",
       "      <td>0.123242</td>\n",
       "      <td>297.666687</td>\n",
       "      <td>0.808877</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   categoria id_producto  n_items  n_orders  pct_interv  savings_total  \\\n",
       "0     abrigo        P047    11004     10789    0.848237    6711.040527   \n",
       "1     abrigo        P013    13200     12866    0.122576    2112.063721   \n",
       "2     abrigo        P020    10665     10460    0.123019    1744.149536   \n",
       "3     abrigo        P005    10722     10498    0.122738    1729.842285   \n",
       "4     abrigo        P058    10660     10424    0.124953    1612.811279   \n",
       "5     abrigo        P069     3207      3161    0.135329     523.081299   \n",
       "6     abrigo        P059     3027      2992    0.131483     500.307251   \n",
       "7     camisa        P042    11017     10773    0.508941    1245.537598   \n",
       "8     camisa        P066     3052      3006    0.134010     263.302612   \n",
       "9     camisa        P062     3130      3092    0.125879     254.271744   \n",
       "10  camiseta        P002    13442     13092    0.120146     681.258118   \n",
       "11  camiseta        P016    10848     10624    0.125000     591.799072   \n",
       "12  camiseta        P006    10903     10648    0.120792     572.973694   \n",
       "13  camiseta        P001    10841     10629    0.118808     532.958008   \n",
       "14  camiseta        P064     6946      6795    0.119637     349.477875   \n",
       "15  camiseta        P063     3050      3007    0.116066     142.602356   \n",
       "16  pantalon        P008    13691     13334    0.130889    1381.661011   \n",
       "17  pantalon        P024    10891     10661    0.133505    1121.135620   \n",
       "18  pantalon        P004    10814     10603    0.120862     974.602295   \n",
       "19  pantalon        P065     4098      4029    0.126159     389.604584   \n",
       "20  sudadera        P003    13760     13411    0.123837    1342.200562   \n",
       "21  sudadera        P060     2986      2950    0.123242     297.666687   \n",
       "\n",
       "    savings_mean_interv  rank_in_cat  \n",
       "0              0.718989            1  \n",
       "1              1.305355            2  \n",
       "2              1.329382            3  \n",
       "3              1.314470            4  \n",
       "4              1.210819            5  \n",
       "5              1.205256            6  \n",
       "6              1.257053            7  \n",
       "7              0.222140            1  \n",
       "8              0.643772            2  \n",
       "9              0.645360            3  \n",
       "10             0.421832            1  \n",
       "11             0.436430            2  \n",
       "12             0.435060            3  \n",
       "13             0.413787            4  \n",
       "14             0.420551            5  \n",
       "15             0.402832            6  \n",
       "16             0.771016            1  \n",
       "17             0.771070            2  \n",
       "18             0.745679            3  \n",
       "19             0.753587            4  \n",
       "20             0.787676            1  \n",
       "21             0.808877            2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MIN_N_PROD_CAT = 200  # ajusta (100/200/500)\n",
    "\n",
    "tmp = by_product_cat[by_product_cat[\"n_items\"] >= MIN_N_PROD_CAT].copy()\n",
    "\n",
    "tmp[\"rank_in_cat\"] = (\n",
    "    tmp.groupby(\"categoria\")[\"savings_total\"]\n",
    "       .rank(method=\"first\", ascending=False)\n",
    "       .astype(int)\n",
    ")\n",
    "\n",
    "TOPN = 10\n",
    "by_product_top_by_category = (\n",
    "    tmp[tmp[\"rank_in_cat\"] <= TOPN]\n",
    "    .sort_values([\"categoria\", \"rank_in_cat\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "display(by_product_top_by_category.head(30))\n",
    "by_product_top_by_category.to_csv(os.path.join(BI_DIR, \"by_product_top_by_category.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb14461-9891-480f-b903-b2cfd0629745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96a8bf7-51e2-45d6-abea-ea030227a380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5281fb-b653-4b3c-99e9-5696b9cb23f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ropa)",
   "language": "python",
   "name": "ropa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
