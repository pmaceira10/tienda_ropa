{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5c6d196-9ed9-4275-bb93-c090ea4905af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Modelo predictivo de devoluciones (item-level)\n",
    "\n",
    "En este notebook se construye y entrena un **modelo supervisado de clasificación binaria** cuyo objetivo es **predecir si un ítem será devuelto (`devuelto = 1`) o no**, utilizando información de producto, cliente, ticket, precio, contexto temporal y comportamiento histórico.\n",
    "\n",
    "El modelo opera **a nivel de ítem**, no a nivel de pedido ni de cliente, lo que permite capturar patrones finos como:\n",
    "- desajustes de talla,\n",
    "- historial individual de devoluciones,\n",
    "- comportamiento específico por producto,\n",
    "- diferencias estructurales entre canal online y canal físico.\n",
    "\n",
    "El dataset utilizado procede de la tabla `base_modelo_devoluciones`, construida previamente a partir de todo el pipeline de generación y enriquecimiento de datos.\n",
    "\n",
    "---\n",
    "\n",
    "## 1) Carga de datos y validaciones iniciales\n",
    "\n",
    "Los datos se cargan desde una base de datos SQLite (`database/mi_base.db`), lo que garantiza:\n",
    "- persistencia del pipeline,\n",
    "- trazabilidad de los experimentos,\n",
    "- independencia del notebook respecto a ficheros intermedios.\n",
    "\n",
    "Antes de entrenar cualquier modelo se realizan **chequeos básicos**:\n",
    "- número total de filas,\n",
    "- tasa global de devolución,\n",
    "- tasa de devolución por canal (online vs físico).\n",
    "\n",
    "Estos chequeos permiten validar que:\n",
    "- la variable objetivo está correctamente generada,\n",
    "- existe un gap claro entre canales (online > físico),\n",
    "- el dataset es coherente con los supuestos de negocio.\n",
    "\n",
    "Resultados observados:\n",
    "- Tasa global de devolución ≈ 0.30\n",
    "- Online ≈ 0.32\n",
    "- Físico ≈ 0.23\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Ingeniería de variables (Feature Engineering)\n",
    "\n",
    "La función `feature_engineering()` transforma la tabla base en un dataset listo para modelar.  \n",
    "Las transformaciones se agrupan en varios bloques conceptuales.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.1 Variables temporales y de cliente\n",
    "\n",
    "A partir de la fecha de compra y las fechas de alta del cliente se construyen:\n",
    "\n",
    "- `anio_compra`\n",
    "- `mes_compra`\n",
    "- `temporada_compra` (SS / FW)\n",
    "- `edad_en_compra`\n",
    "- `antiguedad_cliente_dias`\n",
    "\n",
    "Estas variables permiten capturar:\n",
    "- estacionalidad en las devoluciones,\n",
    "- diferencias por cohortes de edad,\n",
    "- comportamiento según antigüedad del cliente.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2 Variables económicas y promocionales\n",
    "\n",
    "Se generan variables relacionadas con precio y margen:\n",
    "\n",
    "- `en_promocion`\n",
    "- `margen_relativo` (margen / precio_neto)\n",
    "\n",
    "Estas variables ayudan a modelar:\n",
    "- compras impulsivas,\n",
    "- mayor propensión a devolución en campañas promocionales,\n",
    "- sensibilidad del cliente al precio.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.3 Inferencia de talla ideal del cliente\n",
    "\n",
    "Se estima una **talla ideal teórica** para cada cliente a partir de sus características físicas.\n",
    "\n",
    "#### Ropa\n",
    "- Se definen rangos de altura y peso por talla (XS–XL).\n",
    "- Para cada cliente se calcula una distancia normalizada a cada talla.\n",
    "- Se asigna como talla ideal aquella con menor distancia.\n",
    "\n",
    "#### Calzado\n",
    "- La talla ideal se infiere únicamente a partir de la altura.\n",
    "- Se selecciona la talla cuyo rango central está más próximo.\n",
    "\n",
    "Estas tallas ideales no son visibles para el cliente, pero sirven como referencia objetiva para medir errores de ajuste.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.4 Desajuste de talla (feature clave)\n",
    "\n",
    "A partir de la talla comprada y la talla ideal se construyen:\n",
    "\n",
    "- `desajuste_talla`\n",
    "- `desajuste_talla_abs`\n",
    "\n",
    "Este desajuste es uno de los **drivers más importantes** del modelo, especialmente en:\n",
    "- ropa,\n",
    "- calzado,\n",
    "- tallas extremas.\n",
    "\n",
    "Adicionalmente se crea la variable:\n",
    "- `talla_extrema` (XS, XL, 39, 45).\n",
    "\n",
    "---\n",
    "\n",
    "### 2.5 Historial del cliente\n",
    "\n",
    "Ordenando las compras cronológicamente, se generan variables acumuladas:\n",
    "\n",
    "- `compras_previas_cliente`\n",
    "- `devoluciones_previas_cliente`\n",
    "- `ratio_devoluciones_previas_cliente`\n",
    "\n",
    "Estas variables capturan:\n",
    "- clientes sistemáticamente propensos a devolver,\n",
    "- aprendizaje del cliente tras experiencias previas,\n",
    "- patrones persistentes de comportamiento.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.6 Historial del producto\n",
    "\n",
    "De forma análoga, a nivel producto:\n",
    "\n",
    "- `ventas_previas_producto`\n",
    "- `devoluciones_previas_producto`\n",
    "- `ratio_devoluciones_previas_producto`\n",
    "\n",
    "Esto permite identificar:\n",
    "- productos con problemas estructurales de fit,\n",
    "- referencias con fricción logística elevada,\n",
    "- artículos con tasas de devolución anómalas.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.7 Precio relativo por categoría\n",
    "\n",
    "Se calcula la variable:\n",
    "\n",
    "- `precio_rel_cat = precio_neto / precio_medio_categoria`\n",
    "\n",
    "Esto permite capturar:\n",
    "- productos significativamente más caros o baratos dentro de su categoría,\n",
    "- expectativas del cliente respecto al producto.\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Split de entrenamiento y test\n",
    "\n",
    "Se utiliza un **split temporal**, no aleatorio:\n",
    "\n",
    "- 75% de las observaciones más antiguas → train\n",
    "- 25% más reciente → test\n",
    "\n",
    "Configuración:\n",
    "- `mode = \"temporal\"`\n",
    "- `test_size = 0.25`\n",
    "- `date_col = \"fecha_compra\"`\n",
    "\n",
    "Este enfoque:\n",
    "- evita leakage temporal,\n",
    "- simula un escenario real de producción,\n",
    "- penaliza modelos que solo memorizan patrones históricos.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Construcción de matrices X / y\n",
    "\n",
    "### 4.1 Selección de variables\n",
    "\n",
    "Se eliminan columnas no predictivas o que inducen leakage:\n",
    "- identificadores,\n",
    "- fechas originales,\n",
    "- variables objetivo auxiliares,\n",
    "- tallas ideales explícitas.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2 Tratamiento de valores nulos\n",
    "\n",
    "- Se crean indicadores `missing_*` para variables sensibles (altura, peso, edad, etc.).\n",
    "- Variables numéricas → imputación por mediana (calculada solo en train).\n",
    "- Valores infinitos o residuales → sustituidos por 0.0.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.3 Variables categóricas\n",
    "\n",
    "- Normalización de texto (minúsculas, sin acentos).\n",
    "- One-hot encoding.\n",
    "- Alineación exacta de columnas entre train y test.\n",
    "\n",
    "El resultado es una matriz estable y compatible con modelos tree-based y lineales.\n",
    "\n",
    "---\n",
    "\n",
    "## 5) Persistencia del dataset procesado\n",
    "\n",
    "Para garantizar reproducibilidad se guardan los siguientes artefactos:\n",
    "\n",
    "- `X_train.parquet`, `X_test.parquet`\n",
    "- `y_train.parquet`, `y_test.parquet`\n",
    "- índices de train/test\n",
    "- metadata del preprocesado:\n",
    "  - columnas finales,\n",
    "  - medianas usadas,\n",
    "  - columnas categóricas,\n",
    "  - configuración del split.\n",
    "\n",
    "Todo queda almacenado en:\n",
    "data/processed/devoluciones/\n",
    "\n",
    "---\n",
    "\n",
    "## 6) Modelos evaluados\n",
    "\n",
    "Se entrenan varios modelos base para comparación:\n",
    "\n",
    "- Random Forest\n",
    "- Extra Trees\n",
    "- HistGradientBoosting\n",
    "- Logistic Regression\n",
    "- SGDClassifier (log-loss)\n",
    "- XGBoost (modelo final)\n",
    "\n",
    "Todos los modelos utilizan:\n",
    "- clases balanceadas,\n",
    "- evaluación consistente,\n",
    "- métricas centradas en la clase positiva.\n",
    "\n",
    "---\n",
    "\n",
    "## 7) Modelo final: XGBoost\n",
    "\n",
    "### 7.1 Estrategia de entrenamiento\n",
    "\n",
    "El modelo final (`xgb_final`) se entrena en dos fases:\n",
    "\n",
    "1. **Búsqueda aleatoria de hiperparámetros**\n",
    "   - 12 iteraciones\n",
    "   - early stopping con métrica PR-AUC\n",
    "   - selección del mejor conjunto de parámetros\n",
    "\n",
    "2. **Entrenamiento final**\n",
    "   - nuevo split interno\n",
    "   - número de rondas ajustado a la mejor iteración\n",
    "   - early stopping para estabilizar el modelo\n",
    "\n",
    "Configuración clave:\n",
    "- `objective = binary:logistic`\n",
    "- `eval_metric = aucpr`\n",
    "- `tree_method = hist`\n",
    "\n",
    "---\n",
    "\n",
    "### 7.2 Resultados finales en test\n",
    "\n",
    "Evaluación sobre el conjunto de test temporal:\n",
    "\n",
    "- **ROC-AUC (test)**: 0.698\n",
    "- **PR-AUC (test)**: 0.569\n",
    "\n",
    "Con umbral 0.5:\n",
    "- Precision (positiva): 0.465\n",
    "- Recall (positiva): 0.601\n",
    "- F1 (positiva): 0.524\n",
    "\n",
    "Mejor umbral optimizando F1:\n",
    "- Threshold ≈ 0.46\n",
    "- F1 ≈ 0.527\n",
    "- Recall ≈ 0.69\n",
    "\n",
    "Esto permite adaptar el modelo a distintos objetivos operativos:\n",
    "- priorizar recall (detección temprana de devoluciones),\n",
    "- o priorizar precisión (control de costes).\n",
    "\n",
    "---\n",
    "\n",
    "## 8) Artefactos generados\n",
    "\n",
    "### Modelos\n",
    "modelos/devoluciones/xgb_final.json\n",
    "\n",
    "### Métricas y tracking\n",
    "modelos/devoluciones/leaderboard.csv\n",
    "modelos/devoluciones/saved_models.json\n",
    "modelos/devoluciones/metadata/\n",
    "\n",
    "### Datos procesados\n",
    "data/processed/devoluciones/\n",
    "\n",
    "---\n",
    "\n",
    "## 9) Conclusión\n",
    "\n",
    "El modelo final:\n",
    "- captura correctamente el gap entre canal online y físico,\n",
    "- incorpora información física, histórica y económica,\n",
    "- generaliza razonablemente bien en un split temporal exigente,\n",
    "- es directamente utilizable en un entorno productivo.\n",
    "\n",
    "El pipeline completo es **reproducible**, **auditable** y **extensible** para:\n",
    "- tuning adicional,\n",
    "- análisis de interpretabilidad,\n",
    "- simulaciones de impacto económico.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ea4668-08e3-412c-800f-74ffddf9930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import sqlite3\n",
    "import time\n",
    "import unicodedata\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    classification_report,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "\n",
    "DB_PATH = \"database/mi_base.db\"\n",
    "TABLE_NAME = \"base_modelo_devoluciones\"\n",
    "\n",
    "OUT_DIR = Path(\"modelos\") / \"devoluciones\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(OUT_DIR / \"metadata\").mkdir(exist_ok=True)\n",
    "\n",
    "DATA_DIR = Path(\"data\") / \"processed\" / \"devoluciones\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SplitConfig:\n",
    "    mode: str = \"temporal\"\n",
    "    test_size: float = 0.25\n",
    "    date_col: str = \"fecha_compra\"\n",
    "\n",
    "\n",
    "def dump_json(obj, path: Path) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "def normalize_text(s):\n",
    "    if pd.isna(s):\n",
    "        return s\n",
    "    s = unicodedata.normalize(\"NFKD\", str(s)).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    return s.lower().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98ea333-f436-4b4b-bcb9-09d1c198b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_threshold_best_f1(y_true: np.ndarray, y_proba: np.ndarray) -> Tuple[float, float]:\n",
    "    prec, rec, thr = precision_recall_curve(y_true, y_proba)\n",
    "    f1 = 2 * (prec * rec) / (prec + rec + 1e-9)\n",
    "\n",
    "    if len(thr) == 0:\n",
    "        return 0.5, float(f1.max()) if len(f1) else 0.0\n",
    "\n",
    "    idx = int(np.argmax(f1[:-1]))\n",
    "    return float(thr[idx]), float(f1[idx])\n",
    "\n",
    "\n",
    "def eval_binary_classifier(name: str, y_true: np.ndarray, y_proba: np.ndarray) -> Dict:\n",
    "    roc = float(roc_auc_score(y_true, y_proba))\n",
    "    pr = float(average_precision_score(y_true, y_proba))\n",
    "\n",
    "    y_pred_05 = (y_proba >= 0.5).astype(int)\n",
    "    rep_05 = classification_report(y_true, y_pred_05, output_dict=True, zero_division=0)\n",
    "\n",
    "    best_thr, _ = compute_threshold_best_f1(y_true, y_proba)\n",
    "    y_pred_best = (y_proba >= best_thr).astype(int)\n",
    "    rep_best = classification_report(y_true, y_pred_best, output_dict=True, zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"roc_auc_test\": roc,\n",
    "        \"pr_auc_test\": pr,\n",
    "        \"f1_pos@0.5\": float(rep_05[\"1\"][\"f1-score\"]),\n",
    "        \"prec_pos@0.5\": float(rep_05[\"1\"][\"precision\"]),\n",
    "        \"rec_pos@0.5\": float(rep_05[\"1\"][\"recall\"]),\n",
    "        \"best_thr_f1\": float(best_thr),\n",
    "        \"best_f1_pos\": float(rep_best[\"1\"][\"f1-score\"]),\n",
    "        \"best_prec_pos\": float(rep_best[\"1\"][\"precision\"]),\n",
    "        \"best_rec_pos\": float(rep_best[\"1\"][\"recall\"]),\n",
    "        \"support_pos\": int(rep_best[\"1\"][\"support\"]),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "411c5b09-8a1c-4293-9ee6-7da0dc580a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sklearn_model(model, name: str) -> str:\n",
    "    path = OUT_DIR / f\"{name}.joblib\"\n",
    "    joblib.dump(model, path)\n",
    "    return str(path)\n",
    "\n",
    "\n",
    "def save_xgb_booster(booster: xgb.Booster, name: str) -> str:\n",
    "    path = OUT_DIR / f\"{name}.json\"\n",
    "    booster.save_model(str(path))\n",
    "    return str(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "374399f0-7c0c-4ed3-bd18-6dee02d2e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() -> pd.DataFrame:\n",
    "    con = sqlite3.connect(DB_PATH)\n",
    "    try:\n",
    "        df = pd.read_sql_query(f\"SELECT * FROM {TABLE_NAME}\", con)\n",
    "    finally:\n",
    "        con.close()\n",
    "    return df\n",
    "\n",
    "\n",
    "def basic_checks(df: pd.DataFrame) -> None:\n",
    "    print(\"Filas:\", len(df))\n",
    "    print(\"Tasa devolucion global:\", round(float(df[\"devuelto\"].mean()), 4))\n",
    "\n",
    "    m_fisico = df[\"canal\"].astype(str).str.lower().isin([\"fisico\", \"físico\", \"tienda\", \"store\"])\n",
    "    print(\"Tasa devolucion online:\", round(float(df.loc[~m_fisico, \"devuelto\"].mean()), 4))\n",
    "    print(\"Tasa devolucion fisico:\", round(float(df.loc[m_fisico, \"devuelto\"].mean()), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "621c902e-2d1e-4cba-92c1-ee3bfbbcc655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df_in.copy()\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    df[\"fecha_compra\"] = pd.to_datetime(df[\"fecha_compra\"], errors=\"coerce\")\n",
    "    df[\"fecha_primer_compra\"] = pd.to_datetime(df[\"fecha_primer_compra\"], errors=\"coerce\")\n",
    "    df[\"fecha_ultima_compra\"] = pd.to_datetime(df[\"fecha_ultima_compra\"], errors=\"coerce\")\n",
    "\n",
    "    df[\"anio_compra\"] = df[\"fecha_compra\"].dt.year\n",
    "    df[\"mes_compra\"] = df[\"fecha_compra\"].dt.month\n",
    "\n",
    "    def temporada_from_mes(m):\n",
    "        if pd.isna(m):\n",
    "            return \"NA\"\n",
    "        m = int(m)\n",
    "        if m in [3, 4, 5, 6, 7, 8]:\n",
    "            return \"SS\"\n",
    "        if m in [9, 10, 11, 12, 1, 2]:\n",
    "            return \"FW\"\n",
    "        return \"NA\"\n",
    "\n",
    "    df[\"temporada_compra\"] = df[\"mes_compra\"].apply(temporada_from_mes)\n",
    "\n",
    "    df[\"edad_en_compra\"] = df[\"anio_compra\"] - df[\"anio_nacimiento\"]\n",
    "    df[\"antiguedad_cliente_dias\"] = (df[\"fecha_compra\"] - df[\"fecha_primer_compra\"]).dt.days\n",
    "\n",
    "    df[\"en_promocion\"] = df[\"promotion_id\"].notna().astype(\"int8\")\n",
    "\n",
    "    df[\"margen_relativo\"] = np.where(\n",
    "        df[\"precio_neto\"] > 0,\n",
    "        df[\"margen\"] / df[\"precio_neto\"],\n",
    "        0.0\n",
    "    )\n",
    "\n",
    "    ROPA_RANGES = {\n",
    "        \"XS\": {\"h\": (160, 168), \"w\": (50, 62)},\n",
    "        \"S\":  {\"h\": (165, 174), \"w\": (58, 70)},\n",
    "        \"M\":  {\"h\": (170, 180), \"w\": (65, 82)},\n",
    "        \"L\":  {\"h\": (175, 185), \"w\": (75, 95)},\n",
    "        \"XL\": {\"h\": (180, 200), \"w\": (90, 120)},\n",
    "    }\n",
    "\n",
    "    CALZADO_RANGES = {\n",
    "        39: (160, 170),\n",
    "        40: (165, 175),\n",
    "        41: (168, 178),\n",
    "        42: (170, 182),\n",
    "        43: (172, 185),\n",
    "        44: (175, 188),\n",
    "        45: (178, 195),\n",
    "    }\n",
    "\n",
    "    def infer_talla_ideal_ropa(h, w):\n",
    "        if pd.isna(h) or pd.isna(w):\n",
    "            return np.nan\n",
    "        best_talla = None\n",
    "        best_score = None\n",
    "        for talla, ranges in ROPA_RANGES.items():\n",
    "            h_low, h_high = ranges[\"h\"]\n",
    "            w_low, w_high = ranges[\"w\"]\n",
    "            h_mid = (h_low + h_high) / 2\n",
    "            w_mid = (w_low + w_high) / 2\n",
    "            dh = (h - h_mid) / (h_high - h_low)\n",
    "            dw = (w - w_mid) / (w_high - w_low)\n",
    "            score = dh**2 * 0.7 + dw**2 * 0.3\n",
    "            if (best_score is None) or (score < best_score):\n",
    "                best_score = score\n",
    "                best_talla = talla\n",
    "        return best_talla\n",
    "\n",
    "    def infer_talla_ideal_calzado(h):\n",
    "        if pd.isna(h):\n",
    "            return np.nan\n",
    "        best_talla = None\n",
    "        best_score = None\n",
    "        for talla, (h_low, h_high) in CALZADO_RANGES.items():\n",
    "            h_mid = (h_low + h_high) / 2\n",
    "            score = (h - h_mid) ** 2\n",
    "            if (best_score is None) or (score < best_score):\n",
    "                best_score = score\n",
    "                best_talla = talla\n",
    "        return str(best_talla) if best_talla is not None else np.nan\n",
    "\n",
    "    clientes = (\n",
    "        df.groupby(\"customer_id\", as_index=False)[[\"altura_cm\", \"peso_kg\"]]\n",
    "          .first()\n",
    "    )\n",
    "\n",
    "    clientes[\"talla_ideal_ropa\"] = [\n",
    "        infer_talla_ideal_ropa(h, w)\n",
    "        for h, w in zip(clientes[\"altura_cm\"], clientes[\"peso_kg\"])\n",
    "    ]\n",
    "\n",
    "    clientes[\"talla_ideal_calzado\"] = [\n",
    "        infer_talla_ideal_calzado(h)\n",
    "        for h in clientes[\"altura_cm\"]\n",
    "    ]\n",
    "\n",
    "    df = df.merge(\n",
    "        clientes[[\"customer_id\", \"talla_ideal_ropa\", \"talla_ideal_calzado\"]],\n",
    "        on=\"customer_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    ROPA_CATS_LOWER = {\"camiseta\", \"sudadera\", \"pantalon\", \"abrigo\", \"camisa\"}\n",
    "    CALZADO_CAT_LOWER = \"calzado\"\n",
    "\n",
    "    cat_lower = df[\"categoria\"].astype(str).str.lower()\n",
    "    talla_str = df[\"talla\"].astype(str)\n",
    "\n",
    "    tallas_ropa_orden = [\"XS\", \"S\", \"M\", \"L\", \"XL\"]\n",
    "    talla_idx_map = {t: i for i, t in enumerate(tallas_ropa_orden)}\n",
    "\n",
    "    df[\"desajuste_talla\"] = np.nan\n",
    "\n",
    "    mask_ropa = cat_lower.isin(ROPA_CATS_LOWER)\n",
    "    talla_idx = talla_str.map(talla_idx_map)\n",
    "    talla_ideal_idx = df[\"talla_ideal_ropa\"].map(talla_idx_map)\n",
    "\n",
    "    mask_ropa_valid = mask_ropa & talla_idx.notna() & talla_ideal_idx.notna()\n",
    "    df.loc[mask_ropa_valid, \"desajuste_talla\"] = (\n",
    "        talla_idx[mask_ropa_valid].astype(float) - talla_ideal_idx[mask_ropa_valid].astype(float)\n",
    "    )\n",
    "\n",
    "    mask_calzado = (cat_lower == CALZADO_CAT_LOWER)\n",
    "    talla_num = pd.to_numeric(df[\"talla\"], errors=\"coerce\")\n",
    "    talla_ideal_num = pd.to_numeric(df[\"talla_ideal_calzado\"], errors=\"coerce\")\n",
    "\n",
    "    mask_calzado_valid = mask_calzado & talla_num.notna() & talla_ideal_num.notna()\n",
    "    df.loc[mask_calzado_valid, \"desajuste_talla\"] = (\n",
    "        talla_num[mask_calzado_valid] - talla_ideal_num[mask_calzado_valid]\n",
    "    )\n",
    "\n",
    "    df[\"desajuste_talla_abs\"] = df[\"desajuste_talla\"].abs()\n",
    "\n",
    "    tallas_extremas = {\"XS\", \"XL\", \"39\", \"45\"}\n",
    "    df[\"talla_extrema\"] = df[\"talla\"].astype(str).isin(tallas_extremas).astype(\"int8\")\n",
    "\n",
    "    df[\"bmi\"] = np.where(\n",
    "        (df[\"altura_cm\"].notna()) & (df[\"altura_cm\"] > 0),\n",
    "        df[\"peso_kg\"] / (df[\"altura_cm\"] / 100.0) ** 2,\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    df = df.sort_values([\"fecha_compra\", \"customer_id\", \"ticket_id\", \"item_id\"]).reset_index(drop=True)\n",
    "\n",
    "    df[\"compras_previas_cliente\"] = df.groupby(\"customer_id\").cumcount()\n",
    "    df[\"devoluciones_previas_cliente\"] = df.groupby(\"customer_id\")[\"devuelto\"].cumsum() - df[\"devuelto\"]\n",
    "    df[\"ratio_devoluciones_previas_cliente\"] = np.where(\n",
    "        df[\"compras_previas_cliente\"] > 0,\n",
    "        df[\"devoluciones_previas_cliente\"] / df[\"compras_previas_cliente\"],\n",
    "        0.0\n",
    "    )\n",
    "\n",
    "    df[\"id_producto\"] = df[\"id_producto\"].fillna(\"UNKNOWN_PROD\")\n",
    "    df[\"ventas_previas_producto\"] = df.groupby(\"id_producto\").cumcount()\n",
    "    df[\"devoluciones_previas_producto\"] = df.groupby(\"id_producto\")[\"devuelto\"].cumsum() - df[\"devuelto\"]\n",
    "    df[\"ratio_devoluciones_previas_producto\"] = np.where(\n",
    "        df[\"ventas_previas_producto\"] > 0,\n",
    "        df[\"devoluciones_previas_producto\"] / df[\"ventas_previas_producto\"],\n",
    "        0.0\n",
    "    )\n",
    "\n",
    "    precio_med_cat = df.groupby(\"categoria\")[\"precio_neto\"].transform(\"mean\")\n",
    "    df[\"precio_rel_cat\"] = np.where(\n",
    "        precio_med_cat > 0,\n",
    "        df[\"precio_neto\"] / precio_med_cat,\n",
    "        1.0\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23dfcdc4-b0c9-4035-b575-5bcbac048195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df_fe: pd.DataFrame, cfg: SplitConfig) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    if cfg.mode == \"random\":\n",
    "        df_tr, df_te = train_test_split(\n",
    "            df_fe,\n",
    "            test_size=cfg.test_size,\n",
    "            random_state=RANDOM_SEED,\n",
    "            stratify=df_fe[\"devuelto\"].astype(\"int8\")\n",
    "        )\n",
    "        return df_tr, df_te\n",
    "\n",
    "    if cfg.mode == \"temporal\":\n",
    "        df_sorted = df_fe.sort_values([cfg.date_col, \"ticket_id\", \"item_id\"]).reset_index(drop=True)\n",
    "        cut_idx = int((1.0 - cfg.test_size) * len(df_sorted))\n",
    "        df_tr = df_sorted.iloc[:cut_idx].copy()\n",
    "        df_te = df_sorted.iloc[cut_idx:].copy()\n",
    "        return df_tr, df_te\n",
    "\n",
    "    raise ValueError(f\"Split mode no soportado: {cfg.mode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaf94e6b-3284-4977-8ec0-f80e6766cc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xy_from_frames(\n",
    "    df_train: pd.DataFrame,\n",
    "    df_test: pd.DataFrame\n",
    ") -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series, Dict]:\n",
    "\n",
    "    y_train = df_train[\"devuelto\"].astype(\"int8\")\n",
    "    y_test = df_test[\"devuelto\"].astype(\"int8\")\n",
    "\n",
    "    cols_to_drop = [\n",
    "        \"item_id\", \"ticket_id\", \"customer_id\", \"sku\", \"store_id\", \"id_producto\",\n",
    "        \"fecha_compra\", \"fecha_primer_compra\", \"fecha_ultima_compra\",\n",
    "        \"anio_nacimiento\", \"edad_alta\",\n",
    "        \"devuelto\",\n",
    "        \"talla_ideal_ropa\", \"talla_ideal_calzado\",\n",
    "        \"promotion_id\",\n",
    "    ]\n",
    "\n",
    "    X_train = df_train.drop(columns=[c for c in cols_to_drop if c in df_train.columns]).copy()\n",
    "    X_test = df_test.drop(columns=[c for c in cols_to_drop if c in df_test.columns]).copy()\n",
    "\n",
    "    na_flag_cols = [\n",
    "        \"provincia_cliente\",\n",
    "        \"comunidad\",\n",
    "        \"altura_cm\",\n",
    "        \"peso_kg\",\n",
    "        \"edad_en_compra\",\n",
    "        \"antiguedad_cliente_dias\",\n",
    "        \"desajuste_talla\",\n",
    "        \"bmi\",\n",
    "    ]\n",
    "    for col in na_flag_cols:\n",
    "        if col in X_train.columns:\n",
    "            X_train[f\"missing_{col}\"] = X_train[col].isna().astype(\"int8\")\n",
    "            X_test[f\"missing_{col}\"] = X_test[col].isna().astype(\"int8\")\n",
    "\n",
    "    cat_cols = [\n",
    "        \"canal\",\n",
    "        \"provincia_tienda\",\n",
    "        \"provincia_cliente\",\n",
    "        \"comunidad\",\n",
    "        \"categoria\",\n",
    "        \"color\",\n",
    "        \"talla\",\n",
    "        \"temporada_compra\",\n",
    "    ]\n",
    "    for col in cat_cols:\n",
    "        if col in X_train.columns:\n",
    "            X_train[col] = X_train[col].fillna(\"UNKNOWN\").apply(normalize_text)\n",
    "            X_test[col] = X_test[col].fillna(\"UNKNOWN\").apply(normalize_text)\n",
    "\n",
    "    num_cols_to_impute = [\n",
    "        \"altura_cm\",\n",
    "        \"peso_kg\",\n",
    "        \"edad_en_compra\",\n",
    "        \"antiguedad_cliente_dias\",\n",
    "        \"descuento\",\n",
    "        \"precio_neto\",\n",
    "        \"coste_bruto\",\n",
    "        \"margen\",\n",
    "        \"margen_relativo\",\n",
    "        \"compras_previas_cliente\",\n",
    "        \"devoluciones_previas_cliente\",\n",
    "        \"ratio_devoluciones_previas_cliente\",\n",
    "        \"ventas_previas_producto\",\n",
    "        \"devoluciones_previas_producto\",\n",
    "        \"ratio_devoluciones_previas_producto\",\n",
    "        \"desajuste_talla\",\n",
    "        \"desajuste_talla_abs\",\n",
    "        \"bmi\",\n",
    "        \"precio_rel_cat\",\n",
    "    ]\n",
    "\n",
    "    medians = {}\n",
    "    for col in num_cols_to_impute:\n",
    "        if col in X_train.columns:\n",
    "            med = float(pd.to_numeric(X_train[col], errors=\"coerce\").median())\n",
    "            medians[col] = med\n",
    "            X_train[col] = pd.to_numeric(X_train[col], errors=\"coerce\").fillna(med)\n",
    "            X_test[col] = pd.to_numeric(X_test[col], errors=\"coerce\").fillna(med)\n",
    "\n",
    "    X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    X_test = X_test.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    used_cat_cols = [c for c in cat_cols if c in X_train.columns]\n",
    "    X_train_enc = pd.get_dummies(X_train, columns=used_cat_cols, drop_first=True)\n",
    "    X_test_enc = pd.get_dummies(X_test, columns=used_cat_cols, drop_first=True)\n",
    "\n",
    "    x_encoded_columns = list(X_train_enc.columns)\n",
    "    X_test_enc = X_test_enc.reindex(columns=x_encoded_columns, fill_value=0)\n",
    "\n",
    "    base_cols = [\n",
    "        \"descuento\",\n",
    "        \"precio_neto\",\n",
    "        \"coste_bruto\",\n",
    "        \"margen\",\n",
    "        \"n_pedidos\",\n",
    "        \"n_items_comprados\",\n",
    "        \"altura_cm\",\n",
    "        \"peso_kg\",\n",
    "        \"anio_compra\",\n",
    "        \"mes_compra\",\n",
    "        \"edad_en_compra\",\n",
    "        \"antiguedad_cliente_dias\",\n",
    "        \"en_promocion\",\n",
    "        \"margen_relativo\",\n",
    "        \"desajuste_talla\",\n",
    "        \"desajuste_talla_abs\",\n",
    "        \"talla_extrema\",\n",
    "        \"bmi\",\n",
    "        \"compras_previas_cliente\",\n",
    "        \"devoluciones_previas_cliente\",\n",
    "        \"ratio_devoluciones_previas_cliente\",\n",
    "        \"ventas_previas_producto\",\n",
    "        \"devoluciones_previas_producto\",\n",
    "        \"ratio_devoluciones_previas_producto\",\n",
    "        \"precio_rel_cat\",\n",
    "        \"missing_provincia_cliente\",\n",
    "        \"missing_comunidad\",\n",
    "        \"missing_altura_cm\",\n",
    "        \"missing_peso_kg\",\n",
    "        \"missing_edad_en_compra\",\n",
    "        \"missing_antiguedad_cliente_dias\",\n",
    "        \"missing_desajuste_talla\",\n",
    "        \"missing_bmi\",\n",
    "    ]\n",
    "\n",
    "    extra_prefixes = [\"canal_\", \"comunidad_\", \"categoria_\", \"color_\", \"talla_\", \"temporada_compra_\"]\n",
    "    extra_cols = [c for c in x_encoded_columns if any(c.startswith(p) for p in extra_prefixes)]\n",
    "\n",
    "    base_cols_present = [c for c in base_cols if c in x_encoded_columns]\n",
    "    cols_final = list(dict.fromkeys(base_cols_present + extra_cols))\n",
    "\n",
    "    X_train_final = X_train_enc[cols_final].copy()\n",
    "    X_test_final = X_test_enc[cols_final].copy()\n",
    "\n",
    "    prep_meta = {\n",
    "        \"x_encoded_columns\": x_encoded_columns,\n",
    "        \"cols_final\": cols_final,\n",
    "        \"medians\": medians,\n",
    "        \"cat_cols\": used_cat_cols,\n",
    "        \"note\": \"Medians calculadas en train y aplicadas a test. One-hot alineado por columnas de train.\",\n",
    "    }\n",
    "\n",
    "    return X_train_final, y_train, X_test_final, y_test, prep_meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd8c3215-b927-4a35-9ef3-2151882f3f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_data(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    df_train: pd.DataFrame,\n",
    "    df_test: pd.DataFrame,\n",
    "    prep_meta: Dict,\n",
    "    split_cfg: SplitConfig\n",
    ") -> None:\n",
    "\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    X_train.to_parquet(DATA_DIR / \"X_train.parquet\", index=False)\n",
    "    X_test.to_parquet(DATA_DIR / \"X_test.parquet\", index=False)\n",
    "    y_train.to_frame(\"devuelto\").to_parquet(DATA_DIR / \"y_train.parquet\", index=False)\n",
    "    y_test.to_frame(\"devuelto\").to_parquet(DATA_DIR / \"y_test.parquet\", index=False)\n",
    "\n",
    "    keep_cols = [\"fecha_compra\", \"ticket_id\", \"item_id\", \"customer_id\", \"devuelto\"]\n",
    "    keep_cols_train = [c for c in keep_cols if c in df_train.columns]\n",
    "    keep_cols_test = [c for c in keep_cols if c in df_test.columns]\n",
    "\n",
    "    df_train[keep_cols_train].to_parquet(DATA_DIR / \"train_index.parquet\", index=False)\n",
    "    df_test[keep_cols_test].to_parquet(DATA_DIR / \"test_index.parquet\", index=False)\n",
    "\n",
    "    dump_json(prep_meta, OUT_DIR / \"metadata\" / \"preprocess_meta.json\")\n",
    "    dump_json(prep_meta[\"cols_final\"], OUT_DIR / \"metadata\" / \"cols_final.json\")\n",
    "    dump_json(prep_meta[\"x_encoded_columns\"], OUT_DIR / \"metadata\" / \"x_encoded_columns.json\")\n",
    "\n",
    "    split_meta = {\n",
    "        \"mode\": split_cfg.mode,\n",
    "        \"test_size\": split_cfg.test_size,\n",
    "        \"date_col\": split_cfg.date_col,\n",
    "        \"n_train\": int(len(df_train)),\n",
    "        \"n_test\": int(len(df_test)),\n",
    "        \"target_rate_train\": float(df_train[\"devuelto\"].mean()),\n",
    "        \"target_rate_test\": float(df_test[\"devuelto\"].mean()),\n",
    "        \"min_date_train\": str(pd.to_datetime(df_train[split_cfg.date_col]).min()) if split_cfg.date_col in df_train.columns else None,\n",
    "        \"max_date_train\": str(pd.to_datetime(df_train[split_cfg.date_col]).max()) if split_cfg.date_col in df_train.columns else None,\n",
    "        \"min_date_test\": str(pd.to_datetime(df_test[split_cfg.date_col]).min()) if split_cfg.date_col in df_test.columns else None,\n",
    "        \"max_date_test\": str(pd.to_datetime(df_test[split_cfg.date_col]).max()) if split_cfg.date_col in df_test.columns else None,\n",
    "    }\n",
    "    dump_json(split_meta, OUT_DIR / \"metadata\" / \"split_meta.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2480313-28b6-4a42-bc6c-9b794f01164b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas: 905445\n",
      "Tasa devolucion global: 0.2988\n",
      "Tasa devolucion online: 0.3196\n",
      "Tasa devolucion fisico: 0.2344\n",
      "Voy a guardar datos procesados en: C:\\Users\\PEDRO\\Desktop\\ropa\\data\\processed\\devoluciones\n",
      "Datos procesados guardados\n"
     ]
    }
   ],
   "source": [
    "split_cfg = SplitConfig(mode=\"temporal\", test_size=0.25, date_col=\"fecha_compra\")\n",
    "\n",
    "df = load_data()\n",
    "basic_checks(df)\n",
    "\n",
    "df_fe = feature_engineering(df)\n",
    "df_train, df_test = split_train_test(df_fe, split_cfg)\n",
    "\n",
    "X_train, y_train, X_test, y_test, prep_meta = build_xy_from_frames(df_train, df_test)\n",
    "\n",
    "print(\"Voy a guardar datos procesados en:\", DATA_DIR.resolve())\n",
    "save_processed_data(X_train, y_train, X_test, y_test, df_train, df_test, prep_meta, split_cfg)\n",
    "print(\"Datos procesados guardados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29bb0541-1101-4fb7-acd5-c612a7cfa228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos en data/processed:\n",
      "- test_index.parquet\n",
      "- train_index.parquet\n",
      "- X_test.parquet\n",
      "- X_train.parquet\n",
      "- y_test.parquet\n",
      "- y_train.parquet\n"
     ]
    }
   ],
   "source": [
    "print(\"Archivos en data/processed:\")\n",
    "for p in sorted(DATA_DIR.glob(\"*\")):\n",
    "    print(\"-\", p.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b54d5c77-bb6c-45ab-a0e3-16dd71f799a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models():\n",
    "    models = []\n",
    "\n",
    "    models.append((\"rf\", RandomForestClassifier(\n",
    "        n_estimators=600,\n",
    "        max_depth=18,\n",
    "        min_samples_leaf=200,\n",
    "        min_samples_split=400,\n",
    "        max_features=\"sqrt\",\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        n_jobs=1,\n",
    "        random_state=RANDOM_SEED\n",
    "    )))\n",
    "\n",
    "    models.append((\"extratrees\", ExtraTreesClassifier(\n",
    "        n_estimators=1400,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=60,\n",
    "        min_samples_split=300,\n",
    "        max_features=\"sqrt\",\n",
    "        bootstrap=False,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        n_jobs=1,\n",
    "        random_state=RANDOM_SEED\n",
    "    )))\n",
    "\n",
    "    models.append((\"histgb\", HistGradientBoostingClassifier(\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        max_iter=800,\n",
    "        min_samples_leaf=80,\n",
    "        l2_regularization=0.3,\n",
    "        random_state=RANDOM_SEED\n",
    "    )))\n",
    "\n",
    "    models.append((\"logreg\", LogisticRegression(\n",
    "        max_iter=4000,\n",
    "        class_weight=\"balanced\",\n",
    "        solver=\"lbfgs\",\n",
    "        n_jobs=1\n",
    "    )))\n",
    "\n",
    "    models.append((\"sgd_logloss\", SGDClassifier(\n",
    "        loss=\"log_loss\",\n",
    "        alpha=5e-5,\n",
    "        penalty=\"l2\",\n",
    "        class_weight=\"balanced\",\n",
    "        max_iter=5000,\n",
    "        tol=1e-3,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1,\n",
    "        n_iter_no_change=10,\n",
    "        random_state=RANDOM_SEED\n",
    "    )))\n",
    "\n",
    "    models.append((\"xgb_final\", \"xgb_final\"))\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77ab7788-b192-4fe9-9d65-fbd0f8cce5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_train_with_es(\n",
    "    X_tr, y_tr, X_val, y_val,\n",
    "    w_tr=None, w_val=None,\n",
    "    params=None,\n",
    "    num_boost_round=3000,\n",
    "    early_stopping_rounds=80,\n",
    "    verbose_eval=200,\n",
    "    seed=42\n",
    "):\n",
    "    if params is None:\n",
    "        params = {}\n",
    "\n",
    "    base_params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"aucpr\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"seed\": seed,\n",
    "        \"max_bin\": 256,\n",
    "    }\n",
    "    base_params.update(params)\n",
    "\n",
    "    dtr = xgb.DMatrix(X_tr, label=y_tr, weight=w_tr)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val, weight=w_val)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params=base_params,\n",
    "        dtrain=dtr,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=[(dtr, \"train\"), (dval, \"val\")],\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        verbose_eval=verbose_eval\n",
    "    )\n",
    "\n",
    "    proba_val = booster.predict(dval, iteration_range=(0, booster.best_iteration + 1))\n",
    "    pr_auc = float(average_precision_score(y_val, proba_val))\n",
    "    return booster, pr_auc\n",
    "\n",
    "\n",
    "def xgb_sample_params(rng: np.random.Generator) -> Dict:\n",
    "    return {\n",
    "        \"max_depth\": int(rng.integers(3, 8)),\n",
    "        \"min_child_weight\": float(rng.choice([50, 80, 120, 200, 300])),\n",
    "        \"subsample\": float(rng.uniform(0.65, 0.95)),\n",
    "        \"colsample_bytree\": float(rng.uniform(0.60, 0.95)),\n",
    "        \"gamma\": float(rng.uniform(0.0, 0.6)),\n",
    "        \"lambda\": float(rng.uniform(0.5, 4.0)),\n",
    "        \"alpha\": float(rng.uniform(0.0, 2.0)),\n",
    "        \"eta\": float(rng.uniform(0.02, 0.08)),\n",
    "    }\n",
    "\n",
    "\n",
    "def xgb_fit_final_model(X_train, y_train):\n",
    "    xgb_val_size = 0.15\n",
    "    xgb_final_val_size = 0.12\n",
    "    n_trials = 12\n",
    "    early_stop = 80\n",
    "    max_rounds = 3000\n",
    "    extra_rounds = 200\n",
    "\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_train, y_train,\n",
    "        test_size=xgb_val_size,\n",
    "        random_state=RANDOM_SEED,\n",
    "        stratify=y_train\n",
    "    )\n",
    "\n",
    "    w_tr = compute_sample_weight(class_weight=\"balanced\", y=y_tr)\n",
    "    w_val = compute_sample_weight(class_weight=\"balanced\", y=y_val)\n",
    "\n",
    "    rng = np.random.default_rng(RANDOM_SEED)\n",
    "    best = {\"pr_auc\": -1.0, \"params\": None, \"booster\": None}\n",
    "\n",
    "    for _ in range(n_trials):\n",
    "        params = xgb_sample_params(rng)\n",
    "        booster, pr_auc = xgb_train_with_es(\n",
    "            X_tr, y_tr, X_val, y_val,\n",
    "            w_tr=w_tr, w_val=w_val,\n",
    "            params=params,\n",
    "            num_boost_round=max_rounds,\n",
    "            early_stopping_rounds=early_stop,\n",
    "            verbose_eval=250,\n",
    "            seed=RANDOM_SEED\n",
    "        )\n",
    "        if pr_auc > best[\"pr_auc\"]:\n",
    "            best = {\"pr_auc\": pr_auc, \"params\": params, \"booster\": booster}\n",
    "\n",
    "    X_tr2, X_val2, y_tr2, y_val2 = train_test_split(\n",
    "        X_train, y_train,\n",
    "        test_size=xgb_final_val_size,\n",
    "        random_state=123,\n",
    "        stratify=y_train\n",
    "    )\n",
    "\n",
    "    w_tr2 = compute_sample_weight(class_weight=\"balanced\", y=y_tr2)\n",
    "    w_val2 = compute_sample_weight(class_weight=\"balanced\", y=y_val2)\n",
    "\n",
    "    best_params = dict(best[\"params\"])\n",
    "    best_iter = int(best[\"booster\"].best_iteration)\n",
    "    num_rounds = max(best_iter + extra_rounds, 800)\n",
    "\n",
    "    booster_final, pr_auc_val = xgb_train_with_es(\n",
    "        X_tr2, y_tr2, X_val2, y_val2,\n",
    "        w_tr=w_tr2, w_val=w_val2,\n",
    "        params=best_params,\n",
    "        num_boost_round=num_rounds,\n",
    "        early_stopping_rounds=early_stop,\n",
    "        verbose_eval=200,\n",
    "        seed=RANDOM_SEED\n",
    "    )\n",
    "\n",
    "    meta = {\n",
    "        \"best_params\": best_params,\n",
    "        \"search_best_iter\": best_iter,\n",
    "        \"final_best_iter\": int(booster_final.best_iteration),\n",
    "        \"final_pr_auc_val_sklearn\": float(pr_auc_val),\n",
    "        \"num_rounds_used\": int(num_rounds),\n",
    "    }\n",
    "    return booster_final, meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9142081-f63a-4ead-8790-20b1a402fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_eval_save_sklearn(model, name: str, X_train, y_train, X_test, y_test):\n",
    "    t0 = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    fit_secs = time.time() - t0\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        scores = model.decision_function(X_test)\n",
    "        y_proba = 1.0 / (1.0 + np.exp(-scores))\n",
    "\n",
    "    row = eval_binary_classifier(name, y_test.to_numpy(), y_proba)\n",
    "    row[\"fit_time_sec\"] = float(fit_secs)\n",
    "    row[\"n_features\"] = int(X_train.shape[1])\n",
    "\n",
    "    path = save_sklearn_model(model, name)\n",
    "    return row, path\n",
    "\n",
    "\n",
    "def update_outputs(results: List[Dict], saved: List[Dict]) -> pd.DataFrame:\n",
    "    leaderboard = pd.DataFrame(results).sort_values(\n",
    "        [\"pr_auc_test\", \"roc_auc_test\", \"best_f1_pos\"],\n",
    "        ascending=False\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    leaderboard.to_csv(OUT_DIR / \"leaderboard.csv\", index=False, encoding=\"utf-8\")\n",
    "    dump_json(saved, OUT_DIR / \"saved_models.json\")\n",
    "    return leaderboard\n",
    "\n",
    "\n",
    "def train_one_model(name: str, model, X_train, y_train, X_test, y_test, results, saved) -> pd.DataFrame:\n",
    "    print(\"Entrenando:\", name)\n",
    "\n",
    "    if name != \"xgb_final\":\n",
    "        row, path = fit_eval_save_sklearn(model, name, X_train, y_train, X_test, y_test)\n",
    "        results.append(row)\n",
    "        saved.append({\"model\": name, \"path\": path})\n",
    "        leaderboard = update_outputs(results, saved)\n",
    "        print(\"Guardado:\", path, \"PR-AUC:\", round(row[\"pr_auc_test\"], 4), \"ROC-AUC:\", round(row[\"roc_auc_test\"], 4))\n",
    "        return leaderboard\n",
    "\n",
    "    booster_final, meta = xgb_fit_final_model(X_train, y_train)\n",
    "\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    y_proba = booster_final.predict(dtest, iteration_range=(0, booster_final.best_iteration + 1))\n",
    "\n",
    "    row = eval_binary_classifier(\"xgb_final\", y_test.to_numpy(), y_proba)\n",
    "    results.append(row)\n",
    "\n",
    "    path = save_xgb_booster(booster_final, \"xgb_final\")\n",
    "    saved.append({\"model\": \"xgb_final\", \"path\": path})\n",
    "\n",
    "    dump_json(meta, OUT_DIR / \"metadata\" / \"xgb_meta.json\")\n",
    "\n",
    "    leaderboard = update_outputs(results, saved)\n",
    "    print(\"Guardado:\", path, \"PR-AUC:\", round(row[\"pr_auc_test\"], 4), \"ROC-AUC:\", round(row[\"roc_auc_test\"], 4))\n",
    "    return leaderboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56158e1b-51e1-4a04-9233-b525f5106368",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "saved = []\n",
    "models = dict(build_models())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53d31f9f-1c9e-4281-b513-cce656b9120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando: xgb_final\n",
      "[0]\ttrain-aucpr:0.65137\tval-aucpr:0.64429\n",
      "[250]\ttrain-aucpr:0.70245\tval-aucpr:0.69747\n",
      "[500]\ttrain-aucpr:0.70625\tval-aucpr:0.70032\n",
      "[750]\ttrain-aucpr:0.70796\tval-aucpr:0.70105\n",
      "[1000]\ttrain-aucpr:0.70927\tval-aucpr:0.70146\n",
      "[1250]\ttrain-aucpr:0.71052\tval-aucpr:0.70181\n",
      "[1500]\ttrain-aucpr:0.71153\tval-aucpr:0.70197\n",
      "[1535]\ttrain-aucpr:0.71165\tval-aucpr:0.70196\n",
      "[0]\ttrain-aucpr:0.65174\tval-aucpr:0.64821\n",
      "[250]\ttrain-aucpr:0.71266\tval-aucpr:0.70162\n",
      "[457]\ttrain-aucpr:0.71787\tval-aucpr:0.70198\n",
      "[0]\ttrain-aucpr:0.64534\tval-aucpr:0.64158\n",
      "[250]\ttrain-aucpr:0.71008\tval-aucpr:0.70157\n",
      "[500]\ttrain-aucpr:0.71525\tval-aucpr:0.70263\n",
      "[732]\ttrain-aucpr:0.71868\tval-aucpr:0.70272\n",
      "[0]\ttrain-aucpr:0.67837\tval-aucpr:0.67101\n",
      "[250]\ttrain-aucpr:0.70650\tval-aucpr:0.69858\n",
      "[500]\ttrain-aucpr:0.71299\tval-aucpr:0.70253\n",
      "[750]\ttrain-aucpr:0.71660\tval-aucpr:0.70364\n",
      "[1000]\ttrain-aucpr:0.71941\tval-aucpr:0.70390\n",
      "[1250]\ttrain-aucpr:0.72194\tval-aucpr:0.70407\n",
      "[1300]\ttrain-aucpr:0.72246\tval-aucpr:0.70407\n",
      "[0]\ttrain-aucpr:0.64472\tval-aucpr:0.64068\n",
      "[250]\ttrain-aucpr:0.70967\tval-aucpr:0.70150\n",
      "[500]\ttrain-aucpr:0.71487\tval-aucpr:0.70302\n",
      "[750]\ttrain-aucpr:0.71886\tval-aucpr:0.70339\n",
      "[893]\ttrain-aucpr:0.72082\tval-aucpr:0.70335\n",
      "[0]\ttrain-aucpr:0.65276\tval-aucpr:0.64880\n",
      "[250]\ttrain-aucpr:0.71660\tval-aucpr:0.70231\n",
      "[417]\ttrain-aucpr:0.72237\tval-aucpr:0.70261\n",
      "[0]\ttrain-aucpr:0.65217\tval-aucpr:0.64834\n",
      "[250]\ttrain-aucpr:0.71243\tval-aucpr:0.70201\n",
      "[500]\ttrain-aucpr:0.71790\tval-aucpr:0.70254\n",
      "[547]\ttrain-aucpr:0.71882\tval-aucpr:0.70253\n",
      "[0]\ttrain-aucpr:0.65219\tval-aucpr:0.64757\n",
      "[250]\ttrain-aucpr:0.71606\tval-aucpr:0.70251\n",
      "[356]\ttrain-aucpr:0.71955\tval-aucpr:0.70259\n",
      "[0]\ttrain-aucpr:0.64436\tval-aucpr:0.64051\n",
      "[250]\ttrain-aucpr:0.70887\tval-aucpr:0.70110\n",
      "[500]\ttrain-aucpr:0.71377\tval-aucpr:0.70276\n",
      "[655]\ttrain-aucpr:0.71592\tval-aucpr:0.70295\n",
      "[0]\ttrain-aucpr:0.62665\tval-aucpr:0.62326\n",
      "[250]\ttrain-aucpr:0.69969\tval-aucpr:0.69496\n",
      "[500]\ttrain-aucpr:0.70410\tval-aucpr:0.69897\n",
      "[750]\ttrain-aucpr:0.70595\tval-aucpr:0.70022\n",
      "[1000]\ttrain-aucpr:0.70726\tval-aucpr:0.70082\n",
      "[1250]\ttrain-aucpr:0.70848\tval-aucpr:0.70141\n",
      "[1500]\ttrain-aucpr:0.70949\tval-aucpr:0.70180\n",
      "[1750]\ttrain-aucpr:0.71024\tval-aucpr:0.70198\n",
      "[2000]\ttrain-aucpr:0.71091\tval-aucpr:0.70207\n",
      "[2215]\ttrain-aucpr:0.71149\tval-aucpr:0.70214\n",
      "[0]\ttrain-aucpr:0.68361\tval-aucpr:0.67614\n",
      "[250]\ttrain-aucpr:0.71519\tval-aucpr:0.70218\n",
      "[500]\ttrain-aucpr:0.72254\tval-aucpr:0.70316\n",
      "[686]\ttrain-aucpr:0.72687\tval-aucpr:0.70317\n",
      "[0]\ttrain-aucpr:0.64537\tval-aucpr:0.64184\n",
      "[250]\ttrain-aucpr:0.70431\tval-aucpr:0.69802\n",
      "[500]\ttrain-aucpr:0.70931\tval-aucpr:0.70144\n",
      "[750]\ttrain-aucpr:0.71201\tval-aucpr:0.70254\n",
      "[1000]\ttrain-aucpr:0.71398\tval-aucpr:0.70285\n",
      "[1250]\ttrain-aucpr:0.71574\tval-aucpr:0.70306\n",
      "[1493]\ttrain-aucpr:0.71731\tval-aucpr:0.70309\n",
      "[0]\ttrain-aucpr:0.67798\tval-aucpr:0.67903\n",
      "[200]\ttrain-aucpr:0.70335\tval-aucpr:0.70018\n",
      "[400]\ttrain-aucpr:0.71031\tval-aucpr:0.70478\n",
      "[600]\ttrain-aucpr:0.71368\tval-aucpr:0.70615\n",
      "[800]\ttrain-aucpr:0.71611\tval-aucpr:0.70674\n",
      "[1000]\ttrain-aucpr:0.71821\tval-aucpr:0.70689\n",
      "[1011]\ttrain-aucpr:0.71829\tval-aucpr:0.70688\n",
      "Guardado: modelos\\devoluciones\\xgb_final.json PR-AUC: 0.5687 ROC-AUC: 0.6984\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>roc_auc_test</th>\n",
       "      <th>pr_auc_test</th>\n",
       "      <th>f1_pos@0.5</th>\n",
       "      <th>prec_pos@0.5</th>\n",
       "      <th>rec_pos@0.5</th>\n",
       "      <th>best_thr_f1</th>\n",
       "      <th>best_f1_pos</th>\n",
       "      <th>best_prec_pos</th>\n",
       "      <th>best_rec_pos</th>\n",
       "      <th>support_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgb_final</td>\n",
       "      <td>0.698436</td>\n",
       "      <td>0.568677</td>\n",
       "      <td>0.524156</td>\n",
       "      <td>0.464823</td>\n",
       "      <td>0.600852</td>\n",
       "      <td>0.457833</td>\n",
       "      <td>0.526753</td>\n",
       "      <td>0.425684</td>\n",
       "      <td>0.690757</td>\n",
       "      <td>71397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  roc_auc_test  pr_auc_test  f1_pos@0.5  prec_pos@0.5  \\\n",
       "0  xgb_final      0.698436     0.568677    0.524156      0.464823   \n",
       "\n",
       "   rec_pos@0.5  best_thr_f1  best_f1_pos  best_prec_pos  best_rec_pos  \\\n",
       "0     0.600852     0.457833     0.526753       0.425684      0.690757   \n",
       "\n",
       "   support_pos  \n",
       "0        71397  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard = train_one_model(\n",
    "    \"xgb_final\",\n",
    "    \"xgb_final\",\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    results, saved\n",
    ")\n",
    "leaderboard.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e4443f4-7ef3-42e4-81e2-057bcf90b144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory:\n",
      "C:\\Users\\pmace\\Desktop\\ropa\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Working directory:\")\n",
    "print(Path.cwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a498530b-4e1f-4932-a4a1-558acb72bd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando datos procesados en:\n",
      "C:\\Users\\pmace\\Desktop\\ropa\\data\\processed\n",
      "Archivos encontrados:\n",
      "- devoluciones\n",
      "- df_all2.pkl\n",
      "- recs_test_small.pkl\n",
      "- scen_test_small.pkl\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"data/processed\")\n",
    "\n",
    "print(\"Buscando datos procesados en:\")\n",
    "print(DATA_DIR.resolve())\n",
    "\n",
    "if not DATA_DIR.exists():\n",
    "    print(\"La carpeta data/processed NO existe\")\n",
    "else:\n",
    "    files = list(DATA_DIR.glob(\"*\"))\n",
    "    if not files:\n",
    "        print(\"La carpeta existe pero está vacía\")\n",
    "    else:\n",
    "        print(\"Archivos encontrados:\")\n",
    "        for f in sorted(files):\n",
    "            print(\"-\", f.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0962dcd2-17d6-4be6-a4fe-2d236904bce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando modelos en:\n",
      "C:\\Users\\pmace\\Desktop\\ropa\\modelos\\devoluciones\n",
      "Contenido encontrado:\n",
      "- A1_encoder.joblib\n",
      "- A1_metadata.json\n",
      "- A2_encoder.joblib\n",
      "- A2_metadata.json\n",
      "- extratrees.joblib\n",
      "- histgb.joblib\n",
      "- leaderboard.csv\n",
      "- logreg.joblib\n",
      "- metadata\n",
      "- model_a1_encoder.joblib\n",
      "- model_a1_metadata.json\n",
      "- model_a2_encoder.joblib\n",
      "- model_a2_metadata.json\n",
      "- model_a_encoder.joblib\n",
      "- model_a_metadata.json\n",
      "- rf.joblib\n",
      "- saved_models.json\n",
      "- sgd_logloss.joblib\n",
      "- xgb_A1_multiclass.json\n",
      "- xgb_A2_rank.json\n",
      "- xgb_final.json\n",
      "- xgb_model_a.json\n",
      "- xgb_model_a1.json\n",
      "- xgb_model_a1_talla.json\n",
      "- xgb_model_a1_talla_encoder.joblib\n",
      "- xgb_model_a1_talla_metadata.json\n",
      "- xgb_model_a2.json\n",
      "- xgb_model_a2_talla_ctx.json\n",
      "- xgb_model_a2_talla_ctx_encoder.joblib\n",
      "- xgb_model_a2_talla_ctx_metadata.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODELS_DIR = Path(\"modelos/devoluciones\")\n",
    "\n",
    "print(\"Buscando modelos en:\")\n",
    "print(MODELS_DIR.resolve())\n",
    "\n",
    "if not MODELS_DIR.exists():\n",
    "    print(\"La carpeta modelos/devoluciones NO existe\")\n",
    "else:\n",
    "    files = list(MODELS_DIR.glob(\"*\"))\n",
    "    if not files:\n",
    "        print(\"La carpeta existe pero está vacía\")\n",
    "    else:\n",
    "        print(\"Contenido encontrado:\")\n",
    "        for f in sorted(files):\n",
    "            print(\"-\", f.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5315556a-8a1b-47d5-b958-0023e8f4d103",
   "metadata": {},
   "source": [
    "# lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f3eae7-d059-4f24-835d-9962f6c5a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_PATH = Path(\"data/processed/devoluciones\")\n",
    "\n",
    "X_train = pd.read_parquet(BASE_PATH / \"X_train.parquet\")\n",
    "X_test  = pd.read_parquet(BASE_PATH / \"X_test.parquet\")\n",
    "y_train = pd.read_parquet(BASE_PATH / \"y_train.parquet\")\n",
    "y_test  = pd.read_parquet(BASE_PATH / \"y_test.parquet\")\n",
    "\n",
    "train_idx = pd.read_parquet(BASE_PATH / \"train_index.parquet\")\n",
    "test_idx  = pd.read_parquet(BASE_PATH / \"test_index.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "477f8f0d-9a9a-4c18-8afd-3f943a0882ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== X_train ===\n",
      "Shape: (679083, 83)\n",
      "Columns:\n",
      " - descuento\n",
      " - precio_neto\n",
      " - coste_bruto\n",
      " - margen\n",
      " - n_pedidos\n",
      " - n_items_comprados\n",
      " - altura_cm\n",
      " - peso_kg\n",
      " - anio_compra\n",
      " - mes_compra\n",
      " - edad_en_compra\n",
      " - antiguedad_cliente_dias\n",
      " - en_promocion\n",
      " - margen_relativo\n",
      " - desajuste_talla\n",
      " - desajuste_talla_abs\n",
      " - talla_extrema\n",
      " - bmi\n",
      " - compras_previas_cliente\n",
      " - devoluciones_previas_cliente\n",
      " - ratio_devoluciones_previas_cliente\n",
      " - ventas_previas_producto\n",
      " - devoluciones_previas_producto\n",
      " - ratio_devoluciones_previas_producto\n",
      " - precio_rel_cat\n",
      " - missing_provincia_cliente\n",
      " - missing_comunidad\n",
      " - missing_altura_cm\n",
      " - missing_peso_kg\n",
      " - missing_edad_en_compra\n",
      " - missing_antiguedad_cliente_dias\n",
      " - missing_desajuste_talla\n",
      " - missing_bmi\n",
      " - canal_online\n",
      " - comunidad_aragon\n",
      " - comunidad_asturias\n",
      " - comunidad_baleares\n",
      " - comunidad_canarias\n",
      " - comunidad_cantabria\n",
      " - comunidad_castilla y leon\n",
      " - comunidad_castilla-la mancha\n",
      " - comunidad_cataluna\n",
      " - comunidad_ceuta\n",
      " - comunidad_comunidad valenciana\n",
      " - comunidad_extremadura\n",
      " - comunidad_galicia\n",
      " - comunidad_la rioja\n",
      " - comunidad_madrid\n",
      " - comunidad_melilla\n",
      " - comunidad_murcia\n",
      " - comunidad_navarra\n",
      " - comunidad_pais vasco\n",
      " - comunidad_unknown\n",
      " - categoria_bufanda\n",
      " - categoria_calcetines\n",
      " - categoria_calzado\n",
      " - categoria_camisa\n",
      " - categoria_camiseta\n",
      " - categoria_cinturon\n",
      " - categoria_gorra\n",
      " - categoria_pantalon\n",
      " - categoria_sudadera\n",
      " - color_blk\n",
      " - color_blu\n",
      " - color_brn\n",
      " - color_gry\n",
      " - color_lme\n",
      " - color_nav\n",
      " - color_red\n",
      " - color_wht\n",
      " - talla_40\n",
      " - talla_41\n",
      " - talla_42\n",
      " - talla_43\n",
      " - talla_44\n",
      " - talla_45\n",
      " - talla_l\n",
      " - talla_m\n",
      " - talla_onesize\n",
      " - talla_s\n",
      " - talla_xl\n",
      " - talla_xs\n",
      " - temporada_compra_ss\n",
      "\n",
      "=== X_test ===\n",
      "Shape: (226362, 83)\n",
      "Columns:\n",
      " - descuento\n",
      " - precio_neto\n",
      " - coste_bruto\n",
      " - margen\n",
      " - n_pedidos\n",
      " - n_items_comprados\n",
      " - altura_cm\n",
      " - peso_kg\n",
      " - anio_compra\n",
      " - mes_compra\n",
      " - edad_en_compra\n",
      " - antiguedad_cliente_dias\n",
      " - en_promocion\n",
      " - margen_relativo\n",
      " - desajuste_talla\n",
      " - desajuste_talla_abs\n",
      " - talla_extrema\n",
      " - bmi\n",
      " - compras_previas_cliente\n",
      " - devoluciones_previas_cliente\n",
      " - ratio_devoluciones_previas_cliente\n",
      " - ventas_previas_producto\n",
      " - devoluciones_previas_producto\n",
      " - ratio_devoluciones_previas_producto\n",
      " - precio_rel_cat\n",
      " - missing_provincia_cliente\n",
      " - missing_comunidad\n",
      " - missing_altura_cm\n",
      " - missing_peso_kg\n",
      " - missing_edad_en_compra\n",
      " - missing_antiguedad_cliente_dias\n",
      " - missing_desajuste_talla\n",
      " - missing_bmi\n",
      " - canal_online\n",
      " - comunidad_aragon\n",
      " - comunidad_asturias\n",
      " - comunidad_baleares\n",
      " - comunidad_canarias\n",
      " - comunidad_cantabria\n",
      " - comunidad_castilla y leon\n",
      " - comunidad_castilla-la mancha\n",
      " - comunidad_cataluna\n",
      " - comunidad_ceuta\n",
      " - comunidad_comunidad valenciana\n",
      " - comunidad_extremadura\n",
      " - comunidad_galicia\n",
      " - comunidad_la rioja\n",
      " - comunidad_madrid\n",
      " - comunidad_melilla\n",
      " - comunidad_murcia\n",
      " - comunidad_navarra\n",
      " - comunidad_pais vasco\n",
      " - comunidad_unknown\n",
      " - categoria_bufanda\n",
      " - categoria_calcetines\n",
      " - categoria_calzado\n",
      " - categoria_camisa\n",
      " - categoria_camiseta\n",
      " - categoria_cinturon\n",
      " - categoria_gorra\n",
      " - categoria_pantalon\n",
      " - categoria_sudadera\n",
      " - color_blk\n",
      " - color_blu\n",
      " - color_brn\n",
      " - color_gry\n",
      " - color_lme\n",
      " - color_nav\n",
      " - color_red\n",
      " - color_wht\n",
      " - talla_40\n",
      " - talla_41\n",
      " - talla_42\n",
      " - talla_43\n",
      " - talla_44\n",
      " - talla_45\n",
      " - talla_l\n",
      " - talla_m\n",
      " - talla_onesize\n",
      " - talla_s\n",
      " - talla_xl\n",
      " - talla_xs\n",
      " - temporada_compra_ss\n",
      "\n",
      "=== y_train ===\n",
      "Shape: (679083, 1)\n",
      "Columns:\n",
      " - devuelto\n",
      "\n",
      "=== train_index ===\n",
      "Shape: (679083, 5)\n",
      "Columns:\n",
      " - fecha_compra\n",
      " - ticket_id\n",
      " - item_id\n",
      " - customer_id\n",
      " - devuelto\n"
     ]
    }
   ],
   "source": [
    "def quick_overview(df, name):\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"Columns:\")\n",
    "    for c in df.columns:\n",
    "        print(f\" - {c}\")\n",
    "\n",
    "quick_overview(X_train, \"X_train\")\n",
    "quick_overview(X_test, \"X_test\")\n",
    "quick_overview(y_train, \"y_train\")\n",
    "quick_overview(train_idx, \"train_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b723ab3-af4b-4857-a4f5-ca6e3acaa358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comunidad_cataluna                        bool\n",
       "categoria_gorra                           bool\n",
       "categoria_cinturon                        bool\n",
       "categoria_camiseta                        bool\n",
       "categoria_camisa                          bool\n",
       "                                        ...   \n",
       "ratio_devoluciones_previas_cliente     float64\n",
       "ratio_devoluciones_previas_producto    float64\n",
       "precio_rel_cat                         float64\n",
       "edad_en_compra                         float64\n",
       "descuento                              float64\n",
       "Length: 83, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes.sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0f07af-b4c7-4003-abec-59680f13adbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>descuento</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precio_neto</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coste_bruto</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>margen</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n_pedidos</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>talla_onesize</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>talla_s</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>talla_xl</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>talla_xs</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>temporada_compra_ss</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 column    dtype\n",
       "0             descuento  float64\n",
       "1           precio_neto  float64\n",
       "2           coste_bruto  float64\n",
       "3                margen  float64\n",
       "4             n_pedidos  float64\n",
       "..                  ...      ...\n",
       "78        talla_onesize     bool\n",
       "79              talla_s     bool\n",
       "80             talla_xl     bool\n",
       "81             talla_xs     bool\n",
       "82  temporada_compra_ss     bool\n",
       "\n",
       "[83 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"column\": X_train.columns,\n",
    "    \"dtype\": X_train.dtypes.values\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59574230-be08-4d1a-b037-ba3a4ba4e25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n_items_comprados',\n",
       " 'antiguedad_cliente_dias',\n",
       " 'compras_previas_cliente',\n",
       " 'devoluciones_previas_cliente',\n",
       " 'ratio_devoluciones_previas_cliente',\n",
       " 'ventas_previas_producto',\n",
       " 'devoluciones_previas_producto',\n",
       " 'ratio_devoluciones_previas_producto',\n",
       " 'missing_provincia_cliente',\n",
       " 'missing_antiguedad_cliente_dias']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_id_cols = [\n",
    "    c for c in X_train.columns \n",
    "    if any(k in c.lower() for k in [\"item\", \"ticket\", \"product\", \"sku\", \"cliente\", \"customer\"])\n",
    "]\n",
    "\n",
    "possible_id_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "786aff49-064e-47f6-a587-42d654556365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_compra</th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>devuelto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>T378172</td>\n",
       "      <td>T378172-001</td>\n",
       "      <td>C209219</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>T378172</td>\n",
       "      <td>T378172-002</td>\n",
       "      <td>C209219</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>T378174</td>\n",
       "      <td>T378174-001</td>\n",
       "      <td>C209220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>T378174</td>\n",
       "      <td>T378174-002</td>\n",
       "      <td>C209220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>T378176</td>\n",
       "      <td>T378176-001</td>\n",
       "      <td>C209221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fecha_compra ticket_id      item_id customer_id  devuelto\n",
       "0   2025-01-01   T378172  T378172-001     C209219         0\n",
       "1   2025-01-01   T378172  T378172-002     C209219         0\n",
       "2   2025-01-01   T378174  T378174-001     C209220         0\n",
       "3   2025-01-01   T378174  T378174-002     C209220         1\n",
       "4   2025-01-01   T378176  T378176-001     C209221         0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx.head()\n",
    "test_idx.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbda1a8b-c793-4135-b746-8b1e00182584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>descuento</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045573</td>\n",
       "      <td>0.090225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precio_neto</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.286818</td>\n",
       "      <td>30.735368</td>\n",
       "      <td>7.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>80.75</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coste_bruto</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.878926</td>\n",
       "      <td>16.4384</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>margen</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.407892</td>\n",
       "      <td>15.104425</td>\n",
       "      <td>2.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_pedidos</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.60113</td>\n",
       "      <td>3.080691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_items_comprados</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.16709</td>\n",
       "      <td>5.173268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>altura_cm</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177.098089</td>\n",
       "      <td>7.508915</td>\n",
       "      <td>150.1</td>\n",
       "      <td>172.9</td>\n",
       "      <td>176.6</td>\n",
       "      <td>181.0</td>\n",
       "      <td>209.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peso_kg</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.884767</td>\n",
       "      <td>13.151691</td>\n",
       "      <td>40.0</td>\n",
       "      <td>72.3</td>\n",
       "      <td>78.8</td>\n",
       "      <td>86.1</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anio_compra</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022.528028</td>\n",
       "      <td>1.609969</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>2025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mes_compra</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.95885</td>\n",
       "      <td>3.510715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edad_en_compra</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.903302</td>\n",
       "      <td>4.861496</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antiguedad_cliente_dias</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.518508</td>\n",
       "      <td>227.858137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2651.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_promocion</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.24827</td>\n",
       "      <td>0.43201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>margen_relativo</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.535975</td>\n",
       "      <td>0.067846</td>\n",
       "      <td>0.22408</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desajuste_talla</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.086723</td>\n",
       "      <td>0.585971</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desajuste_talla_abs</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.257103</td>\n",
       "      <td>0.533648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talla_extrema</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.164457</td>\n",
       "      <td>0.37069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.325788</td>\n",
       "      <td>2.65731</td>\n",
       "      <td>16.984235</td>\n",
       "      <td>23.84859</td>\n",
       "      <td>25.308379</td>\n",
       "      <td>26.760856</td>\n",
       "      <td>38.400251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compras_previas_cliente</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.797101</td>\n",
       "      <td>2.87219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>devoluciones_previas_cliente</th>\n",
       "      <td>679083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.514146</td>\n",
       "      <td>1.360484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 count unique  top freq         mean  \\\n",
       "descuento                     679083.0    NaN  NaN  NaN     0.045573   \n",
       "precio_neto                   679083.0    NaN  NaN  NaN    56.286818   \n",
       "coste_bruto                   679083.0    NaN  NaN  NaN    26.878926   \n",
       "margen                        679083.0    NaN  NaN  NaN    29.407892   \n",
       "n_pedidos                     679083.0    NaN  NaN  NaN      2.60113   \n",
       "n_items_comprados             679083.0    NaN  NaN  NaN      4.16709   \n",
       "altura_cm                     679083.0    NaN  NaN  NaN   177.098089   \n",
       "peso_kg                       679083.0    NaN  NaN  NaN    79.884767   \n",
       "anio_compra                   679083.0    NaN  NaN  NaN  2022.528028   \n",
       "mes_compra                    679083.0    NaN  NaN  NaN      6.95885   \n",
       "edad_en_compra                679083.0    NaN  NaN  NaN    23.903302   \n",
       "antiguedad_cliente_dias       679083.0    NaN  NaN  NaN    95.518508   \n",
       "en_promocion                  679083.0    NaN  NaN  NaN      0.24827   \n",
       "margen_relativo               679083.0    NaN  NaN  NaN     0.535975   \n",
       "desajuste_talla               679083.0    NaN  NaN  NaN     0.086723   \n",
       "desajuste_talla_abs           679083.0    NaN  NaN  NaN     0.257103   \n",
       "talla_extrema                 679083.0    NaN  NaN  NaN     0.164457   \n",
       "bmi                           679083.0    NaN  NaN  NaN    25.325788   \n",
       "compras_previas_cliente       679083.0    NaN  NaN  NaN     1.797101   \n",
       "devoluciones_previas_cliente  679083.0    NaN  NaN  NaN     0.514146   \n",
       "\n",
       "                                     std        min       25%        50%  \\\n",
       "descuento                       0.090225        0.0       0.0        0.0   \n",
       "precio_neto                    30.735368        7.8      27.0       50.0   \n",
       "coste_bruto                      16.4384        5.0      12.0       22.0   \n",
       "margen                         15.104425        2.8      16.0       27.0   \n",
       "n_pedidos                       3.080691        0.0       1.0        2.0   \n",
       "n_items_comprados               5.173268        0.0       1.0        2.0   \n",
       "altura_cm                       7.508915      150.1     172.9      176.6   \n",
       "peso_kg                        13.151691       40.0      72.3       78.8   \n",
       "anio_compra                     1.609969     2017.0    2022.0     2023.0   \n",
       "mes_compra                      3.510715        1.0       4.0        7.0   \n",
       "edad_en_compra                  4.861496       16.0      21.0       23.0   \n",
       "antiguedad_cliente_dias       227.858137        0.0       0.0        0.0   \n",
       "en_promocion                     0.43201        0.0       0.0        0.0   \n",
       "margen_relativo                 0.067846    0.22408       0.5       0.56   \n",
       "desajuste_talla                 0.585971       -5.0       0.0        0.0   \n",
       "desajuste_talla_abs             0.533648        0.0       0.0        0.0   \n",
       "talla_extrema                    0.37069        0.0       0.0        0.0   \n",
       "bmi                              2.65731  16.984235  23.84859  25.308379   \n",
       "compras_previas_cliente          2.87219        0.0       0.0        1.0   \n",
       "devoluciones_previas_cliente    1.360484        0.0       0.0        0.0   \n",
       "\n",
       "                                    75%        max  \n",
       "descuento                           0.0       0.35  \n",
       "precio_neto                       80.75      130.0  \n",
       "coste_bruto                        45.0       65.0  \n",
       "margen                             38.5       65.0  \n",
       "n_pedidos                           4.0       25.0  \n",
       "n_items_comprados                   5.0       49.0  \n",
       "altura_cm                         181.0      209.8  \n",
       "peso_kg                            86.1      144.0  \n",
       "anio_compra                      2024.0     2025.0  \n",
       "mes_compra                         10.0       12.0  \n",
       "edad_en_compra                     26.0       49.0  \n",
       "antiguedad_cliente_dias            63.0     2651.0  \n",
       "en_promocion                        0.0        1.0  \n",
       "margen_relativo                0.583333   0.652174  \n",
       "desajuste_talla                     0.0        6.0  \n",
       "desajuste_talla_abs                 0.0        6.0  \n",
       "talla_extrema                       0.0        1.0  \n",
       "bmi                           26.760856  38.400251  \n",
       "compras_previas_cliente             2.0       48.0  \n",
       "devoluciones_previas_cliente        0.0       35.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe(include=\"all\").T.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5782764d-b5e9-4547-96c2-aa2a6bb9e4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ropa)",
   "language": "python",
   "name": "ropa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
